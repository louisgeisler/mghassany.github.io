<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 2 Échantillonnage et Théorèmes limites | Statistique Inférentielle</title>
  <meta name="description" content="Cours de Statistique Inférentielle A3 ESILV" />
  <meta name="generator" content="bookdown 0.24.10 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 2 Échantillonnage et Théorèmes limites | Statistique Inférentielle" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Cours de Statistique Inférentielle A3 ESILV" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 2 Échantillonnage et Théorèmes limites | Statistique Inférentielle" />
  
  <meta name="twitter:description" content="Cours de Statistique Inférentielle A3 ESILV" />
  

<meta name="author" content="Mohamad Ghassany" />


<meta name="date" content="2022-02-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon" />
<link rel="prev" href="tp-statistique-descriptive-avec-r.html"/>
<link rel="next" href="exercices-1.html"/>
<script src="book_assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="book_assets/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="book_assets/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="book_assets/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="book_assets/kePrint-0.0.1/kePrint.js"></script>
<link href="book_assets/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="book_assets/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="book_assets/bsTable-3.3.7/bootstrapTable.js"></script>
<link href="book_assets/font-awesome-5.15.3/css/all.min.css" rel="stylesheet" />
<link href="book_assets/font-awesome-5.15.3/css/v4-shims.min.css" rel="stylesheet" />
<script src="book_assets/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="book_assets/plotly-binding-4.10.0/plotly.js"></script>
<script src="book_assets/typedarray-0.1/typedarray.min.js"></script>
<link href="book_assets/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="book_assets/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="book_assets/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="book_assets/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */
</style>


<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class='beforeimg'>            
   <a href="https://www.esilv.fr/">
       <img src="img/Logo_ESILV_new_blanc.png" style="width:50%; padding:0px 0; display:block; margin: 0 auto;" alt="ESILV logo">
    </a>
</li>
<li class='before'><a href="./">Statistique Inférentielle</a></li>

<li class="divider"></li>
<li><a href="index.html#overview">Overview<span></span></a>
<ul>
<li><a href="index.html#plan-et-déroulement-du-cours">Plan et déroulement du cours<span></span></a></li>
</ul></li>
<li><a href="introduction.html#introduction">Introduction<span></span></a>
<ul>
<li><a href="introduction.html#la-démarche-statistique">La démarche statistique<span></span></a></li>
<li><a href="introduction.html#objectifs-et-plan-du-cours">Objectifs et plan du cours<span></span></a></li>
</ul></li>
<li class="part"><span><b>Statistique descriptive<span></span></b></span></li>
<li class="part"><span><b>Séance 1<span></span></b></span></li>
<li class="chapter" data-level="1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html"><i class="fa fa-check"></i><b>1</b> Statistique descriptive<span></span></a>
<ul>
<li class="chapter" data-level="1.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#terminologie"><i class="fa fa-check"></i><b>1.1</b> Terminologie<span></span></a></li>
<li class="chapter" data-level="1.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#statistique-et-probabilités"><i class="fa fa-check"></i><b>1.2</b> Statistique et Probabilités<span></span></a></li>
<li class="chapter" data-level="1.3" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#description-dune-série-de-valeurs"><i class="fa fa-check"></i><b>1.3</b> Description d’une série de valeurs<span></span></a></li>
<li class="chapter" data-level="1.4" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#représentations-graphiques"><i class="fa fa-check"></i><b>1.4</b> Représentations graphiques<span></span></a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#variable-qualitative"><i class="fa fa-check"></i><b>1.4.1</b> Variable qualitative<span></span></a></li>
<li class="chapter" data-level="1.4.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#variable-quantitative"><i class="fa fa-check"></i><b>1.4.2</b> Variable quantitative<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#indicateurs-statistiques"><i class="fa fa-check"></i><b>1.5</b> Indicateurs statistiques<span></span></a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#tendance-centrale"><i class="fa fa-check"></i><b>1.5.1</b> Tendance centrale<span></span></a></li>
<li class="chapter" data-level="1.5.2" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#dispersion-variabilité"><i class="fa fa-check"></i><b>1.5.2</b> Dispersion (variabilité)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="statistique-descriptive.html"><a href="statistique-descriptive.html#statistique-descriptive-bidimensionnelle"><i class="fa fa-check"></i><b>1.6</b> Statistique descriptive bidimensionnelle<span></span></a>
<ul>
<li><a href="statistique-descriptive.html#deux-variables-quantitatives">Deux variables quantitatives<span></span></a></li>
<li><a href="statistique-descriptive.html#une-variable-quantitative-et-une-qualitative">Une variable quantitative et une qualitative<span></span></a></li>
<li><a href="statistique-descriptive.html#deux-variables-qualitatives">Deux variables qualitatives<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="exercices.html#exercices">Exercices<span></span></a></li>
<li><a href="tp-statistique-descriptive-avec-r.html#tp-statistique-descriptive-avec-r">TP Statistique descriptive avec R<span></span></a>
<ul>
<li><a href="tp-statistique-descriptive-avec-r.html#quest-ce-que-cest-que">Qu’est-ce que c’est que <svg aria-hidden="true" role="img" viewBox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:steelblue;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/></svg>?<span></span></a>
<ul>
<li><a href="tp-statistique-descriptive-avec-r.html#rstudio">RStudio<span></span></a></li>
</ul></li>
<li><a href="tp-statistique-descriptive-avec-r.html#ère-partie-données-quantitatives-discrètes">1ère partie: Données quantitatives discrètes<span></span></a>
<ul>
<li><a href="tp-statistique-descriptive-avec-r.html#effectifs-et-fréquence">Effectifs et fréquence<span></span></a></li>
<li><a href="tp-statistique-descriptive-avec-r.html#mesures-de-tendance-centrale">Mesures de tendance centrale<span></span></a></li>
<li><a href="tp-statistique-descriptive-avec-r.html#indicateurs-de-dispersion">Indicateurs de dispersion<span></span></a></li>
<li><a href="tp-statistique-descriptive-avec-r.html#représentations-graphiques-1">Représentations graphiques<span></span></a></li>
</ul></li>
<li><a href="tp-statistique-descriptive-avec-r.html#ème-partie-analyse-descriptive">2ème partie : Analyse descriptive<span></span></a>
<ul>
<li><a href="tp-statistique-descriptive-avec-r.html#données-utilisées">Données utilisées<span></span></a></li>
<li><a href="tp-statistique-descriptive-avec-r.html#définition-du-répertoire-de-travail">Définition du répertoire de travail<span></span></a></li>
<li><a href="tp-statistique-descriptive-avec-r.html#chargement-des-données">Chargement des données<span></span></a></li>
<li><a href="tp-statistique-descriptive-avec-r.html#analyse-descriptive-univariée">Analyse descriptive univariée<span></span></a></li>
<li><a href="tp-statistique-descriptive-avec-r.html#analyse-descriptive-bivariée">Analyse descriptive bivariée<span></span></a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Statistique Inférentielle<span></span></b></span></li>
<li class="part"><span><b>Séance 2<span></span></b></span></li>
<li class="chapter" data-level="2" data-path="echantillonnage-et-theoremes-limites.html"><a href="echantillonnage-et-theoremes-limites.html"><i class="fa fa-check"></i><b>2</b> Échantillonnage et Théorèmes limites<span></span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="echantillonnage-et-theoremes-limites.html"><a href="echantillonnage-et-theoremes-limites.html#échantillonnage"><i class="fa fa-check"></i><b>2.1</b> Échantillonnage<span></span></a></li>
<li class="chapter" data-level="2.2" data-path="echantillonnage-et-theoremes-limites.html"><a href="echantillonnage-et-theoremes-limites.html#la-statistique-overlinex_n"><i class="fa fa-check"></i><b>2.2</b> La statistique <span class="math inline">\(\overline{X}_n\)</span><span></span></a></li>
<li class="chapter" data-level="2.3" data-path="echantillonnage-et-theoremes-limites.html"><a href="echantillonnage-et-theoremes-limites.html#théorèmes-limites"><i class="fa fa-check"></i><b>2.3</b> Théorèmes limites<span></span></a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="echantillonnage-et-theoremes-limites.html"><a href="echantillonnage-et-theoremes-limites.html#loi-faible-des-grands-nombres"><i class="fa fa-check"></i><b>2.3.1</b> Loi faible des grands nombres<span></span></a></li>
<li class="chapter" data-level="2.3.2" data-path="echantillonnage-et-theoremes-limites.html"><a href="echantillonnage-et-theoremes-limites.html#loi-forte-des-grands-nombres"><i class="fa fa-check"></i><b>2.3.2</b> Loi forte des grands nombres<span></span></a></li>
<li><a href="echantillonnage-et-theoremes-limites.html#illustration-de-la-loi-des-grands-nombres">Illustration de la loi des grands nombres<span></span></a></li>
<li class="chapter" data-level="2.3.3" data-path="echantillonnage-et-theoremes-limites.html"><a href="echantillonnage-et-theoremes-limites.html#théorème-central-limite"><i class="fa fa-check"></i><b>2.3.3</b> Théorème central limite<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="echantillonnage-et-theoremes-limites.html"><a href="echantillonnage-et-theoremes-limites.html#loi-pourcentage"><i class="fa fa-check"></i><b>2.4</b> Loi d’un pourcentage<span></span></a></li>
<li class="chapter" data-level="2.5" data-path="echantillonnage-et-theoremes-limites.html"><a href="echantillonnage-et-theoremes-limites.html#etude-de-la-statistique-s2"><i class="fa fa-check"></i><b>2.5</b> Etude de la statistique <span class="math inline">\(S^2\)</span><span></span></a></li>
<li class="chapter" data-level="2.6" data-path="echantillonnage-et-theoremes-limites.html"><a href="echantillonnage-et-theoremes-limites.html#intro-estimation"><i class="fa fa-check"></i><b>2.6</b> Introduction à l’estimation<span></span></a></li>
</ul></li>
<li><a href="exercices-1.html#exercices-1">Exercices<span></span></a></li>
<li><a href="tp-illustration-numérique-des-théorèmes-limites-avec-r.html#tp-illustration-numérique-des-théorèmes-limites-avec-r">TP illustration numérique des théorèmes limites avec R<span></span></a>
<ul>
<li><a href="tp-illustration-numérique-des-théorèmes-limites-avec-r.html#réalisations-de-variables-aléatoires">Réalisations de variables aléatoires<span></span></a></li>
<li><a href="tp-illustration-numérique-des-théorèmes-limites-avec-r.html#fonction-de-densité">Fonction de densité<span></span></a></li>
<li><a href="tp-illustration-numérique-des-théorèmes-limites-avec-r.html#fonction-de-répartition">Fonction de répartition<span></span></a></li>
<li><a href="tp-illustration-numérique-des-théorèmes-limites-avec-r.html#illustrations-de-théorèmes-limites">Illustrations de théorèmes limites<span></span></a>
<ul>
<li><a href="tp-illustration-numérique-des-théorèmes-limites-avec-r.html#loi-forte-de-grands-nombres">Loi forte de grands nombres<span></span></a></li>
<li><a href="tp-illustration-numérique-des-théorèmes-limites-avec-r.html#théorème-central-limite-1">Théorème central limite<span></span></a></li>
</ul></li>
<li><a href="tp-illustration-numérique-des-théorèmes-limites-avec-r.html#bonus">Bonus<span></span></a></li>
</ul></li>
<li class="part"><span><b>Séance 3<span></span></b></span></li>
<li class="chapter" data-level="3" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html"><i class="fa fa-check"></i><b>3</b> Estimation ponctuelle<span></span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="3.2" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#méthodes-destimation"><i class="fa fa-check"></i><b>3.2</b> Méthodes d’estimation<span></span></a></li>
<li class="chapter" data-level="3.3" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#la-méthode-des-moments"><i class="fa fa-check"></i><b>3.3</b> La méthode des moments<span></span></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#lestimateur-des-moments-emm"><i class="fa fa-check"></i><b>3.3.1</b> L’estimateur des moments (EMM)<span></span></a></li>
<li class="chapter" data-level="3.3.2" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#exemples"><i class="fa fa-check"></i><b>3.3.2</b> Exemples<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#la-méthode-du-maximum-de-vraisemblance"><i class="fa fa-check"></i><b>3.4</b> La méthode du maximum de vraisemblance<span></span></a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#la-fonction-de-vraisemblance"><i class="fa fa-check"></i><b>3.4.1</b> La fonction de vraisemblance<span></span></a></li>
<li class="chapter" data-level="3.4.2" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#lestimateur-de-maximum-de-vraisemblance-emv"><i class="fa fa-check"></i><b>3.4.2</b> L’estimateur de maximum de vraisemblance (EMV)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#qualité-dun-estimateur"><i class="fa fa-check"></i><b>3.5</b> Qualité d’un estimateur<span></span></a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#estimateur-sans-biais-et-de-variance-minimale-esbvm"><i class="fa fa-check"></i><b>3.5.1</b> Estimateur sans biais et de variance minimale (ESBVM)<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#propriétés-des-estimateurs-des-moments-emm"><i class="fa fa-check"></i><b>3.6</b> Propriétés des estimateurs des moments (EMM)<span></span></a>
<ul>
<li><a href="estimation-ponctuelle.html#propriétés-de-overlinex_n">Propriétés de <span class="math inline">\(\overline{X}_n\)</span><span></span></a></li>
<li><a href="estimation-ponctuelle.html#propriétés-de-la-variance-empirique-s_n2">Propriétés de la variance empirique <span class="math inline">\(S_{n}^{2}\)</span><span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="estimation-ponctuelle.html"><a href="estimation-ponctuelle.html#propriétés-des-estimateurs-de-maximum-de-vraisemblance-emv"><i class="fa fa-check"></i><b>3.7</b> Propriétés des estimateurs de maximum de vraisemblance (EMV)<span></span></a></li>
</ul></li>
<li><a href="exercices-2.html#exercices-2">Exercices<span></span></a></li>
<li class="part"><span><b>Séance 4<span></span></b></span></li>
<li><a href="tp-estimation.html#tp-estimation">TP estimation<span></span></a>
<ul>
<li class="chapter" data-level="3.8" data-path="tp-estimation.html"><a href="tp-estimation.html"><i class="fa fa-check"></i><b>3.8</b> Comparaison d’estimateurs<span></span></a></li>
<li class="chapter" data-level="3.9" data-path="tp-estimation.html"><a href="tp-estimation.html#le-maximum-de-vraisemblance"><i class="fa fa-check"></i><b>3.9</b> Le maximum de vraisemblance<span></span></a></li>
<li class="chapter" data-level="3.10" data-path="tp-estimation.html"><a href="tp-estimation.html#loi-de-weibull"><i class="fa fa-check"></i><b>3.10</b> Loi de Weibull<span></span></a></li>
</ul></li>
<li class="part"><span><b>Séance 5<span></span></b></span></li>
<li class="chapter" data-level="4" data-path="estimation-par-intervalle-de-confiance.html"><a href="estimation-par-intervalle-de-confiance.html"><i class="fa fa-check"></i><b>4</b> Estimation par Intervalle de confiance<span></span></a>
<ul>
<li class="chapter" data-level="4.1" data-path="estimation-par-intervalle-de-confiance.html"><a href="estimation-par-intervalle-de-confiance.html#intervalles-de-confiance-pour-les-paramètres-de-la-loi-normale"><i class="fa fa-check"></i><b>4.1</b> Intervalles de confiance pour les paramètres de la loi normale<span></span></a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="estimation-par-intervalle-de-confiance.html"><a href="estimation-par-intervalle-de-confiance.html#ic-normale-variance-connue"><i class="fa fa-check"></i><b>4.1.1</b> Intervalle de confiance pour l’espérance d’une loi normale avec variance connue<span></span></a></li>
<li class="chapter" data-level="4.1.2" data-path="estimation-par-intervalle-de-confiance.html"><a href="estimation-par-intervalle-de-confiance.html#ic-normale-variance-inconnue"><i class="fa fa-check"></i><b>4.1.2</b> Intervalle de confiance pour l’espérance d’une loi normale avec variance inconnue<span></span></a></li>
<li class="chapter" data-level="4.1.3" data-path="estimation-par-intervalle-de-confiance.html"><a href="estimation-par-intervalle-de-confiance.html#ic-normale-variance"><i class="fa fa-check"></i><b>4.1.3</b> Intervalle de confiance pour la variance d’une loi normale<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="estimation-par-intervalle-de-confiance.html"><a href="estimation-par-intervalle-de-confiance.html#ic-proportion"><i class="fa fa-check"></i><b>4.2</b> Intervalle de confiance pour une proportion<span></span></a></li>
<li class="chapter" data-level="4.3" data-path="estimation-par-intervalle-de-confiance.html"><a href="estimation-par-intervalle-de-confiance.html#récapitulatif-pour-la-construction-dintervalles-de-confiance"><i class="fa fa-check"></i><b>4.3</b> Récapitulatif pour la construction d’intervalles de confiance<span></span></a></li>
</ul></li>
<li><a href="exercices-3.html#exercices-3">Exercices<span></span></a></li>
<li class="part"><span><b>Séance 6<span></span></b></span></li>
<li><a href="tp-intervalle-de-confiance.html#tp-intervalle-de-confiance">TP Intervalle de confiance<span></span></a>
<ul>
<li class="chapter" data-level="4.4" data-path="tp-intervalle-de-confiance.html"><a href="tp-intervalle-de-confiance.html"><i class="fa fa-check"></i><b>4.4</b> IC pour la moyenne et la variance de la loi normale<span></span></a></li>
<li class="chapter" data-level="4.5" data-path="tp-intervalle-de-confiance.html"><a href="tp-intervalle-de-confiance.html#ic-pour-une-proportion-et-effet-de-la-confiance"><i class="fa fa-check"></i><b>4.5</b> IC pour une proportion et effet de la confiance<span></span></a></li>
<li class="chapter" data-level="4.6" data-path="tp-intervalle-de-confiance.html"><a href="tp-intervalle-de-confiance.html#ic-pour-le-paramètre-lambda-dune-loi-exponentielle"><i class="fa fa-check"></i><b>4.6</b> IC pour le paramètre <span class="math inline">\(\lambda\)</span> d’une loi exponentielle<span></span></a></li>
</ul></li>
<li class="part"><span><b>Séance 7<span></span></b></span></li>
<li class="chapter" data-level="5" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html"><i class="fa fa-check"></i><b>5</b> Tests d’hypothèses<span></span></a>
<ul>
<li class="chapter" data-level="5.1" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html#introduction-le-problème-de-décision"><i class="fa fa-check"></i><b>5.1</b> Introduction: le problème de décision<span></span></a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html#les-tests-unilatéraux-et-bilatéraux"><i class="fa fa-check"></i><b>5.1.1</b> Les tests unilatéraux et bilatéraux<span></span></a></li>
<li class="chapter" data-level="5.1.2" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html#relation-entre-tests-dhypothèses-bilatéraux-et-intervalles-de-confiance"><i class="fa fa-check"></i><b>5.1.2</b> Relation entre tests d’hypothèses bilatéraux et intervalles de confiance<span></span></a></li>
<li class="chapter" data-level="5.1.3" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html#la-démarche-générale-dun-test-dhypothèse"><i class="fa fa-check"></i><b>5.1.3</b> La démarche générale d’un test d’hypothèse<span></span></a></li>
<li class="chapter" data-level="5.1.4" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html#types-de-test-dhypothèses"><i class="fa fa-check"></i><b>5.1.4</b> Types de test d’hypothèses<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html#les-tests-dhypothèses-à-partir-dun-seul-échantillon"><i class="fa fa-check"></i><b>5.2</b> Les tests d’hypothèses à partir d’un seul échantillon<span></span></a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html#les-tests-sur-la-moyenne-dune-distribution-normale-de-variance-connue"><i class="fa fa-check"></i><b>5.2.1</b> Les tests sur la moyenne d’une distribution normale de variance connue<span></span></a></li>
<li class="chapter" data-level="5.2.2" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html#les-tests-sur-la-moyenne-dune-distribution-normale-de-variance-inconnue"><i class="fa fa-check"></i><b>5.2.2</b> Les tests sur la moyenne d’une distribution normale de variance inconnue<span></span></a></li>
<li class="chapter" data-level="5.2.3" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html#les-tests-sur-la-variance-dune-distribution-normale"><i class="fa fa-check"></i><b>5.2.3</b> Les tests sur la variance d’une distribution normale<span></span></a></li>
<li class="chapter" data-level="5.2.4" data-path="tests-dhypotheses.html"><a href="tests-dhypotheses.html#les-tests-sur-une-proportion"><i class="fa fa-check"></i><b>5.2.4</b> Les tests sur une proportion<span></span></a></li>
</ul></li>
</ul></li>
<li><a href="exercices-4.html#exercices-4">Exercices<span></span></a></li>
<li class="part"><span><b>Séance 8<span></span></b></span></li>
<li class="chapter" data-level="6" data-path="tests-dhypotheses-sur-deux-echantillons.html"><a href="tests-dhypotheses-sur-deux-echantillons.html"><i class="fa fa-check"></i><b>6</b> Tests d’hypothèses sur deux échantillons<span></span></a>
<ul>
<li class="chapter" data-level="6.1" data-path="tests-dhypotheses-sur-deux-echantillons.html"><a href="tests-dhypotheses-sur-deux-echantillons.html#comparaison-de-deux-échantillons-gaussiens-indépendants"><i class="fa fa-check"></i><b>6.1</b> Comparaison de deux échantillons gaussiens indépendants<span></span></a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="tests-dhypotheses-sur-deux-echantillons.html"><a href="tests-dhypotheses-sur-deux-echantillons.html#test-de-fisher-de-comparaison-des-variances"><i class="fa fa-check"></i><b>6.1.1</b> Test de Fisher de comparaison des variances<span></span></a></li>
<li class="chapter" data-level="6.1.2" data-path="tests-dhypotheses-sur-deux-echantillons.html"><a href="tests-dhypotheses-sur-deux-echantillons.html#tests-de-comparaison-de-moyennes"><i class="fa fa-check"></i><b>6.1.2</b> Tests de comparaison de moyennes<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="tests-dhypotheses-sur-deux-echantillons.html"><a href="tests-dhypotheses-sur-deux-echantillons.html#comparaison-de-deux-proportions"><i class="fa fa-check"></i><b>6.2</b> Comparaison de deux proportions<span></span></a></li>
</ul></li>
<li><a href="exercices-5.html#exercices-5">Exercices<span></span></a></li>
<li class="appendix"><span><b>Annexe<span></span></b></span></li>
<li class="chapter" data-level="A" data-path="app-introRStudio.html"><a href="app-introRStudio.html"><i class="fa fa-check"></i><b>A</b> Introduction to <code>RStudio</code><span></span></a></li>
<li class="chapter" data-level="B" data-path="tab:normale1.html"><a href="tab:normale1.html"><i class="fa fa-check"></i><b>B</b> Table 1 de la loi Normale centrée réduite<span></span></a></li>
<li class="chapter" data-level="C" data-path="tab:normale2.html"><a href="tab:normale2.html"><i class="fa fa-check"></i><b>C</b> Table 2 de la loi Normale centrée réduite<span></span></a></li>
<li class="chapter" data-level="D" data-path="tab:student.html"><a href="tab:student.html"><i class="fa fa-check"></i><b>D</b> Table de la loi de Student<span></span></a></li>
<li class="chapter" data-level="E" data-path="tab:khideux.html"><a href="tab:khideux.html"><i class="fa fa-check"></i><b>E</b> Table de la loi de Khi-deux <span class="math inline">\(\chi^2\)</span><span></span></a></li>
<li class="chapter" data-level="F" data-path="tab:fisher.html"><a href="tab:fisher.html"><i class="fa fa-check"></i><b>F</b> Tables de la loi de Fisher <span class="math inline">\(F\)</span><span></span></a>
<ul>
<li class="chapter" data-level="F.1" data-path="tab:fisher.html"><a href="tab:fisher.html#pour-alpha-5"><i class="fa fa-check"></i><b>F.1</b> Pour <span class="math inline">\(\alpha = 5\%\)</span><span></span></a></li>
<li class="chapter" data-level="F.2" data-path="tab:fisher.html"><a href="tab:fisher.html#pour-alpha-2.5"><i class="fa fa-check"></i><b>F.2</b> Pour <span class="math inline">\(\alpha = 2.5\%\)</span><span></span></a></li>
<li class="chapter" data-level="F.3" data-path="tab:fisher.html"><a href="tab:fisher.html#pour-alpha-1"><i class="fa fa-check"></i><b>F.3</b> Pour <span class="math inline">\(\alpha = 1\%\)</span><span></span></a></li>
<li class="chapter" data-level="F.4" data-path="tab:fisher.html"><a href="tab:fisher.html#pour-alpha-0.05"><i class="fa fa-check"></i><b>F.4</b> Pour <span class="math inline">\(\alpha = 0.05\%\)</span><span></span></a></li>
</ul></li>
<li class="chapter" data-level="G" data-path="notes-et-examens.html"><a href="notes-et-examens.html"><i class="fa fa-check"></i><b>G</b> Notes et examens<span></span></a>
<ul>
<li><a href="notes-et-examens.html#sujets-corrections">Sujets &amp; Corrections<span></span></a></li>
<li><a href="notes-et-examens.html#notes">Notes<span></span></a></li>
<li><a href="notes-et-examens.html#analyse-notes">Analyse Notes<span></span></a></li>
</ul></li>
<li><a href="références-et-crédits.html#références-et-crédits">Références et Crédits<span></span></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistique Inférentielle</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="echantillonnage-et-theoremes-limites" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapitre 2</span> Échantillonnage et Théorèmes limites<a href="echantillonnage-et-theoremes-limites.html#echantillonnage-et-theoremes-limites" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<!-- from (Cours 1ère année) Thérèse Phan-Probabilités et statistique. 2-Ecole Centrale Paris (2005) -->
<div id="échantillonnage" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Échantillonnage<a href="echantillonnage-et-theoremes-limites.html#échantillonnage" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>L’étude d’une caractéristique d’une pièce fabriquée en grand nombre (telle que la luminosité d’une ampoule, sa durée de vie ou encore le diamètre d’une pièce mécanique) relève, elle aussi, de la statistique descriptive. Il n’est toutefois <strong>pas possible</strong> de mesurer cette caractéristique sur toutes les pièces produites. Il est alors nécessaire de se limiter à l’étude des éléments d’un <strong>échantillon</strong>. Cet échantillon devra répondre à des critères particuliers pour pouvoir représenter la population toute entière dans l’étude statistique.</p>
<p>La démarche statistique présente plusieurs étapes :</p>
<ul>
<li><strong>Prélèvement d’un échantillon représentatif de la population ou échantillon aléatoire</strong> par des techniques appropriées. Cela relève de la théorie de l’échantillonnage.</li>
<li><strong>Étude des caractéristiques de cet échantillon</strong>, issu d’une population dont on connaît la loi de probabilité. On s’intéresse principalement à ceux issus d’une population gaussienne.</li>
</ul>

<div class="definition">
<span id="def:echantillon" class="definition"><strong>Définition 2.1  \iffalse (Echantillon) </strong></span>Un échantillon aléatoire est un <span class="math inline">\(n\)</span>-uplet <span class="math inline">\((X_1,\ldots,X_n)\)</span> de <span class="math inline">\(n\)</span> variables aléatoires indépendantes suivant la même loi qu’une variable <span class="math inline">\(X\)</span> appelée variable aléatoire parente. Une réalisation de l’échantillon sera notée <span class="math inline">\((x_1,\ldots,x_n)\)</span>.
</div>

<div class="definition">
<p><span id="def:statistique" class="definition"><strong>Définition 2.2  \iffalse (Une statistique) </strong></span>Soit <span class="math inline">\(X\)</span> une variable aléatoire. Considérons un <span class="math inline">\(n\)</span>-échantillon <span class="math inline">\((X_1,\ldots,X_n)\)</span> de <span class="math inline">\(X\)</span>. Une <strong>Statistique</strong> <span class="math inline">\(T\)</span> est une variable aléatoire fonction mesurable de <span class="math inline">\((X_1,\ldots,X_n)\)</span>.</p>
<p><span class="math display">\[ T(X)=T(X_1,\ldots,X_n) \]</span></p>
A un échantillon, on peut associer plusieurs statistiques.
</div>
<!-- <br></br> -->
</div>
<div id="la-statistique-overlinex_n" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> La statistique <span class="math inline">\(\overline{X}_n\)</span><a href="echantillonnage-et-theoremes-limites.html#la-statistique-overlinex_n" class="anchor-section" aria-label="Anchor link to header"></a></h2>

<div class="definition">
<span id="def:unnamed-chunk-58" class="definition"><strong>Définition 2.3  \iffalse (Moyenne empirique) </strong></span>La statistique <span class="math inline">\(\overline{X}_n\)</span> ou moyenne empirique d’un échantillon est une statistique définie par <span class="math display">\[\overline{X}_n = \frac{1}{n} \sum_{i=1}^n X_i\]</span>
</div>
<p><strong>Espérance et variance de <span class="math inline">\(\overline{X}_n\)</span></strong>:</p>
<p>Soit <span class="math inline">\(m\)</span> l’espérance et <span class="math inline">\(\sigma^2\)</span> la variance de la variable parente <span class="math inline">\(X\)</span> (e.g. l’espérance et la variance de la population). L’espérance et la variance de la statistique <span class="math inline">\(\overline{X}_n\)</span> sont:</p>
<p><span class="math display">\[E(\overline{X}_n) = m\]</span>
<span class="math display">\[V(\overline{X}_n) = \frac{\sigma^2}{n}\]</span></p>
<p><strong>Démonstration</strong>:</p>
<ul>
<li><span class="math inline">\(E(\overline{X}_n) = \frac{1}{n} \sum_{i=1}^n E(X_i) = \frac{1}{n} nm = m\)</span></li>
<li><span class="math inline">\(V(\overline{X}_n) =V(\frac{1}{n} \sum_{i=1}^n X_i) = \frac{1}{n^2} V(\sum_{i=1}^n X_i) = \frac{1}{n^2} \sum_{i=1}^n V(X_i) = \frac{1}{n^2} \sum_{i=1}^n \sigma^2 = \frac{1}{n^2} n \sigma^2 = \frac{\sigma^2}{n} \quad \quad\)</span> (Les <span class="math inline">\(X_i\)</span> étant supposées indépendantes)</li>
</ul>
</div>
<div id="théorèmes-limites" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Théorèmes limites<a href="echantillonnage-et-theoremes-limites.html#théorèmes-limites" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Cette section introduit trois résultats importants de la théorie asymptotique
des probabilités: la loi faible des grands nombres, la loi forte des grands nombres
et le théorème central limite, dans sa version pour variables aléatoires indépendantes et identiquement distribuées (<span class="math inline">\(X_i\)</span> suivent la même loi pour <span class="math inline">\(i=1,\ldots,n\)</span>). Ce sont des résultats qui traitent les propriétés de la distribution de la statistique <span class="math inline">\(\overline{X}_n\)</span>.</p>
<div class="rmdinsight">
<p>Des variables aléatoires indépendantes et identiquement distribuées (<strong>i.i.d</strong>) sont des variables aléatoires indépendantes qui suivent la même loi de probabilité, donc ont la même espérance et la même variance.</p>
</div>
<p>Les deux lois des grands nombres énoncent les conditions sous lesquelles la
moyenne d’une suite de variables aléatoires converge vers leur espérance commune et expriment l’idée que lorsque le nombre d’observations augmente, la
différence entre la valeur attendue (<span class="math inline">\(m = E(X)\)</span>) et la valeur observée (<span class="math inline">\(\overline{X}_n\)</span>) tend vers zéro. De son côté, le théorème central limite établit que la distribution
standardisée d’une moyenne tend asymptotiquement vers une loi normale, et
cela même si la distribution des variables sous-jacentes est non normale. Ce
résultat est central en probabilités et statistique et peut être facilement illustré
(cf. figure <a href="echantillonnage-et-theoremes-limites.html#fig:illust">2.1</a>). Indépendamment de la distribution sous-jacente des observations (ici une loi uniforme), lorsque <span class="math inline">\(n\)</span> croît, la distribution de <span class="math inline">\(\overline{X}_n\)</span> tend vers une
loi normale: on observe dans l’illustration la forme de plus en plus symétrique
de la distribution ainsi que la concentration autour de l’espérance (ici <span class="math inline">\(m = 0.5\)</span>)
et la réduction de la variance.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:illust"></span>
<img src="Statistique_inferentielle_files/figure-html/illust-1.png" alt="Illustration du théorème central limite: histogramme de la moyenne de 200 échantillons issus d'une loi uniforme sur l'intervalle (0,1) en fonction de la taille $n$ de l'échantillon." width="70%" />
<p class="caption">
Figure 2.1: Illustration du théorème central limite: histogramme de la moyenne de 200 échantillons issus d’une loi uniforme sur l’intervalle (0,1) en fonction de la taille <span class="math inline">\(n\)</span> de l’échantillon.
</p>
</div>
<p>Les retombées pratiques de ces résultats sont importantes. En effet, la
moyenne de variables aléatoires est une quantité qui intervient dans plusieurs
procédures statistiques. Aussi, le résultat du théorème central limite permet
l’approximation des probabilités liées à des sommes de variables aléatoires (e.g. méthode de Monte-Carlo).
De plus, lorsque l’on considère des modèles statistiques, le terme d’erreur représente la somme de beaucoup d’erreurs (erreurs de mesure, variables non
considérées, etc.). En prenant comme justification le théorème central limite,
ce terme d’erreur est souvent supposé se comporter comme une loi normale.</p>
<div id="loi-faible-des-grands-nombres" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Loi faible des grands nombres<a href="echantillonnage-et-theoremes-limites.html#loi-faible-des-grands-nombres" class="anchor-section" aria-label="Anchor link to header"></a></h3>

<div class="theorem">
<p><span id="thm:fable" class="theorem"><strong>Théorème 2.1  \iffalse (Loi faible des grands nombres) </strong></span>Soit <span class="math inline">\(X_1,\ldots,X_n\)</span> une suite de variables aléatoires indépendantes et identiquement distribuées. On suppose que <span class="math inline">\(E(|X_i|) &lt; \infty\)</span> et que tous les <span class="math inline">\(X_i\)</span> admettent la même espérance <span class="math inline">\(E(X_i)=m\)</span>. Alors:</p>
<p><span class="math display">\[\overline{X}_n = \frac{1}{n} \sum_{i=1}^n X_i \rightarrow m \quad \text{au sens de la convergence en probabilités}\]</span></p>
càd <span class="math inline">\(\forall \varepsilon &gt; 0, \lim_{n \to \infty} P(|\overline{X}_n - m|&gt; \varepsilon) = 0\)</span>.
</div>
<div class="rmdinsight">
<p><span class="math inline">\(\overline{X}_n \text{ converge en probabilité vers } m \text{ quand } n \rightarrow +\infty\)</span>.</p>
</div>
</div>
<div id="loi-forte-des-grands-nombres" class="section level3 hasAnchor" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> Loi forte des grands nombres<a href="echantillonnage-et-theoremes-limites.html#loi-forte-des-grands-nombres" class="anchor-section" aria-label="Anchor link to header"></a></h3>

<div class="theorem">
<p><span id="thm:forte" class="theorem"><strong>Théorème 2.2  \iffalse (Loi forte des grands nombres) </strong></span>Soit <span class="math inline">\(X_1,\ldots,X_n\)</span> une suite de variables aléatoires indépendantes et identiquement distribuées. On suppose que <span class="math inline">\(E(|X_i|) &lt; \infty\)</span> et que tous les <span class="math inline">\(X_i\)</span> admettent la même espérance <span class="math inline">\(E(X_i)=m\)</span>. Alors:</p>
<p><span class="math display">\[\overline{X}_n = \frac{1}{n} \sum_{i=1}^n X_i \rightarrow m \quad \text{presque sûrement}\]</span></p>
càd <span class="math inline">\(P\big( \lim_{n \to \infty} \overline{X}_n = m\big) = 1\)</span>.
</div>
<div class="rmdinsight">
<p><span class="math inline">\(\overline{X}_n \text{ converge presque sûrement vers } m\)</span></p>
</div>
</div>
<div id="illustration-de-la-loi-des-grands-nombres" class="section level3 unnumbered hasAnchor">
<h3>Illustration de la loi des grands nombres<a href="echantillonnage-et-theoremes-limites.html#illustration-de-la-loi-des-grands-nombres" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Prenons l’exemple d’un lancer de dé équilibré. On lance un dé et on note <span class="math inline">\(X\)</span> le résultat obtenu. La loi de <span class="math inline">\(X\)</span> est la suivante:</p>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(x_i\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(3\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(4\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(5\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(6\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(P(X = x_i)\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\frac{1}{6}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\frac{1}{6}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\frac{1}{6}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\frac{1}{6}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\frac{1}{6}\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\frac{1}{6}\)</span>
</td>
</tr>
</tbody>
</table>
<p>Et donc l’espérance de <span class="math inline">\(X\)</span> est <span class="math inline">\(E(X)=\sum_i p_i x_i = 3.5\)</span>. Pour illustrer le théorème on va procéder à un échantillonnage. On répète le lancement du dé <span class="math inline">\(n\)</span> fois. A chaque <span class="math inline">\(n\)</span> on va calculer la moyenne empirique des résultats obtenus, qu’on va noter <span class="math inline">\(\overline{X}_n\)</span>. Selon la loi de grands nombre cette moyenne va converger vers l’espérance théorique:</p>
<p><span class="math display">\[\overline{X}_n \rightarrow E(X)=m=3.5 \quad \text{quand} \quad n \rightarrow \infty\]</span></p>
<p>Traçons l’évolution de la moyenne empirique en fonction de la taille <span class="math inline">\(n\)</span> de l’échantillon, dans deux différents échantillonnages aléatoires:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-60"></span>
<img src="Statistique_inferentielle_files/figure-html/unnamed-chunk-60-1.png" alt="Convergence de $\overline{X}_n$ vers $m=3.5$ pour deux différents échantillonnages" width="70%" /><img src="Statistique_inferentielle_files/figure-html/unnamed-chunk-60-2.png" alt="Convergence de $\overline{X}_n$ vers $m=3.5$ pour deux différents échantillonnages" width="70%" />
<p class="caption">
Figure 2.2: Convergence de <span class="math inline">\(\overline{X}_n\)</span> vers <span class="math inline">\(m=3.5\)</span> pour deux différents échantillonnages
</p>
</div>
</div>
<div id="théorème-central-limite" class="section level3 hasAnchor" number="2.3.3">
<h3><span class="header-section-number">2.3.3</span> Théorème central limite<a href="echantillonnage-et-theoremes-limites.html#théorème-central-limite" class="anchor-section" aria-label="Anchor link to header"></a></h3>

<div class="theorem">
<p><span id="thm:central" class="theorem"><strong>Théorème 2.3  \iffalse (Théorème central limite) </strong></span>Soit <span class="math inline">\(X_1,\ldots,X_n\)</span> une suite de variables aléatoires indépendantes et identiquement distribuées, d’espérance <span class="math inline">\(m\)</span> et variance <span class="math inline">\(\sigma^2\)</span> finie. Alors</p>
<p><span class="math display" id="eq:central">\[\begin{equation}
\frac{\overline{X}_n - m}{ \sigma/\sqrt{n}} \xrightarrow{n \to \infty} \mathcal{N}(0,1) \quad \text{en distribution}
\tag{2.1}
\end{equation}\]</span></p>
<p>On voit bien que, afin que la convergence se fasse, une standardisation est
nécessaire: en effet, on peut voir le rapport dans <a href="echantillonnage-et-theoremes-limites.html#eq:central">(2.1)</a> comme</p>
<p><span class="math display">\[\frac{\overline{X}_n - m}{ \sigma/\sqrt{n}} = \frac{\overline{X}_n - E(\overline{X}_n)}{ \sqrt{var(\overline{X}_n)}}\]</span></p>
</div>
<div class="rmdtip">
<p><strong>Notes Historiques</strong></p>
<p>La loi faible des grands nombres a été établie la première fois par J. Bernoulli
pour le cas particulier d’une variable aléatoire binaire ne prenant que les valeurs 0 ou 1. Le résultat a été publié en 1713.</p>
<p>La loi forte des grands nombres est due au mathématicien E. Borel (1871-
1956), d’où parfois son autre appellation: théorème de Borel.</p>
<p>Le théorème central limite a été formulé pour la première fois par A. de
Moivre en 1733 pour approximer le nombre de “piles” dans le jet d’une pièce
de monnaie équilibrée. Ce travail a été un peu oublié jusqu’à ce que P.S. Laplace
ne l’étende à l’approximation d’une loi binomiale par la loi normale dans son
ouvrage <em>Théorie analytique des probabilités</em> en 1812. C’est dans les premières
années du <span class="math inline">\(XX^e\)</span> siècle que A. Lyapounov l’a redéfini en termes généraux et
prouvé avec rigueur.</p>
</div>
<p><strong>Application 1</strong>:</p>
<p>Pour une taille d’échantillon <span class="math inline">\(n\)</span> suffisamment grande, on peut considérer que <span class="math inline">\(\overline{X}_n\)</span> a pour loi:</p>
<p><span class="math display">\[ \overline{X}_n \thicksim \mathcal{N}\big(m, \frac{\sigma^2}{n}\big)\]</span></p>
<div class="rmdcaution">
<p>Dans la notation de la loi normale ci dessus <span class="math inline">\(\frac{\sigma^2}{n}\)</span> est la variance. <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span> est l’écart-type.</p>
</div>
<p><strong>Application 2</strong>: la loi d’un pourcentage, étudiée dans la section suivante.</p>
</div>
</div>
<div id="loi-pourcentage" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Loi d’un pourcentage<a href="echantillonnage-et-theoremes-limites.html#loi-pourcentage" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Soit <span class="math inline">\(X\)</span> la variable aléatoire représentant le nombre de succès au cours d’une suite de <span class="math inline">\(n\)</span>
répétitions indépendantes d’une même épreuve dont la probabilité de succès est <span class="math inline">\(p\)</span>.</p>
<p>La loi de <span class="math inline">\(X\)</span> est la loi binomiale de paramètres <span class="math inline">\(n\)</span> et <span class="math inline">\(p\)</span> notée <span class="math inline">\(\mathcal{B}(n, p)\)</span>. <span class="math inline">\(X\)</span> est la somme de <span class="math inline">\(n\)</span> variables indépendantes de Bernoulli de paramètre <span class="math inline">\(p\)</span>.</p>
<p>Notons <span class="math inline">\(P_n\)</span> la <em>fréquence empirique</em> du nombre de succès parmi les <span class="math inline">\(n\)</span> épreuves:</p>
<p><span class="math display">\[P_n= \frac{X}{n}\]</span></p>
<div class="rmdinsight">
<p><span class="math inline">\(P_n = \overline{X}_n\)</span> car <span class="math inline">\(X\)</span> est la somme de <span class="math inline">\(n\)</span> variables indépendantes de Bernoulli de paramètre <span class="math inline">\(p\)</span>.</p>
</div>
<p><span class="math inline">\(P_n\)</span> a pour espérance et pour variance:</p>
<p><span class="math display">\[E(P_n) = p \quad \quad \text{et} \quad \quad V(P_n) = \frac{p(1-p)}{n}\]</span></p>
<p>En appliquant le théorème central limite à <span class="math inline">\(X\)</span> somme des variables de Bernoulli:</p>
<p><span class="math display">\[ \text{Pour } n \text{ suffisamment grand, on peut considérer que } P_n \text{ suit la loi normale :}\]</span>
<span class="math display">\[P_n \thicksim \mathcal{N}\bigg(p, {\frac{p(1-p)}{n}}\bigg)\]</span></p>
<p>Ce résultat est une autre formulation du théorème de “De Moivre-Laplace” (<a href="./variables-al%C3%A9atoires-continues.html#approximation-normale-dune-r%C3%A9partition-binomiale" target="_blank">lien</a>).</p>
</div>
<div id="etude-de-la-statistique-s2" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Etude de la statistique <span class="math inline">\(S^2\)</span><a href="echantillonnage-et-theoremes-limites.html#etude-de-la-statistique-s2" class="anchor-section" aria-label="Anchor link to header"></a></h2>

<div class="definition">
<span id="def:unnamed-chunk-61" class="definition"><strong>Définition 2.4  \iffalse (Variance empirique) </strong></span>La statistique <span class="math inline">\(S_n^2\)</span> ou variance empirique d’échantillon est définie par:
<span class="math display">\[S_n^{2}=\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\overline{X}_n\right)^{2}\]</span>
</div>
<p><strong>Propriétés:</strong></p>
<ul>
<li><span class="math inline">\(S_n^{2}=\frac{1}{n} \big(\sum_{i=1}^{n}X_{i}^2\big)-\big(\overline{X}_n\big)^{2}\)</span>.</li>
<li><span class="math inline">\(S_n^{2}=\frac{1}{n} \sum_{i=1}^{n}\big(X_{i}-m\big)^2-\big(\overline{X}_n-m\big)^{2}\)</span>.</li>
<li><span class="math inline">\(S_n^{2} \text{ converge presque sûrement vers } \sigma^2\)</span>.</li>
</ul>
<p><strong>Espérance de <span class="math inline">\(S_n^{2}\)</span>:</strong></p>
<ul>
<li>L’espérance de <span class="math inline">\(S_n^{2}\)</span> est:</li>
</ul>
<p><span class="math display">\[E(S_n^{2}) = \frac{n-1}{n}\sigma^2\]</span></p>
<p><em>démonstration</em>:</p>
<p><span class="math display">\[\begin{align}
E(S_n^{2}) &amp; =\frac{1}{n} \sum_{i=1}^{n}E\big(X_{i}-m\big)^2-E\big(\overline{X}_n-m\big)^{2} \\
           &amp; =  \frac{1}{n} \sum_{i=1}^{n}V(X_i)-V(\overline{X}_n) \\
           &amp; = \frac{1}{n} \sum_{i=1}^{n}\sigma^2- \frac{\sigma^2}{n} = \sigma^2- \frac{\sigma^2}{n} = \frac{n-1}{n} \sigma^2
\end{align}\]</span></p>
<div class="rmdinsight">
<p>On peut remarquer que si on pose: <span class="math inline">\({S_n^{*}}^2 = \frac{n}{n-1}S_n^2\)</span> alors <span class="math inline">\(E({S_n^{*}}^2) = \sigma^2\)</span>.</p>
</div>
<!-- ## Echantillons Gaussiens -->
<!-- Dans ce paragraphe, on considère que la variable $X$ (la variante parente, de la population) suit une loi normale de moyenne $m$ et d'écart-type $\sigma$. -->
<!-- $$ X \thicksim \mathcal{N}(m,\sigma^2)$$ -->
<!-- Soit $(X_1,\ldots,X_n)$ un échantillon aléatoire de $X$. -->
</div>
<div id="intro-estimation" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Introduction à l’estimation<a href="echantillonnage-et-theoremes-limites.html#intro-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>On appelle estimation, la procédure d’utilisation des informations obtenues à partir d’un échantillon qui permet de déduire des résultats concernant l’ensemble de la population.</p>
<div class="rmdcaution">
<p>Dans ce cours, les estimations sont calculées à partir d’un échantillonnage aléatoire simple et avec remise, càd tous les individus de la population ont une probabilité égale de faire partie de l’échantillon et qu’un individu peut être choisi plus d’une fois.</p>
</div>
<p>La statistique inconnue d’une population, à estimer à partir d’un échantillon, est appelée un
paramètre. Souvent le paramètre à estimer est une moyenne, un total, une proportion, un
écart-type ou une variance.
Le <em>paramètre</em> de la population est estimé à partir d’une <em>estimation</em> elle même calculée à partir des
données d’un échantillon.</p>
<p>Le tableau ci dessous illustre les différents symboles souvent utilisés.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Paramètres population
</th>
<th style="text-align:left;">
Estimations calculées sur un échantillon de taille <span class="math inline">\(n\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<strong>Moyenne</strong>
</td>
<td style="text-align:left;">
<span class="math inline">\(m\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(\overline{X}_n=\hat{m}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<strong>Ecart-type</strong>
</td>
<td style="text-align:left;">
<span class="math inline">\(\sigma\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(S_n=\hat{\sigma}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<strong>Variance</strong>
</td>
<td style="text-align:left;">
<span class="math inline">\(\sigma^2\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(S_n^2=\hat{\sigma}^2\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
<strong>Proportion</strong>
</td>
<td style="text-align:left;">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(P_n=\hat{p}\)</span>
</td>
</tr>
</tbody>
</table>
<div class="rmdtip">
<p>On dit que <span class="math inline">\(\overline{X}_n\)</span> est un estimateur de <span class="math inline">\(m\)</span>. La valeur obtenue est une estimation de <span class="math inline">\(m\)</span>, qu’on appelle <span class="math inline">\(\hat{m}\)</span>.</p>
</div>
<div class="rmdinsight">
<p>Les estimateurs sont des variables aléatoires et les estimations sont les valeurs
observées des estimateurs (i.e des variables aléatoires).</p>
</div>
<p>Dans ce chapitre nous avons introduit des estimateurs de la moyenne, la variance et la proportion. Nous avons aussi étudié les lois de ces estimateurs. Dans le chapitre suivant, nous allons étudier la théorie de l’estimation ponctuelle et la recherche d’un estimateur.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tp-statistique-descriptive-avec-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exercices-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"plugins": "copy-code-button"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
