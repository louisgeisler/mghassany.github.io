[
["index.html", "Statistique Inférentielle Overview Plan du cours", " Statistique Inférentielle Mohamad Ghassany 2019-10-23 Overview Ce document est dédié pour le cours de Statistique Inférentielle destiné aux étudiants en année 3 de l’École supérieure d’ingénieurs Léonard-de-Vinci. Plan du cours Séance Contenu Séance 1 Statistique descriptive, TP Prise en main sur R Séance 2 Echantillonage, Théorèmes limites, lois des \\(\\overline{X}_n, S_n^2\\) et \\(P_n\\), TP sur l’illustration des théorèmes limites Séance 3 Estimation ponctuelle et recherche d’estimateur, Méthode des moments, Méthode du maximum de vraissemblance Séance 4 Séance de TP: Suite du TP sur les théorèmes limites, TP sur l’estimation ponctuelle Contrôle continu Samedi le 30 novembre 2019 Séance 5 Estimation par Intervalle de Confiance Séance 6 Tests d’Hypothèses Séance 7 Séance 8 Séance 9 Examen Semaine du 20 janvier 2020 "],
["introduction.html", "Introduction", " Introduction La statistique est la science dont l’objet est de recueillir, de traiter et d’analyser des données issues de l’observation de phénomènes aléatoires, c’est-à-dire dans lesquels le hasard intervient. L’analyse des données est utilisée pour décrire les phénomènes étudiés, faire des prévisions et prendre des décisions à leur sujet. En cela, la statistique est un outil essentiel pour la compréhension et la gestion des phénomènes complexes. Les données étudiées peuvent être de toute nature, ce qui rend la statistique utile dans tous les champs disciplinaires et explique pourquoi elle est enseignée dans toutes les filières universitaires, de l’économie à la biologie en passant par la psychologie, et bien sûr les sciences de l’ingénieur. Le point fondamental est que les données sont entâchées d’incertitudes et présentent des variations pour plusieurs raisons : le déroulement des phénomènes observés n’est pas prévisible à l’avance avec certitude (par exemple on ne sait pas prévoir avec certitude les cours de la bourse ou les pannes des voitures) toute mesure est entâchée d’erreur etc… Il y a donc intervention du hasard et des probabilités. L’objectif essentiel de la statistique est de maîtriser au mieux cette incertitude pour extraire des informations utiles des données, par l’intermédiaire de l’analyse des variations dans les observations. Les méthodes statistiques se répartissent en deux classes : La statistique descriptive, statistique exploratoire ou analyse des données, a pour but de résumer l’information contenue dans les données de façon synthétique et efficace. Elle utilise pour cela des représentations de données sous forme de graphiques, de tableaux et d’indicateurs numériques (par exemple des moyennes). Elle permet de dégager les caractéristiques essentielles du phénomène étudié et de suggérer des hypothèses pour une étude ultérieure plus sophistiquée. Les probabilités n’ont ici qu’un rôle mineur. La statistique inférentielle va au delà de la simple description des données. Elle a pour but de faire des prévisions et de prendre des décisions au vu des observations. En général, il faut pour cela proposer des modèles probabilistes du phénomène aléatoire étudié et savoir gérer les risques d’erreurs. Les probabilités jouent ici un rôle fondamental. Pour le grand public, les statistiques désignent les résumés de données fournis par la statistique descriptive. Par exemple, on parle des “statistiques du chômage” ou des “statistiques de l’économie américaine”. Mais on oublie en général les aspects les plus importants liés aux prévisions et à l’aide à la décision apportés par la statistique inférentielle. L’informatique et la statistique sont deux éléments du traitement de l’information : l’informatique acquiert et traite l’information tandis que la statistique l’analyse. Les deux disciplines sont donc étroitement liées. En particulier, l’augmentation considérable de la puissance des ordinateurs et la facilité de transmission des données par internet ont rendu possible l’analyse de très grandes masses de données, ce qui nécessite l’utilisation de méthodes de plus en plus sophistiquées, connues sous le nom de data mining, fouille de données ou Big Data. Enfin, l’informatique décisionnelle ou business intelligence regroupe les outils d’aide à la décision devenus essentiels dans la gestion des entreprises. Ces outils nécessitent un recours important aux méthodes statistiques. Plus généralement, tout ingénieur est amené à prendre des décisions au vu de certaines informations, dans des contextes où de nombreuses incertitudes demeurent. Il importe donc qu’un ingénieur soit formé aux techniques de gestion du risque et de traitement de données expérimentales. Aujourd’hui, les statistiques sont partout. Les statistiques descriptives sont présentées dans tous les journaux et magazines. L’inférence statistique est devenue indispensable au santé public et la recherche médicale, à l’ingénierie et les études scientifiques, à la commercialisation et l’éducation, la comptabilité, l’économie, les prévisions météorologiques, les sondages, aux sports, à l’assurance, et à toutes les recherches scientifiques. Les statistiques sont en effet enracinées dans notre patrimoine intellectuel. La démarche statistique La statistique et les probabilités sont les deux aspects complémentaires de l’étude des phénomènes aléatoires. Ils sont cependant de natures bien différentes. Les probabilités peuvent être envisagées comme une branche des mathématiques pures, basée sur la théorie de la mesure, abstraite et complètement déconnectée de la réalité. Les probabilités appliquées proposent des modèles probabilistes du déroulement de phénomènes aléatoires concrets. On peut alors, préalablement à toute expérience, faire des prévisions sur ce qui va se produire. Par exemple, il est usuel de modéliser la durée de bon fonctionnement ou durée de vie d’un système, mettons une ampoule électrique, par une variable aléatoire \\(X\\) de loi exponentielle de paramètre \\(\\lambda\\). Ayant adopté ce modèle probabiliste, on peut effectuer tous les calculs que l’on veut. Par exemple : La probabilité que l’ampoule ne soit pas encore tombée en panne à la date \\(t\\) est \\(P(X &gt; t) = e^{−\\lambda t}\\) . La durée de vie moyenne est \\(E(X) = 1/\\lambda\\). Si \\(n\\) ampoules identiques sont mises en fonctionnement en même temps, et qu’elles fonctionnent indépendamment les unes des autres, le nombre \\(N_t\\) d’ampoules qui tomberont en panne avant un instant \\(t\\) est une variable aléatoire de loi binomiale \\(\\mathcal{B}(n,P(X ≤ t)) = \\mathcal{B}(n,1 − e^{-\\lambda t})\\). Donc on s’attend à ce que, en moyenne, \\(E(N_t) = n(1 − e^{-\\lambda t})\\) ampoules tombent en panne entre 0 et \\(t\\) Dans la pratique, l’utilisateur de ces ampoules est très intéressé par ces résultats. Il souhaite évidemment avoir une évaluation de leur durée de vie, de la probabilité qu’elles fonctionnent correctement pendant plus d’un mois, un an, etc… Mais si l’on veut utiliser les résultats théoriques énoncés plus haut, il faut d’une part pouvoir s’assurer qu’on a choisi un bon modèle, c’est-à-dire que la durée de vie de ces ampoules est bien une variable aléatoire de loi exponentielle, et, d’autre part, pouvoir calculer d’une manière ou d’une autre la valeur du paramètre \\(\\lambda\\). C’est la statistique qui va permettre de résoudre ces problèmes. Pour cela, il faut faire une expérimentation, recueillir des données et les analyser. On met donc en place ce qu’on appelle un essai ou une expérience. On fait fonctionner en parallèle et indépendamment les unes des autres \\(n = 10\\) ampoules identiques, dans les mêmes conditions expérimentales, et on relève leurs durées de vie. Admettons que l’on obtienne les durées de vie suivantes, exprimées en heures : 91.6 35.7 251 24.3 5.4 67.3 171 9.5 118 57.1 Notons \\(x_1 ,\\ldots,x_n\\) ces observations. Il est bien évident que la durée de vie des ampoules n’est pas prévisible avec certitude à l’avance. On va donc considérer que \\(x_1 ,\\ldots,x_n\\) sont les réalisations de variables aléatoires \\(X_1 ,\\ldots,X_n\\). Cela signifie qu’avant l’expérience, la durée de vie de la \\(i^{\\text{ème}}\\) ampoule est inconnue et que l’on traduit cette incertitude en modélisant cette durée par une variable aléatoire \\(X_i\\). Mais après l’expérience, la durée de vie a été observée. Il n’y a donc plus d’incertitude, cette durée est égale au réel \\(x_i\\). On dit que \\(x_i\\) est la réalisation de \\(X_i\\) sur l’essai effectué. Puisque les ampoules sont identiques, il est naturel de supposer que les \\(X_i\\) sont de même loi. Cela signifie qu’on observe plusieurs fois le même phénomène aléatoire. Mais le hasard fait que les réalisations de ces variables aléatoires de même loi sont différentes, d’où la variabilité dans les données. Puisque les ampoules ont fonctionné indépendamment les unes des autres, on pourra également supposer que les \\(X_i\\) sont des variables aléatoires indépendantes. On peut alors se poser les questions suivantes : Au vu de ces observations, est-il raisonnable de supposer que la durée de vie d’une ampoule est une variable aléatoire de loi exponentielle? Si non, quelle autre loi serait plus appropriée? C’est un problème de choix de modèle ou de test d’adéquation. Si le modèle de loi exponentielle a été retenu, comment proposer une valeur (ou un ensemble de valeurs) vraisemblable pour le paramètre \\(\\lambda\\)? C’est un problème d’estimation paramétrique. Dans ce cas, peut-on garantir que \\(\\lambda\\) est inférieur à une valeur fixée \\(\\lambda_0\\) ? Cela garantira alors que \\(E(X) = 1/\\lambda \\geq 1/\\lambda_0\\), autrement dit que les ampoules seront suffisamment fiables. C’est un problème de test d’hypothèses paramétriques. Sur un parc de 100 ampoules, à combien de pannes peut-on s’attendre en moins de 50 h? C’est un problème de prévision. Le premier problème central est celui de l’estimation : comment proposer, au vu des observations, une approximation des grandeurs inconnues du problème qui soit la plus proche possible de la réalité? La première question peut se traiter en estimant la fonction de répartition ou la densité de la loi de probabilité sous-jacente, la seconde revient à estimer un paramètre de cette loi, la troisième à estimer un nombre moyen de pannes sur une période donnée. Le second problème central est celui des tests d’hypothèses : il s’agit de se prononcer sur la validité d’une hypothèse liée au problème : la loi est-elle exponentielle? \\(\\lambda\\) est-il inférieur à \\(\\lambda_0\\)? un objectif de fiabilité est-il atteint? En répondant oui ou non à ces questions, il est possible que l’on se trompe. Donc, à toute réponse statistique, il faudra associer le degré de confiance que l’on peut accorder à cette réponse. C’est une caractéristique importante de la statistique par rapport aux mathématiques classiques, pour lesquelles un résultat est soit juste, soit faux. Pour résumer, la démarche probabiliste suppose que la nature du hasard est connue. Cela signifie que l’on adopte un modèle probabiliste particulier (ici la loi exponentielle), qui permettra d’effectuer des prévisions sur les observations futures. Dans la pratique, la nature du hasard est inconnue. La statistique va, au vu des observations, formuler des hypothèses sur la nature du phénomène aléatoire étudié. Maîtriser au mieux cette incertitude permettra de traiter les données disponibles. Probabilités et statistiques agissent donc en aller-retour dans le traitement mathématique des phénomènes aléatoires. L’exemple des ampoules est une illustration du cas le plus fréquent où les données se présentent sous la forme d’une suite de nombres. C’est ce cas que nous traiterons dans ce cours, mais il faut savoir que les données peuvent être beaucoup plus complexes : des fonctions, des images, etc… Les principes et méthodes généraux que nous traiterons dans ce cours seront adaptables à tous les types de données. Objectifs et plan du cours Ce cours a pour but de présenter les principes de base d’une analyse statistique de données (description, estimation, tests), ainsi que les méthodes statistiques les plus usuelles. Ces méthodes seront toujours illustrées par des problèmes concrets. Le cours privilégie l’application à la théorie. Les méthodes présentées seront mises en œuvre à l’aide du logiciel (https://www.r-project.org). Le premier chapitre présente les techniques de base en statistique descriptive, représentations graphiques et indicateurs statistiques. Le chapitre suivant introduit l’échantillonnage et les théorèmes limites avec une étude des statistiques \\(\\overline{X}_n\\) et \\(S^2\\). Le chapitre 3 est consacré aux problèmes d’estima tion paramétrique ponctuelle, le chapitre 4 aux intervalles de confiance et le chapitre 5 aux tests d’hypothèses. Enfin, des annexes donnent quelques rappels de probabilités utiles en statistique et des tables des lois de probabilité usuelles. "],
["statistique-descriptive.html", "Chapitre 1 Statistique descriptive 1.1 Terminologie 1.2 Statistique et Probabilités 1.3 Description d’une série de valeurs 1.4 Représentations graphiques 1.5 Indicateurs statistiques 1.6 Statistique descriptive bidimensionnelle", " Chapitre 1 Statistique descriptive La statistique descriptive a pour but de résumer l’information contenue dans les données de façon à en dégager les caratéristiques essentielles sous une forme simple et intelligible. Les deux principaux outils de la statistique descriptive sont les représentations graphiques et les indicateurs statistiques. Il ne faut pas confondre la statistique qui est la science qui vient d’être définie et une statistique qui est un ensemble de données chiffrées sur un sujet précis. 1.1 Terminologie Les premières statistiques correctement élaborées ont été celles des recensements démographiques. Ainsi le vocabulaire statistique est essentiellement celui de la démographie. Les ensembles étudiés sont appelés population. Les éléments de la population sont appelés individus ou unités statistiques. La population est étudiée selon une ou plusieurs variables (ou caractères). L’ensemble des individus constitue l’échantillon étudié. Exemple: si l’échantillon est un groupe de TD à l’ESILV, Un individu est un étudiant. La population peut être l’ensemble des étudiants de l’ESILV, des élèves ingénieur de France, etc.. Les variables étudiées peuvent être la taille, la filière choisie, la moyenne d’année, la couleur des yeux, etc.. Si l’échantillon est constitué de tous les individus de la population, on dit que l’on fait un recensement. Il est extrêmement rare que l’on se trouve dans cette situation. Quand l’échantillon n’est qu’une partie de la population, on parle de sondage. Le principe des sondages est d’étendre à l’ensemble de la population les enseignements tirés de l’étude de l’échantillon. Pour que les résultats observés lors d’une étude soient généralisables à la population statistique, l’échantillon doit être représentatif de cette dernière, c’est à dire qu’il doit refléter fidèlement sa composition et sa complexité. Seul l’échantillonnage aléatoire assure la représentativité de l’échantillon. Il existe des méthodes pour y parvenir, dont nous ne parlerons pas ici. Un échantillon est qualifié d’aléatoire lorsque chaque individu de la population a une probabilité connue et non nulle d’appartenir à l’échantillon. Le cas particulier le plus connu est celui qui affecte à chaque individu la même probabilité d’appartenir à l’échantillon. Définition 1.1 (Echantillonnage aléatoire simple) L’échantillonnage aléatoire simple est une méthode qui consiste à prélever au hasard et de façon indépendante, \\(n\\) individus ou unités d’échantillonnage d’une population à \\(N\\) individus. Chaque individu possède ainsi la même probabilité de faire partie d’un échantillon de \\(n\\) individus et chacun des échantillons possibles de taille \\(n\\) possède la même probabilité d’être constitué. 1.2 Statistique et Probabilités Les concepts qui viennent d’être présentés sont les homologues de concepts du calcul des probabilités et il est possible de disposer en regard les concepts homologues (voir table ci-dessous). Probabilités Statistique Espace fondamental Population Epreuve Tirage (d’un individu), expérimentation Evènement élémentaire Individu, observation Variable aléatoire Variable (Caractère) Epreuves répétées Echantillonnage Nbre de répétitions d’une épreuve Taille de l’échantillon, effectif total Probabilité Fréquence observée Loi de probabilité Distribution observée ou loi empirique Espérance mathématique Moyenne observée Variance Variance observée Le mot “variable” désigne à la fois la grandeur que l’on veut étudier (variable statistique) et l’objet mathématique qui la représente (variable aléatoire). Ainsi la notion de variable se confond avec celle de variable aléatoire. Une variable statistique peut être discrète ou continue, qualitative ou quantitative. Les méthodes de représentation des données diffèrent suivant la nature des variables étudiées. 1.3 Description d’une série de valeurs On considère ici une série (un ensemble) de valeurs, numériques, ou non, homogènes en ce sens qu’elles se réfèrent à une même variable et qu’elles ne sont pas structurées en sous-ensembles. Chaque valeur est associée à un individu statistique (unité statistique, observation). C’est le cas, par exemple, des notes obtenus par une promotion d’élèves à un examen. Dans cet exemple, lorsqu’il y a plusieurs examens, on peut vouloir considérer ensemble les notes d’un même élève. Les notes sont alors structurées en sous-ensembles et les méthodes à utiliser diffèrent de celles présentées ici. Pour décrire une telle série, l’examen direct des valeurs n’est pas commode dès lors que ces valeurs sont un tant soit peu nombreuses. Pour cela, la statistique propose deux types d’outils : des graphiques et des indicateurs statistiques. 1.4 Représentations graphiques Face à un problème particulier, on peut chercher à construire un graphique ad hoc. Mais, la plupart du temps, on utilise des graphiques standard dont la nature diffère selon le type de la variable étudiée. 1.4.1 Variable qualitative Les valeurs que peut prendre une variable qualitative \\(X\\) (ex: couleur) constituent un ensemble de \\(M\\) modalités: {exemple: 1= bleu; 2=blanc; … ; M=rouge}; une telle série présente une apparence numérique mais on ne peut faire de calcul sur ces nombres (dans l’exemple, blanc n’est pas égale à deux fois bleu). Autres exemples: catégorie socio-professionnelle, genre, région d’appartenance, etc. Données On a “mesuré” une variable qualitative sur \\(n\\) individus. Les données brutes sont constituées par la série des \\(n\\) valeurs \\(\\{x_i; i=1,\\ldots,n\\}\\) avec \\(x_i\\) le numéro de la modalité pour l’individu \\(i\\), \\(x_i \\in 1,\\ldots,M\\). Il est commode d’agréger ces données en comptant le nombre d’individus \\(n_m\\) possédant la modalité \\(m\\). \\(n_m\\) est un effectif, ou une fréquence absolue (par opposition à la fréquence relative \\(n_m/n\\)) Table 1.1: Variable qualitative: données brutes (gauche) et agrégées (droite). \\(n_m\\) nombre d’individus possédant la modalité \\(m\\) n°ind. \\(X\\) \\(1\\) \\(x_1\\) \\(\\vdots\\) \\(\\vdots\\) \\(i\\) \\(x_i\\) \\(\\vdots\\) \\(\\vdots\\) \\(n\\) \\(x_n\\) modalité effectif \\(1\\) \\(n_1\\) \\(\\vdots\\) \\(\\vdots\\) \\(m\\) \\(n_m\\) \\(\\vdots\\) \\(\\vdots\\) \\(M\\) \\(n_M\\) Diagramme en bâtons (barplot) Il représente les données agrégées (groupées). Les modalités figurent en abscisse; la longueur d’un bâton le long de l’ordonnée est proportionnelle à l’effectif (ou à la fréquence). Il est utile de trier les modalités, généralement par fréquence décroissante. Figure 1.1: Diagramme en bâtons L’ordre doit être respecté pour une variable ordinale. Quand il s’agit d’une variable nominale, il est préférable d’ordonner les modalités par effectifs croissants ou décroissant pour rendre le graphique plus lisible. Attention à ne pas confondre cette représentation avec un histogramme (cas de variable continue). Diagrammes circulaires (pie chart) Le fameux “camembert” n’est commode que s’il y a peu de modalités. Ici encore, il est commode de trier les modalités par effectifs décroissants. Figure 1.2: Diagramme circulaire de la variable “couleur des yeux” 1.4.2 Variable quantitative Cas de variable quantitative discrète La distribution de \\(X\\) est fournie par le tableau des fréquences qui fait correspondre aux différentes valeurs (modalités) de la variable. Soit l’exemple suivant de nombre de personnes par ménage pour les 10 ménages suivants: 2 3 3 3 4 5 5 5 5 6 On peut représenter la série avec un diagramme en bâtons (vertical ou horizontal). Figure 1.3: Le nombre de personnes par ménage Cas de variable quantitative continue Pour la visualisation d’une série numérique, l’outil de base est l’histogramme, outil qui ressemble à un diagramme en bâtons mais qui doit en être distingué. Il repose sur une subdivision de la plage de variation de \\(X\\) en intervalles; pour chaque intervalle \\([a,b[\\) on compte le nombre d’individus tels que \\(X \\in [a,b[\\), nombre dit effectif de l’intervalle. Dans l’histogramme, les intervalles sont représentés sur l’axe des abscisses. Au-dessus de chaque intervalle, on dessine un rectangle dont la surface est proportionnelle à son effectif. La base étant la longueur de l’intervalle, la hauteur de chaque rectangle s’interprète comme une densité (effectif par unité de longueur). Table 1.2: Variable quantitative: données brutes (gauche) et agrégées (droite). n°ind. \\(X\\) \\(1\\) \\(x_1\\) \\(\\vdots\\) \\(\\vdots\\) \\(i\\) \\(x_i\\) \\(\\vdots\\) \\(\\vdots\\) \\(n\\) \\(x_n\\) intervalle effectif \\(1\\) \\(n_1\\) \\(\\vdots\\) \\(\\vdots\\) \\([a,b[\\) \\(n_{[a,b[}\\) \\(\\vdots\\) \\(\\vdots\\) \\(M\\) \\(n_M\\) Le nombre de classes doit être choisi de façon à ce que l’effectif moyen par intervalle soit suffisamment grand afin de pas être gêné par des irrégularités locales et, au contraire, afin de mettre en évidence une tendance générale. Soit l’exemple suivant: on s’intéresse à la taille de 237 étudiants1. L’idée de représenter en ordonnée la densité (et non l’effectif) permet de prendre en compte des intervalles de longueurs inégales, ce qui peut être nécessaire pour les intervalles extrêmes. Celà permet aussi de présenter la distribution de l’échantillon. Dans la figure précédente, nous avons utilisé des effectifs (fréquences absolues), on préfère généralement utiliser des fréquences relativespour pouvoir superposer facilement des distributions de référence. Une autre graphique à base des quartiles est la boîte à dispersion ou boîte à moustaches (boxplot). Un rectangle, délimité par les premier et troisième quartiles, représente \\(50\\%\\) de la population. Dans ce rectangle, une barre centrale représente la médiane. De part et d’autre du rectangle, on figure deux segments dont la longueur est environ 1.5 fois l’écart interquartile: “environ” car chaque segment est en fait délimité par une observation réelle incluse dans cet intervalle, celle qui est la plus éloignée de la médiane. Enfin, les observations au-delà de ces limites sont représentées individuellement. Figure 1.4: Boîte à moustaches de Rythme cardiaque de 237 étudiants 1.5 Indicateurs statistiques Les représentations graphiques présentées dans la section précédente ne permettent qu’une analyse visuelle de la répartition des données. Pour des variables quantitatives, il est intéressant de donner des indicateurs numériques permettant de caractériser au mieux ces données. On donne en général deux indicateurs : un indicateur de tendance centrale (ou de localisation) et un indicateur de dispersion: L’ordre de grandeur des observations situées au centre de la distribution: c’est la tendance centrale. La “largeur” de la série, c’est-à-dire la plus ou moins grande fluctuation des observations autour de la tendance centrale : c’est la dispersion. 1.5.1 Tendance centrale Les mesures de tendance centrale permettent d’obtenir une idée juste de l’ordre de grandeur des valeurs ainsi que de la valeur centrale de la caractéristique que l’on désire étudier. Les trois principaux indicateurs de tendance centrale sont: Le Mode. La Moyenne. La Médiane. Le Mode empirique Le mode d’une distribution statistique, noté \\(M_o\\), est la modalité de variable la plus représentée dans la distribution. Également appelé “valeur dominante” de la distribution. Il correspond au sommet de la distribution: le mode est la valeur la plus fréquente La Moyenne empirique La moyenne empirique de l’échantillon est la moyenne arithmétique des observations. Cet indicateur, noté \\(\\overline{x}\\), est le plus utilisé. Le calcul de la moyenne dépends de la représentation des données: Si les données statistiques sont exploitées en série (données individuelles): \\[ \\overline{x}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i} \\] Exemple: Les notes d’un étudiant dans 7 matières sont: 18 16 15 14 12 17 11 La note moyenne est donc \\[ \\overline{x}=\\frac{18+16+15+14+12+17+11}{7}=14.71 \\] Si les données statistiques sont groupées par modalités, \\(n_i\\) étant l’effectif correspondant à la modalité \\(x_i\\) : \\[ \\overline{x}=\\frac{1}{n} \\sum_{i=1}^{p} n_{i} x_{i} \\] Exemple: Soit les notes obtenues par un élève au baccalauréat: \\(x_i\\) \\(n_i\\) 4 2 8 3 16 2 13 3 5 2 Total 12 La moyenne empirique pondérée de cet élève au baccalauréat est: \\[ \\overline{x}=\\frac{(4 \\times 2)+(8 \\times 3)+(16 \\times 2)+(13 \\times 3)+(5 \\times 2)}{12}=\\frac{113}{12}=9.42 \\] La Médiane empirique On appelle “médiane” d’une distribution statistique, notée \\(M_e\\) , la valeur de la variable qui partage en deux groupes d’effectif identique les observations classées par ordre croissant. Il y a 50% des observations qui sont inférieures ou égales à la médiane et 50% des observations qui sont supérieures ou égales à la médiane. L’avantage principal de la médiane, par rapport à la moyenne arithmétique, est qu’elle n’est pas indûment influencée par quelques données extrêmes. Si l’on considère les \\(x_i\\) rangés par ordre croissant la médiane est définie par: \\[\\begin{align} M_e = x_{(n+1)/2} \\quad &amp;\\text{si}\\quad n \\quad\\text{impair}\\\\ M_e = \\frac{x_{n/2}+x_{(n/2)+1}}{2} \\quad &amp;\\text{si}\\quad n \\quad\\text{pair} \\end{align}\\] 1.5.2 Dispersion (variabilité) Après celle relative à la tendance centrale, la deuxième question que l’on se pose à propos d’une série numérique est celle de sa dispersion (souvent sous-entendu “autour de la tendance centrale”). Exemples: Un patient apprend de son médecin que sa pression intra-oculaire est de 19. La pression moyenne pour ceux de son âge et de son sexe est de 17. Que peut-il conclure? Ce n’est pas nécessairement inquiétant: les données d’une population sont presque toutes distinctes de la moyenne. Mais s’écarte-t-il trop de la moyenne? De combien les autres membres de la population s’écartent de la moyenne? La température moyenne à Montréal est de 6.9°C. Ceci n’empêche pas la température de baisser à -35°C en hiver et de monter à +35°C en été. On va définir: L’étendue. La variance et l’écart-type. Etendue (amplitude) empirique C’est la différence entre les valeurs maximum et minimum, soit, les valeurs ayant été classées par ordre croissant : \\(x_n-x_1\\). Historiquement, c’est le critère le plus ancien (employé par les Grecs pour leurs mesure astronomiques). Il est utilisé lorsque l’on ne s’intéresse pas en détail à la dispersion : par exemple, on dira que le temps de trajet en TGV entre Rennes et Paris est compris entre 2h05 (train direct) et 2h25 (quelques arrêts). Variance et Ecart-type empiriques La variance et sa racine l’écart-type sont les indicateurs de dispersion utilisés de manière standard. La variance (noté usuellement \\(s^2\\) pour une série de valeurs observées, \\(\\sigma^2\\) pour une distribution théorique et \\(V(X)\\) pour une variable aléatoire), est la moyenne des carrés des écarts à la moyenne. Soit, pour une série numérique: \\[ s^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\overline{x}\\right)^{2} \\] Par rapport à la variance, l’intérêt de l’écart-type est qu’il s’exprime dans les mêmes unités que les valeurs étudiées. Cependant, la variabilité doit toujours se comparer à la valeur moyenne. Des données présentent une forte variabilité si l’écart-type est grand par rapport à la moyenne. Aussi on définit le coefficient de variation empirique de l’échantillon par \\[ cv_{n}=\\frac{s_{n}}{\\overline{x}_{n}} \\] L’intérêt de cet indicateur est qu’il est sans dimension. Une pratique empirique courante est de considérer que l’échantillon possède une variabilité significative si \\(cv_{n} &gt; 0.15\\). Si \\(cv_{n} \\leq 0.15\\), les données présentent peu de variabilité et on considère que la moyenne empirique à elle seule est un bon résumé de tout l’échantillon. En , la commande var(x) donne \\(s*^2 = \\frac{n}{n-1}s^2\\) au lieu de \\(s^2\\). C’est aussi ce que l’on a sur les calculatrices dotées de fonctionnalités statistiques. On en verra l’explication au chapitre Estimation. De même \\(s*=\\sqrt{s*^2}\\) est donné en par sd(x) (standard deviation). \\(s_{n}^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-\\overline{x}_{n}\\right)^{2}=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}^{2}-\\overline{x}_{n}^{2}\\) évoque \\(\\operatorname{Var}(X)=E\\left[(X-E(X))^{2}\\right]=E\\left(X^{2}\\right)-[E(X)]^{2}\\). En finance, la variabilité d’une série de données est appelée volatilité. L’étude de la volatilité est fondamentale dans les analyses de risque financier. 1.6 Statistique descriptive bidimensionnelle Dans cette section, on sintérese a l’étude simultanée de deux variables \\(X\\) et \\(Y\\), étudiées sur le même échantillon, toujours noté \\(\\Omega\\). L’objectif essentiel des méthodes présentées est de mettre en évidence une éventuelle variation simultanée des deux variables, que nous appellerons alors liaison. Dans certains cas, cette liaison peut être considérée a priori comme causale, une variable \\(X\\) expliquant l’autre \\(Y\\); dans d’autres, ce n’est pas le cas, et les deux variables jouent des rôles symétriques. Dans la pratique, il conviendra de bien différencier les deux situations et une liaison n’entraîne pas nécessairement une causalité. Les données sont présentées de la façon suivante: on dispose de deux séries \\(X\\) et \\(Y\\) représentant l’observation des variables \\(X\\) et \\(Y\\) sur les mêmes \\(n\\) individus: on a une série bidimensionnelle \\((X,Y)\\) de taille \\(n\\): individu \\(X\\) \\(Y\\) \\(1\\) \\(x_1\\) \\(y_1\\) \\(2\\) \\(x_2\\) \\(y_2\\) \\(\\ldots\\) \\(\\ldots\\) \\(\\ldots\\) \\(i\\) \\(x_i\\) \\(y_i\\) \\(\\ldots\\) \\(\\ldots\\) \\(\\ldots\\) \\(n\\) \\(x_n\\) \\(y_n\\) où \\(x_i\\) est la valeur de \\(X\\) et \\(y_i\\) celle de \\(Y\\) pour l’individu n° \\(i\\) de la série. Deux variables quantitatives Pour étudier la liaison entre deux variables quantitatives (discrètes), on commence par faire un graphique du type nuage de points (scatterplot). La forme générale de ce graphique indique s’ll existe ou non une liaison entre les deux variables. Il s’agit d’un graphique très commode pour représenter les observations simultanées de deux variables quantitatives. Figure 1.5: Exemple de nuage de points représentant la consommation de carburant en fonction du poids de voitures. L’exemple extrait du dataset mtcars dans R Le choix des échelles a retenir pour réaliser un nuage de points peut s’avérer délicat. D’une façon générale, on distinguera le cas de variables homogènes (représentant la même grandeur et exprimées dans la même unité) de celui des variables hétérogenes. Dans le premier cas, on choisira la même échelle sur les deux axes (qui seront donc orthonormés); dans le second cas, il est recommandé soit de représenter les variables centrées et réduites sur des axes orthonormés, soit de choisir des échelles telles que ce soit sensiblement ces variables là que l’on représente (c’est en genéral cette seconde solution qu’utilisent, de façon automatique, les logiciels statistiques). Rappel: variables centrées et réduites Si \\(X\\) est une variable quantitative de moyenne \\(\\overline{x}\\) et d’écart-type \\(\\sigma_{X},\\) on apelle variable centrée associée à \\(X\\) la variable \\(X-\\overline{x}\\) (elle est de moyenne nulle et d’écart-type \\(\\sigma_{X}\\)), et variable centrée et réduite (ou tout simplement variable réduite) associe à \\(X\\) la variable \\(\\frac{X-\\overline{x}}{\\sigma}\\) (elle est de moyene nulle et d’écart-type égal à un). Une variable centrée er réduite s’exprime sans unité. Coefficient de corrélation linéaire On appelle coefficient de corrélation linéaire de \\(X\\) et de \\(Y\\) la valeur définie par \\[\\rho = \\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{V(X)V(Y)}} = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}\\] Où \\(Cov(X,Y)\\) est la covariance de \\(X\\) et de \\(Y\\) la valeur si elle existe: \\[Cov(X,Y) = \\frac{1}{N} \\sum_{i=1}^N \\left( X_i - \\bar{X} \\right) \\left( Y_i - \\bar{Y} \\right)\\] On peut montrer que \\(-1 \\leq \\rho(X,Y) \\leq 1\\). Interprétation de \\(\\rho\\) Le coefficient de corrélation est une mesure du degré de linéarité entre \\(X\\) et \\(Y\\). Les valeurs de \\(\\rho\\) proches de \\(1\\) ou \\(-1\\) indiquent une linéarité quasiment rigoureuse entre \\(X\\) et \\(Y\\). Les valeurs de \\(\\rho\\) proche de 0 indiquent une absence de toute relation linéaire. Lorsque \\(\\rho(X,Y)\\) est positif, \\(Y\\) a tendance à augmenter si \\(X\\) en fait autant. Lorsque \\(\\rho(X,Y) &lt; 0\\), \\(Y\\) a tendance à diminuer si \\(X\\) augmente. Si \\(\\rho(X,Y) =0\\), on dit que ces deux statistiques sont non corrélées. Figure 1.6: Illustration de l’effet de la variation of the effect of varying the strength and direction of a correlation La corrélation mesure l’association, pas la causalité. Dans certains cas, une liaison peut être considérée a priori comme causale, une variable expliquant l’autre. Dans d’autres, ce n’est pas le cas et les deux variables jouent alors des rôles symétriques. Sur ce lien on trouve des exemples de variables associées linéairement mais non liées de manière causale. D’autre part, une corrélation nulle ne signifie pas que deux variables sont indépendantes. Voici quelques exemples: Figure 1.7: Exemples où la corrélation est presque nulle mais les variables ne sont pas indépendantes. Une variable quantitative et une qualitative On dispose d’une variable qualitative \\(X\\) à \\(p\\) modalités \\(m_{1}, \\ldots, m_{p}\\) et une variable quantitative \\(Y\\). On a alors \\(p\\) sous-populations déterminées par les \\(p\\) modalités de \\(X\\). L’étude de la liaison entre \\(X\\) et \\(Y\\) consiste en l’étude des différences entre ces sous-populations: il y aura absence de lien si on ne distingue pas de différence notoire dans les caractéristiques de ces différentes sous-populations. Une façon commode de représenter les données dans le cas de l’étude simultanée d’une variable quantitative et d’une variable qualitative consiste à réaliser des boîtes à moustaches parallèles. Les boîtes à moustaches permettent de comparer facilement des groupes d’individus, par exemple ici les garçons et les filles parmi 237 étudiants2: Figure 1.8: Boîtes à moustaches par sexe Deux variables qualitatives On considère dans ce paragraphe deux variables qualitatives observées simultanément sur \\(n\\) individus. On suppose que la première, notée \\(X,\\) possède \\(r\\) modalités notées \\(x_{1}, \\ldots, x_{\\ell}, \\ldots, x_{r},\\) et que la seconde, notée \\(Y,\\) possède \\(c\\) modalités notées \\(y_{1}, \\ldots, y_{h}, \\ldots, y_{c}\\). Ces données sont présentées dans un tableau à double entrée, appelé tables de contingence, dans lequel on dispose les modalités de \\(X\\) en lignes et celles de \\(Y\\) en colonnes. Ce tableau est donc de dimension \\(r \\times c\\) et a pour élément générique le nombre \\(n_{\\ell h}\\) d’observations conjointes des modalités \\(x_{\\ell}\\) de \\(X\\) et \\(y_{h}\\) de \\(Y ;\\) les quantités \\(n_{\\ell h}\\) sont appelées les effectifs conjoints. Une table de contingence se présente donc sous la forme suivante: \\(y_1\\) \\(\\ldots\\) \\(y_h\\) \\(\\ldots\\) \\(y_c\\) sommes \\(x_1\\) \\(n_{11}\\) \\(n_{1h}\\) \\(n_{1c}\\) \\(n_{1.}\\) \\(\\vdots\\) \\(x_{\\ell}\\) \\(n_{\\ell 1}\\) \\(n_{\\ell h}\\) \\(n_{\\ell c}\\) \\(n_{\\ell .}\\) \\(\\vdots\\) \\(x_r\\) \\(n_{r 1}\\) \\(n_{r h}\\) \\(n_{rc}\\) \\(n_{r.}\\) sommes \\(n_{.1}\\) \\(n_{.h}\\) \\(n_{.c}\\) \\(n\\) Les quantités \\(n_{\\ell .}(\\ell=1, \\ldots, r)\\) et \\(n_{.h}(h=1, \\ldots, c)\\) sont appelées les effectifs marginaux; ils sont définis par \\(n_{\\ell .}=\\sum_{h=1}^{c} n_{\\ell h}\\) et \\(n_{. h}=\\sum_{\\ell=1}^{r} n_{\\ell h}\\) et ils vérifient \\(\\sum_{\\ell=1}^{r} n_{\\ell.}=\\sum_{h=1}^{c} n_{.h}=n\\). De façon analogue, on peut définir les notions de fréquences conjointes et de fréquences marginales. On peut représenter graphiquement deux variables qualitatives avec des diagrammes en barre parallèles (mosaïcplots). Indices de liaison Lorsque tous les profis-lignes sont égaux, ce qui est équivalent à ce que tous les profil-colonnes soient égaux et que \\[ \\forall(\\ell, h) \\in\\{1, \\ldots, r\\} \\times\\{1, \\ldots, c\\} : n_{\\ell h}=\\frac{n_{\\ell .} n_{.h}}{n} \\] on dit qu’il n’exist aucune forme de liaison entre les deux variables considérées \\(X\\) et \\(Y .\\) Par suite, la mesure de la laison va se faire en évaluant l’écart entre la situation observée et l’état de non liaison défini ci-dessus. Khi-deux Il est courant en statistique de comparer une table de contingence observée, d’effectif conjoint générique \\(n_{\\ell h},\\) à une table de contingence donnée a priori (et appelée standard), d’effectif conjoint générique \\(s_{\\ell h},\\) en calculant la quantié \\[ \\sum_{\\ell=1}^{r} \\sum_{h=1}^{c} \\frac{\\left(n_{\\ell h}-s_{\\ell h}\\right)^{2}}{s_{\\ell h}} \\] De façon naturelle, pour mesurer la liaison sur une table de contingence, on utilise donc l’indice appelé khi-deux (chi-square) et défini comme suit: \\[ \\chi^{2}=\\sum_{\\ell=1}^{r} \\sum_{h=1}^{c} \\frac{\\left(n_{\\ell h}-\\frac{n_{\\ell+} n_{+h}}{n}\\right)^{2}}{\\frac{n_{\\ell+} n_{+h}}{n}}=n\\left[\\sum_{\\ell=1}^{r} \\sum_{h=1}^{c} \\frac{n_{\\ell h}^{2}}{n_{\\ell+} n_{+h}}-1\\right] \\] Le coefficient \\(\\chi^{2}\\) est toujours positif ou nul et il est d’autant plus grand que la liaison entre les deux variables considérés est forte. Un document complet et intéressant sur la visualization des données est sur ce lien Disponibles dans le jeu de données survey de la librairie MASS de ↩ On pourra dire en regardant ces deux figures qu’il n’y a pas de différence de rythme cardiaque entre les garçons et les filles, mais il y probablement une différence de taille. Pour confirmer cette comparaison on effectuera un test d’hypothèse de comparaison de moyennes entre deux échantillons.↩ "],
["exercices.html", "Exercices", " Exercices Exercice 1.1 (Nature des variables et graphique correspondant) Lors d’une enquête, on interroge 1000 individus sur leur âge, leur sexe, leur couleur préférée, leur nombre de frères et soeurs et leur département de naissance. Quelle est la nature de chacune de ces variables? Par quel outil graphique visualiseriez-vous la distribution de chacune des variables élémentaires? Exercice 1.2 (Petite série d’effectifs) On réalise un sondage auprès de 1000 personnes pour évaluer le nombre d’individus par ménage. On obtient la série statistique suivante: Nb de personnes par ménage 1 2 3 4 5 6 Total effectif 107 137 197 302 180 77 1000 Représenter cette série statistique à l’aide d’un graphique. Calculer la moyenne, la variance, l’écart-type et la médiane de cette distribution. Exercice 1.3 (Robustesse de la médiane aux données extrêmes) On a repertorié le temps mis par 20 étudiants pour décrocher un premier emploi (en mois): 0 0 0 0 0 1 1 1 2 2 2 3 3 3 4 4 6 6 8 20 Calculer la moyenne puis la médiane des observations. L’étudiant qui a mis 20 mois à trouver du travail a réalisé un tour du monde avant de chercher un emploi. On considère donc qu’il ne fait pas partie de la population qui nous intéresse et on décide de supprimer cette valeur de l’échantillon. Même question que la question 1 sans la dernière valeur (20). Comparer la stabilité des deux indicateurs de position vis-à-vis de l’élimination de valeurs extrêmes. Exercice 1.4 (Corrélation) Les données suivantes représentent la taille (en cm) et le salaire annuel brut (en k€) de 12 avocats ayant fait la même formation et obtenu presque les même notes. Taille Salaire 162.6 61 165.1 64 167.6 58 170.2 73 175.3 47 177.8 66 Taille Salaire 182.9 75 182.9 58 188.0 92 188.0 72 190.5 60 193.0 84 Représenter les données sur un nuage de points. Calculer le coefficient de corrélation et interpréter. "],
["tp-statistique-descriptive-avec-r.html", "TP Statistique descriptive avec R Qu’est-ce que c’est que ? 1ère partie: Données quantitatives discrètes 2ème partie : Analyse descriptive", " TP Statistique descriptive avec R Qu’est-ce que c’est que ? C’est un langage de programmation et un logiciel gratuit et libre. Il est surtout utilisé pour le développement de programmes statistiques et des analyses de données. Il gagne en popularité depuis quelques années avec l’émergence de la data science et du fait qu’il est gratuit et ouvert (open-source). est née d’un projet de recherche mené par deux chercheurs, Ross Ihaka et Robert Gentleman à l’université d’Auckland (Nouvelle-Zélande) en 1993. En 1997 est mis en place le Comprehension R Archive Network (CRAN) qui centralise les contributions au projet. Depuis le projet connaît une croissance soutenue, grâce à des contributions de la part de milliers de personnes à travers le monde. RStudio C’est une IDE (Integrated Development Environment) ou Environnement Intégré de Développement. Il sert d’interface entre et l’utilisateur, offre à celui diverses commodités d’utilisation Une introduction au RStudio est présentée dans l’annexe A. Vous trouverez une bonne introduction à sur ce lien . 1ère partie: Données quantitatives discrètes Le nombre d’arbres plantés sur les parcelles d’un lotissement a été compté. Les données obtenues sont les suivantes: \\[1,2,4,1,6,3,2,1,2,0,1,2,2,1,3,0,3,2,1,2,2,3,2,3.\\] 1. Quelle est la nature de variable étudiée? 2. Rentrer ces données sous la forme d’un vecteur nommé arbres et affichez ce vecteur. 3. Trier les valeurs de ce vecteur par ordre croissant. 4. Donner la taille de l’échantillon (c’est-à-dire le nombre de composantes de ce vecteur) en la notant n et affichez sa valeur. Effectifs et fréquence 5. Montrer la séquence des modalités et la séquence des effectifs correspondants. 6. Montrer le tableau de fréquences et de pourcentages. 7. Calculer et afficher les effectifs cumulés et les fréquences cumulées. Mesures de tendance centrale 8. Calculer le nombre moyen d’arbres par parcelle. 9. Calculer le nombre maximum et le nombre minimum d’arbres sur une parcelle. 10. Calculer le nombre médian d’arbres par parcelle. 11. Utiliser la fonction summary() pour obtenir un tableau récapitulatif des indicateurs. Indicateurs de dispersion 12. Calculer la variance du nombre d’arbres plantés sur les parcelles. 13. Calculer maintenant l’écart-type et vérifier que l’écart-type est la racine carrée de la variance. 14. Calculer la variance vous-même. La variance obtenue est elle la même que la précédente? Le logiciel utilise \\(n-1\\) pour le dénomiateur dans la définition de la variance, c’est-à-dire \\(\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2\\) (d’écart-type noté \\(\\sigma_{n-1}\\) ou \\(s\\). Cette quantité est souvent préférée dans les applications numériques pour des questions d’estimation). Représentations graphiques 15. La fontion plot() affiche par défaut un nuage de points avec en abscisse le numéro de l’observation (ici de 1 à 24) et en ordonnée le nombre d’arbres. Tester cette fonction. Modifier le titre de la figure, les noms des axes, la couleur et la forme des points affichés. 16. Afficher la courbe des fréquence cumulées. (Indication: Utiliser la fonction ecdf()). 17. Tracer un diagramme en bâtons par la fonction barplot() à partir du tableau des effectifs ou des fréquences. 2ème partie : Analyse descriptive Données utilisées Une enquête a été réalisée sur 237 étudiants. Les données sont les suivantes: Sex: The sex of the student. (Factor with levels “Male” and “Female”.) Wr.Hnd: span (distance from tip of thumb to tip of little finger of spread hand) of writing hand, in centimetres. NW.Hnd: span of non-writing hand. W.Hnd: writing hand of student. (Factor, with levels “Left” and “Right”.) Fold: “Fold your arms! Which is on top” (Factor, with levels “R on L”, “L on R”, “Neither”.) Pulse: pulse rate of student (beats per minute). Clap: ‘Clap your hands! Which hand is on top?’ (Factor, with levels “Right”, “Left”, “Neither”.) Exer: how often the student exercises. (Factor, with levels “Freq” (frequently), “Some”, “None”.) Smoke: how much the student smokes. (Factor, levels “Heavy”, “Regul” (regularly), “Occas” (occasionally), “Never”.) Height: height of the student in centimetres. M.I: whether the student expressed height in imperial (feet/inches) or metric (centimetres/metres) units. (Factor, levels “Metric”, “Imperial”.) Age: age of the student in years. Définition du répertoire de travail Vous avez la possibilité de définir un Répertoire de travail dans lequel vous allez stocker votre script R, vos données etc… Ceci est réalisé par la fonction setwd(\"..Chemin/de/votre/repertoire\"). Cette fonction considère comme seul paramètre le chemin d’accès au répertoire que vous avez choisi. A tout moment, vous pouvez vérifier le répertoire de travail courant en executant l’instruction suivante: getwd() 1. Définisser votre répertoire de travail. Chargement des données Il existe une multitude de fonctions qui permettent de charger un fichier de données. Télécharger le fichier de données en cliquant ici et enregistrer le dans votre répertoire. Ensuite utiliser la fonction read.csv() pour charger les données dans . Cette fonction prend comme principaux paramètres d’entrée le fichier à charger (file=\"data.txt\"), le séparateur de colonnes dans le fichier initial (sep=) et la présence (ou non) des noms de colonnes dans le fichier (header=). Ouvrez toujours le fichier de données dans un éditeur de texte pour connaitre le séparateur de colonnes et voir si les noms de colonnes sont présents. 2. Charger le fichier des données dans l’enquête dans un tableau nommé data. L’instruction de chargement du fichier est la suivante: donnees = read.csv(&quot;enquete.csv&quot;, header = T , sep=&quot;,&quot;) Le fichier de données est chargé dans l’environnement et est affecté à l’objet donnees. C’est cet objet, de type dataframe qui va faire l’objet de manipulations par la suite. 3. Afficher le nombre de d’observations (lignes) et le nombre de variables (colonnes). 4. Utiliser la fonction head() pour afficher les premières lignes (6 par défaut) de données chargées. 5. L’accès à une colonne d’un dataframe se fait par la notation $: nom_du_dataframe$nom_variable. Afficher les valeurs de la variable Age de vos données. Analyse descriptive univariée Indicateurs statistiques pour variables quantitatives 6. Calculer et afficher la moyenne et l’écart-type d’age des élèves qui ont participé à l’enquête. 7. Appliquer la fonction summary() sur la variable Age. Qu’est ce que cette fonction calcule et affiche? Représentations graphiques pour variables quantitatives 8. Tracer l’histogramme de la variable Age. Ecrire un titre correspondante à votre figure, modifier les noms des axes et les couleurs des bâtons. 9. Afficher une la boîte à moustache correspondante à la variable Age. Commenter ce qu’on observe sur cette figure. Indicateurs statistiques et représentations graphiques pour variables qualitatives 10. Choisir une variable qualitative parmi les variables de cette enquête. Justifier votre choix. Calculer et afficher les effectifs et les fréquences de cette variable. Pour voir les variables dans votre dataframe, vous pouvez utiliser la fonction names() pour afficher les noms des variables, ou str() (structure) pour voir toutes les colonnes, leur types, les quelques premières valeurs, etc.. Ou simplement dans Rstudio on peut voir la structure du dataframe dans la fenêtre “Environment”. 11. Afficher un diagramme circulaire (en utilisant la fonction pie()) pour la variable qualitative choisie. Analyse descriptive bivariée Indicateurs pour le croisement de deux variables qualitatives Le tableau de contingence est un moyen particulier de représenter simultanément deux caractères observés sur une même population, s’ils sont discrets ou bien continus et regroupés en classes. 12. Un tableau de contingence des effectifs joints croisant deux variables qualitatives est réalisé par la fonction table(). Effectuer et afficher le croisement de deux variables (Sex) et (Smoke). 13. Utiliser la fonction addmargins() pour ajouter au tableau les effectifs marginaux. Représentations graphiques pour le croisement de deux variables qualitatives On peut représenter le croisement de deux variables qualitatives avec un diagramme en bâtons. Dans le cas de deux variables qualitatives, la fonction barplot() prend comme premier paramètre le tableau de contingence. 14. Afficher un diagramme en bâtons représentant la distribution du tabagisme (variable Smoke) en fontion du sexe des étudiants. La figure souhaitée est la suivante: On remarque qu’il y a plus de femmes que des hommes fument régulièrement. (selon l’enquête réalisée) Indicateurs pour le croisement d’une variable qualitative et d’une variable quantitative Disons qu’on souhaite calculer la moyenne de fréquence cardiaque chez les hommes ayant répondu au questionnaire de l’enquête. On a besoin de filtrer le dataframe de la façon suivante: # On utilise la fontion subset pour créer un sous ensemble de nos données # Remarquer qu&#39;on utilise == pour comparer pulse_hommes = subset(donnees, donnees$Sex==&quot;Male&quot;) 15. Vérifier que le sous ensemble créé pulse_homme ne contient que des hommes. 16. Ensuite calculer les indicateurs statistiques de la fréquence cardiaque chez les hommes (vous pouvez utiliser la fonction summary()). 17. Faire la même chose mais pour les femmes. Représentation graphique pour le croisement d’une variable qualitative et d’une variable quantitative On peut réaliser une boîte à moustache des valeurs de la variable quantitative en fonction des modalités de la variables qualitative, pour cela on peut utliser la fonction boxplot(). Plus précisémeent, on utilise le paramètre formula qui permet de spécifier que nous voulons une boîte à moustache de la variable quantitative en fonction (caractère ~ ) de la variable quantitative. 18. Afficher sur la même figure la fréquence cardiaque en fontion du sexe. Interpréter la figure. La figure souhaitée est la suivante: 19. Afficher sur la même figure la taille (variable Height) en fontion du sexe. Interpréter la figure. Représentation graphique pour le croisement de deux variables quantitatives Un nuage de points entre les deux variables quantitatives est réalisé par la fonction plot(). Le premier paramètre correspond à la variable en abscisse et le deuxième à la variable en ordonnées. 20. Afficher la fréquence cardiaque en fonction de l’age. Modifier les paramètres de la figure (titre, noms des axes, couleurs des points, tailles, formes, etc..) ◼ "],
["echantillonnage-et-theoremes-limites.html", "Chapitre 2 Échantillonnage et Théorèmes limites 2.1 Échantillonnage 2.2 La statistique \\(\\overline{X}_n\\) 2.3 Théorèmes limites 2.4 Loi d’un pourcentage 2.5 Etude de la statistique \\(S^2\\) 2.6 Introduction à l’estimation", " Chapitre 2 Échantillonnage et Théorèmes limites 2.1 Échantillonnage L’étude d’une caractéristique d’une pièce fabriquée en grand nombre (telle que la luminosité d’une ampoule, sa durée de vie ou encore le diamètre d’une pièce mécanique) relève, elle aussi, de la statistique descriptive. Il n’est toutefois pas possible de mesurer cette caractéristique sur toutes les pièces produites. Il est alors nécessaire de se limiter à l’étude des éléments d’un échantillon. Cet échantillon devra répondre à des critères particuliers pour pouvoir représenter la population toute entière dans l’étude statistique. La démarche statistique présente plusieurs étapes : Prélèvement d’un échantillon représentatif de la population ou échantillon aléatoire par des techniques appropriées. Cela relève de la théorie de l’échantillonnage. Étude des caractéristiques de cet échantillon, issu d’une population dont on connaît la loi de probabilité. On s’intéresse principalement à ceux issus d’une population gaussienne. Définition 2.1 (Echantillon) Un échantillon aléatoire est un \\(n\\)-uplet \\((X_1,\\ldots,X_n)\\) de \\(n\\) variables aléatoires indépendantes suivant la même loi qu’une variable \\(X\\) appelée variable aléatoire parente. Une réalisation de l’échantillon sera notée \\((x_1,\\ldots,x_n)\\). Définition 2.2 (Une statistique) Soit \\(X\\) une variable aléatoire. Considérons un \\(n\\)-échantillon \\((X_1,\\ldots,X_n)\\) de \\(X\\). Une Statitique \\(T\\) est une variable aléatoire fonction mesurable de \\((X_1,\\ldots,X_n)\\). \\[ T(X)=T(X_1,\\ldots,X_n) \\] A un échantillon, on peut associer plusieurs statistiques. 2.2 La statistique \\(\\overline{X}_n\\) Définition 2.3 (Moyenne empirique) La statistique \\(\\overline{X}_n\\) ou moyenne empirique d’un échantillon est une statistique définie par \\[\\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i\\] Espérance et variance de \\(\\overline{X}_n\\): Soit \\(m\\) l’espérance et \\(\\sigma^2\\) la variance de la variable parente \\(X\\) (e.g. l’espérance et la variance de la population). L’espérance et la variance de la statistique \\(\\overline{X}_n\\) sont: \\[E(\\overline{X}_n) = m\\] \\[V(\\overline{X}_n) = \\frac{\\sigma^2}{n}\\] Démonstration: \\(E(\\overline{X}_n) = \\frac{1}{n} \\sum_{i=1}^n E(X_i) = \\frac{1}{n} nm = m\\) \\(V(\\overline{X}_n) =\\frac{1}{n} \\sum_{i=1}^n V(X_i) = \\frac{1}{n} n \\frac{\\sigma^2}{n}= \\frac{\\sigma^2}{n} \\quad \\quad\\) (Les \\(X_i\\) étant supposées indépendantes) 2.3 Théorèmes limites Cette section introduit trois résultats importants de la théorie asymptotique des probabilités: la loi faible des grands nombres, la loi forte des grands nombres et le théorème central limite, dans sa version pour variables aléatoires indépendantes et identiquement distribuées (\\(X_i\\) suivent la même loi pour \\(i=1,\\ldots,n\\)). Ce sont des résultats qui traitent les propriétés de la distribution de la statistique \\(\\overline{X}_n\\). Des variables aléatoires indépendantes et identiquement distribuées (i.i.d) sont des variables aléatoires indépendantes qui suivent la même loi de probabilité, donc ont la même espérance et la même variance. Les deux lois des grands nombres énoncent les conditions sous lesquelles la moyenne d’une suite de variables aléatoires converge vers leur espérance commune et expriment l’idée que lorsque le nombre d’observations augmente, la différence entre la valeur attendue (\\(m = E(X)\\)) et la valeur observée (\\(\\overline{X}_n\\)) tend vers zéro. De son côté, le théorème central limite établit que la distribution standardisée d’une moyenne tend asymptotiquement vers une loi normale, et cela même si la distribution des variables sous-jacentes est non normale. Ce résultat est central en probabilités et statistique et peut être facilement illustré (cf. figure 2.1). Indépendamment de la distribution sous-jacente des observations (ici une loi uniforme), lorsque \\(n\\) croît, la distribution de \\(\\overline{X}_n\\) tend vers une loi normale: on observe dans l’illustration la forme de plus en plus symétrique de la distribution ainsi que la concentration autour de l’espérance (ici \\(m = 0.5\\)) et la réduction de la variance. Figure 2.1: Illustration du théorème central limite: histogramme de la moyenne de 200 échantillons issus d’une loi uniforme sur l’intervalle (0,1) en fonction de la taille \\(n\\) de l’échantillon. Les retombées pratiques de ces résultats sont importantes. En effet, la moyenne de variables aléatoires est une quantité qui intervient dans plusieurs procédures statistiques. Aussi, le résultat du théorème central limite permet l’approximation des probabilités liées à des sommes de variables aléatoires (e.g. méthode de Monte-Carlo). De plus, lorsque l’on considère des modèles statistiques, le terme d’erreur représente la somme de beaucoup d’erreurs (erreurs de mesure, variables non considérées, etc.). En prenant comme justification le théorème central limite, ce terme d’erreur est souvent supposé se comporter comme une loi normale. 2.3.1 Loi faible des grands nombres Théorème 2.1 (Loi faible des grands nombres) Soit \\(X_1,\\ldots,X_n\\) une suite de variables aléatoires indépendantes et identiquement distribuées. On suppose que \\(E(|X_i|) &lt; \\infty\\) et que tous les \\(X_i\\) admettent la même espérance \\(E(X_i)=m\\). Alors: \\[\\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i \\rightarrow m \\quad \\text{au sens de la convergence en probabilités}\\] càd \\(\\forall \\varepsilon &gt; 0, \\lim_{n \\to \\infty} P(|\\overline{X}_n - m|&gt; \\varepsilon) = 0\\). \\(\\overline{X}_n \\text{ converge en probabilité vers } m \\text{ quand } n \\rightarrow +\\infty\\). 2.3.2 Loi forte des grands nombres Théorème 2.2 (Loi forte des grands nombres) Soit \\(X_1,\\ldots,X_n\\) une suite de variables aléatoires indépendantes et identiquement distribuées. On suppose que \\(E(|X_i|) &lt; \\infty\\) et que tous les \\(X_i\\) admettent la même espérance \\(E(X_i)=m\\). Alors: \\[\\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i \\rightarrow m \\quad \\text{presque sûrement}\\] càd \\(\\forall \\varepsilon &gt;0, P\\big( \\lim_{n \\to \\infty} \\overline{X}_n = m\\big) = 1\\). \\(\\overline{X}_n \\text{ converge presque sûrement vers } m\\) Illustration de la loi des grands nombres Prenons l’exemple d’un lancer de dé équilibré. On lance un dé et on note \\(X\\) le résultat obtenu. La loi de \\(X\\) est la suivante: \\(x_i\\) \\(1\\) \\(2\\) \\(3\\) \\(4\\) \\(5\\) \\(6\\) \\(P(X = x_i)\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) Et donc l’espérance de \\(X\\) est \\(E(X)=\\sum_i p_i x_i = 3.5\\). Pour illustrer le théorème on va procéder à un échantillonnage. On répète le lancement du dé \\(n\\) fois. A chaque \\(n\\) on va calculer la moyenne empirique des résultats obtenus, qu’on va noter \\(\\overline{X}_n\\). Selon la loi de grands nombre cette moyenne va converger vers l’espérance théorique: \\[\\overline{X}_n \\rightarrow E(X)=m=3.5 \\quad \\text{quand} \\quad n \\rightarrow \\infty\\] Traçons l’évolution de la moyenne empirique en fonction de la taille \\(n\\) de l’échantillon, dans deux différents échantillonnages aléatoires: Figure 2.2: Convergence de \\(\\overline{X}_n\\) vers \\(m=3.5\\) pour deux différents échantillonnages 2.3.3 Théorème central limite Théorème 2.3 (Théorème central limite) Soit \\(X_1,\\ldots,X_n\\) une suite de variables aléatoires indépendantes et identiquement distribuées, d’espérance \\(m\\) et variance \\(\\sigma^2\\) finie. Alors \\[\\begin{equation} \\frac{\\overline{X}_n - m}{ \\sigma/\\sqrt{n}} \\xrightarrow{n \\to \\infty} \\mathcal{N}(0,1) \\quad \\text{en distribution} \\tag{2.1} \\end{equation}\\] On voit bien que, afin que la convergence se fasse, une standardisation est nécessaire: en effet, on peut voir le rapport dans (2.1) comme \\[\\frac{\\overline{X}_n - m}{ \\sigma/\\sqrt{n}} = \\frac{\\overline{X}_n - E(\\overline{X}_n)}{ \\sqrt{var(\\overline{X}_n)}}\\] Notes Historiques La loi faible des grands nombres a été établie la première fois par J. Bernoulli pour le cas particulier d’une variable aléatoire binaire ne prenant que les valeurs 0 ou 1. Le résultat a été publié en 1713. La loi forte des grands nombres est due au mathématicien E. Borel (1871- 1956), d’où parfois son autre appellation: théorème de Borel. Le théorème central limite a été formulé pour la première fois par A. de Moivre en 1733 pour approximer le nombre de “piles” dans le jet d’une pièce de monnaie équilibrée. Ce travail a été un peu oublié jusqu’à ce que P.S. Laplace ne l’étende à l’approximation d’une loi binomiale par la loi normale dans son ouvrage Théorie analytique des probabilités en 1812. C’est dans les premières années du \\(XX^e\\) siècle que A. Lyapounov l’a redéfini en termes généraux et prouvé avec rigueur. Application 1: Pour une taille d’échantillon \\(n\\) suffisamment grande, on peut considérer que \\(\\overline{X}_n\\) a pour loi: \\[ \\overline{X}_n \\thicksim \\mathcal{N}\\big(m, \\frac{\\sigma^2}{n}\\big)\\] Dans la notation de la loi normale ci dessus \\(\\frac{\\sigma^2}{n}\\) est la variance. \\(\\frac{\\sigma}{\\sqrt{n}}\\) est l’écart-type. Application 2: la loi d’un pourcentage, étudiée dans la section suivante. 2.4 Loi d’un pourcentage Soit \\(X\\) la variable aléatoire représentant le nombre de succès au cours d’une suite de \\(n\\) répétitions indépendantes d’une même épreuve dont la probabilité de succès est \\(p\\). La loi de \\(X\\) est la loi binomiale de paramètres \\(n\\) et \\(p\\) notée \\(\\mathcal{B}(n, p)\\). \\(X\\) est la somme de \\(n\\) variables indépendantes de Bernoulli de paramètre \\(p\\). Notons \\(P_n\\) la fréquence empirique du nombre de succès parmi les \\(n\\) épreuves: \\[P_n= \\frac{X}{n}\\] \\(P_n = \\overline{X}_n\\) car \\(X\\) est la somme de \\(n\\) variables indépendantes de Bernoulli de paramètre \\(p\\). \\(P_n\\) a pour espérance et pour variance: \\[E(P_n) = p \\quad \\quad \\text{et} \\quad \\quad V(P_n) = \\frac{p(1-p)}{n}\\] En appliquant le théorème central limite à \\(X\\) somme des variables de Bernoulli: \\[ \\text{Pour } n \\text{ suffisamment grand, on peut être considérer que } P_n \\text{ suit la loi normale :}\\] \\[P_n \\thicksim \\mathcal{N}\\bigg(p, {\\frac{p(1-p)}{n}}\\bigg)\\] Ce résultat est une autre formulation du théorème de “De Moive-Laplace” (lien). 2.5 Etude de la statistique \\(S^2\\) Définition 2.4 (Variance empirique) La statistique \\(S_n^2\\) ou variance empirique d’échantillon est définie par: \\[S_n^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}_n\\right)^{2}\\] Propriétés: \\(S_n^{2}=\\frac{1}{n} \\big(\\sum_{i=1}^{n}X_{i}^2\\big)-\\big(\\overline{X}_n\\big)^{2}\\). \\(S_n^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\big(X_{i}-m\\big)^2-\\big(\\overline{X}_n-m\\big)^{2}\\). \\(S_n^{2} \\text{ converge presque sûrement vers } \\sigma^2\\). Espérance de \\(S_n^{2}\\): L’espérance de \\(S_n^{2}\\) est: \\[E(S_n^{2}) = \\frac{n-1}{n}\\sigma^2\\] démonstration: \\[\\begin{align} E(S_n^{2}) &amp; =\\frac{1}{n} \\sum_{i=1}^{n}E\\big(X_{i}-m\\big)^2-E\\big(\\overline{X}_n-m\\big)^{2} \\\\ &amp; = \\frac{1}{n} \\sum_{i=1}^{n}V(X_i)-V(\\overline{X}_n) \\\\ &amp; = \\frac{1}{n} \\sum_{i=1}^{n}\\sigma^2- \\frac{\\sigma^2}{n} = \\sigma^2- \\frac{\\sigma^2}{n} = \\frac{n-1}{n} \\sigma^2 \\end{align}\\] On peut remarquer que si on pose: \\({S_n^{*}}^2 = \\frac{n}{n-1}S_n^2\\) alors \\(E({S_n^{*}}^2) = \\sigma^2\\). 2.6 Introduction à l’estimation On appelle estimation, la procédure d’utilisation des informations obtenues à partir d’un échantillon qui permet de déduire des résultats concernant l’ensemble de la population. Dans ce cours, les estimations sont calculées à partir d’un échantillonnage aléatoire simple et avec remise, càd tous les individus de la population ont une probabilité égale de faire partie de l’échantillon et qu’un individu peut être choisi plus d’une fois. La statistique inconnue d’une population, à estimer à partir d’un échantillon, est appelée un paramètre. Souvent le paramètre à estimer est une moyenne, un total, une proportion, un écart-type ou une variance. Le paramètre de la population est estimé à partir d’une estimation calculée à partir des données d’un échantillon. Le tableau ci dessous illustre les différents symboles souvent utilisés. Paramètres population Estimations calculées sur un échantillon de taille \\(n\\) Moyenne \\(m\\) \\(\\overline{X}_n=\\hat{m}\\) Ecart-type \\(\\sigma\\) \\(S_n=\\hat{\\sigma}\\) Variance \\(\\sigma^2\\) \\(S_n^2=\\hat{\\sigma}^2\\) Proportion \\(p\\) \\(P_n=\\hat{p}\\) On dit que \\(\\overline{X}_n\\) est un estimateur de \\(m\\). La valeur obtenue est une estimation de \\(m\\), qu’on appelle \\(\\hat{m}\\). Les estimateurs sont des variables aléatoires et les estimations sont les valeurs observées des estimateurs (i.e des variables aléatoires). Dans ce chapitre nous avons introduit des estimateurs de la moyenne, la variance et la proportion. Nous avons aussi étudié les lois de ces estimateurs. Dans le chapitre suivant, nous allons étudier la théorie de l’estimation ponctuelle et la recherche d’un estimateur. "],
["exercices-1.html", "Exercices", " Exercices Exercice 2.1 (Loi de \\(\\overline{X}_n\\)) Une population est composée de 3 salariés A, B et C âgés respectivement de 23, 37 et 45 ans. On choisit au hasard un salarié. Définir l’expérience aléatoire \\(\\varepsilon\\), la population \\(\\Omega\\), la probabilité \\(P\\) et la variable aléatoire \\(X\\) étudiée. Calculer \\(E(X)=m\\) et \\(V(X)=\\sigma^2\\). Que représentent \\(E(X)\\) et \\(V(X)\\)? On choisit maintenant au hasard un échantillon de 2 salariés. Définir la nouvelle expérience aléatoire \\(\\varepsilon_n\\), l’ensemble des échantillons \\(E_n\\) et les variables alétoires \\(X_i, i=1,\\ldots,n\\). Définir la variable alétoire \\(\\overline{X}_n\\) et déterminer sa loi. Calculer \\(E(\\overline{X}_n)\\) et \\(V(\\overline{X}_n)\\). Retrouver les formules du cours. Exercice 2.2 (Loi de \\(P_n\\)) Une population est composée de 3 individus A, B et C dont les résultats de vote pour un certain candidat sont respectivement les suivants: Non, Non et Oui. On choisit au hasard un individu. Définir l’expérience aléatoire \\(\\varepsilon\\), la population \\(\\Omega\\), la probabilité \\(P\\) et la variable aléatoire \\(X\\) étudiée. Calculer \\(E(X)\\) et \\(V(X)\\). Que représente \\(E(X)\\)? On choisit maintenant au hasard un échantillon de 2 individus. Définir la nouvelle expérience aléatoire \\(\\varepsilon_n\\), l’ensemble des échantillons \\(E_n\\) et les variables alétoires \\(X_i, i=1,\\ldots,n\\). Définir la variable alétoire \\(P_n\\) et déterminer sa loi. Calculer \\(E(P_n)\\) et \\(V(P_n)\\). Retrouver les formules du cours. Exercice 2.3 Est ce qu’il s’agit d’une variable alétoire? Moyenne de la population. Taille de la population. Taille de l’échantillon. Moyenne de l’échantillon. Variance de la moyenne de l’échantillon. Plus grande valeur de l’échantillon. Variance de la population. Variance estimée de la moyenne de l’échantillon. Exercice 2.4 (Théorème Central Limite) Devant l’augmentation des problèmes de poids dans la population européenne, une nouvelle étude est mandatée pour mesurer la relation entre celui-ci et la quantité de calories ingérées par habitant. Des études antérieures montrent qu’un Européen consomme en moyenne \\(2700\\) calories par jour avec un écart-type de \\(800\\). On dispose dans cette étude d’un échantillon de \\(500\\) Européens. Définisser les variables aléatoires étudiées dans l’énoncé. On les nomme \\(X_i\\) et \\(\\overline{X}_n\\). Utiliser le TCL pour donner la distribution de la v.a. \\(\\overline{X}_n\\). Calculer la probabilité que la moyenne des calories consommées par jour par les Européens, qu’on a nommé \\(\\overline{X}_n\\), dans l’échantillon soit supérieure à \\(2750\\). Exercice 2.5 Afin d’estimer leur espérance respective, on échantillonne 2 populations. On utilise un échantillon de taille \\(n_{1}\\) pour la population 1, qui présente un écart-type égal à \\(\\sigma_{1}\\). Pour la population 2, dont l’écart-type vaut \\(\\sigma_{2}=2\\sigma_{1}\\), on prend un échantillon de taille \\(n_{2}=2 n_{1}\\). Pour lequel des 2 échantillons est-ce que l’estimation de la moyenne de la population est la plus précise? Exercice 2.6 Dans une certaine commune française, on veut estimer la proportion de familles vivant en dessous du seuil de pauvreté. Si cette proportion est environ \\(0.15\\), quelle est la taille de l’échantillon nécessaire pour que l’écart-type de l’estimateur soit égal à \\(0.02\\)? Extra Exercice 2.7 (Théorème Central Limite) Rémy et ses 9 amis voudraient jouer au bowling. Ils décident de rassembler leur argent de poche et espèrent obtenir la somme totale nécessaire. On peut supposer que l’argent de poche de chacun est une variable aléatoire \\(X_i\\) qui suit la loi exponentielle de paramètre \\(\\lambda=0.06\\). Sa densité est donc \\[ f(x)=0.06 e^{-0.06 x} \\times 1_{\\mathbb{R}^+}(x) \\] De plus, on admet que les \\(X_i\\) sont indépendantes. Démontrer que la loi exponentielle \\(\\mathcal{E}(\\lambda)\\) est un cas exceptionnelle de la loi Gamma en donnant les paramètres de celle-ci. (un rappel de la définition de la loi Gamma est donnée ci dessous). Soit \\(S_{10}=\\sum_{i=1}^{10} X_{i}\\) Quelle est la loi de \\(S_{10}\\)? Sachant qu’une partie du bowling coûte \\(15 €\\), quelle est la probabilité que Rémy et ses amis puissent jouer une partie? (Indication: Appliquer le TCL pour \\(S_{10}= \\sum_{i=1}^n X_i = n \\times \\overline{X}_n\\)) Comment faut-il choisir \\(z&gt;0\\) pour que la probabilité que la somme totale d’argent du groupe soit supérieure à \\(z\\) soit égale à \\(5 \\%\\)? Loi Gamma \\(\\Gamma(a,\\lambda)\\) On dit que la variable aléatoire \\(X\\) suit une loi Gamme de paramètres \\(a&gt;0\\) et \\(\\lambda&gt;0\\), \\(X \\thicksim \\Gamma(a,\\lambda)\\) si \\(X\\) a la densité: \\[\\forall \\, x \\in \\mathbb{R}, \\quad f_{a,\\lambda} (x)= \\frac{\\lambda^a}{\\Gamma(a)} x^{a-1} e^{-\\lambda x} \\times {1}_{\\mathbb{R}_{+}}(x)\\] La fonction Gamma est définie sur \\(\\mathbb{R}_{+}^*\\) par: \\(\\Gamma(x) = \\int_0^{+\\infty} t^{x-1}e^{-t} dt\\). Propriétés de la fonction Gamma: \\(\\Gamma(x+1)=x\\Gamma(x) \\quad \\forall \\, x &gt;0\\) \\(\\Gamma(n+1) = n! \\quad \\forall n \\in \\mathbb{N}\\) \\(\\Gamma(1) = 1\\) et \\(\\Gamma(\\frac{1}{2})=\\sqrt{\\pi}\\) Propriétés de la loi Gamma: \\(E(X)= \\frac{a}{\\lambda}\\) et \\(V(X)= \\frac{a}{\\lambda^2}\\). Si \\((X_n)_{n \\in \\mathbb{N}}\\) est une suite de variables aléatoires indépendantes de lois \\(\\Gamma(a_n,\\lambda)\\) alors la variable aléatoire somme \\(\\sum_{n=1}^N X_n\\) suit également une loi gamma \\(\\Gamma(\\sum_{n=1}^N a_n, \\lambda)\\). "],
["tp-illustration-numerique-des-theoremes-limites-avec-r.html", "TP illustration numérique des théorèmes limites avec R Illustrations de théorèmes limites Bonus", " TP illustration numérique des théorèmes limites avec R Réalisations de variables aléatoires Pour générer (simuler) des réalisations de variables aléatoires on utilise la fonction qui commence par la lettre r (pour random) succédée par le nom de la loi que l’on souhaite simuler. Par exemple rnorm pour simuler des réalisations de la variable alétoire de loi normale. Tapez ?rnorm pour voir la liste des paramètres (arguments) de cette fonction. rnorm(10) # génére 10 réalistions alétoires de la loi normale centrée réduite. #ans&gt; [1] 1.7111 0.1184 0.2113 0.8255 0.4184 1.8033 0.3251 0.3784 0.0252 0.0345 rnorm(10, mean = 1, sd = 3) # génére 10 réalisations alétoires de la loi normale d&#39;espérance 1 et écart-type 3 #ans&gt; [1] 4.7308 5.9451 -3.1275 0.5337 -3.8268 3.9036 1.9544 0.0549 #ans&gt; [9] -0.6323 4.6497 1. Simuler un vecteur de 1000 réalisations indépendantes de loi uniforme sur l’intervalle \\([0,1]\\). Simuler ensuite 1000 réalisations de la loi exponentielle de paramètre 2. Extra: Afin de vérifier les simulations on peut afficher l’histogramme des réalisations et superposer avec la densité de la loi correspondante. Fonction de densité Pour calculer la densité d’une certaine loi, il suffit d’utiliser comme fonction le nom de la loi dans avec le préfixe d pour une densité. Taper ?dnorm pour comprendre le fonctionnement de cette commande. 2. Que vaut la densité de la loi normale centrée réduite en 0? Essayer la même chose pour la loi binomiale de paramètres \\(n=10\\) et \\(p=0.5\\). Cette commande permet de tracer facilement des fonctions de densité. 3. Que se passe-t-il si l’on demande la fonction de densité de la loi binomiale en 0.3? Pourquoi? 4. Tracer la fonction de densité de la loi normale centrée réduite. Commencer par créer un vecteur d’abscisses à l’aide de la fonction seq(). Tracer ensuite la fonction de densité en ces points. Il existe plusieurs paramètres réglables pour avoir des courbes de différents design. 5. Tracer un histogramme d’un vecteur de 10000 réalisations indépendantes d’une loi normale centrée réduite. Superposer l’histogramme avec la densité réelle de cette loi. Fonction de répartition Pour calculer la fonction de répartition d’une certaine loi on utilise le nom de la loi dans avec le préfixe p. 6. Que vaut la fonction de répartition de la loi normale centrée réduite en 0? 7. Tracer la fonction de répartition de la loi normale centrée réduite. On peut également tracer des fonctions de répartitions empiriques (calculées sur un échantillon). 8. Créer un vecteur de 100 réalisations indépendates de la loi de votre choix. Utiliser la fonction ecdf() pour construire la fonction de répartition empirique de votre vecteur. Puis superposer avec la fonction de répartition théorique. Illustrations de théorèmes limites Loi forte de grands nombres On considère une variable \\(X\\) à valeurs dans \\(\\{0,1,3\\}\\), distribuée comme suit: \\(P(X=0)=0.5, P(X=1)=0.25, P(X=3)=0.25\\). 9. Proposer une façon de simuler \\(X\\). (Suggestion: utiliser la fonction sample()). 10. On considère \\(X_1,X_2,\\ldots\\) une suite infinie de variables indépendantes de même loi que \\(X\\). Soit \\(\\overline{X}_n\\) la moyenne empirique des \\(X_i\\) pour \\(i \\in \\{1,\\ldots,n\\}\\). 10.1 Simuler la suite des \\(X_i\\) pour \\(i \\in \\{1,\\ldots,10000\\}\\). 10.2 Produire un graphique représentant l’évolution de \\(\\overline{X}_n\\) pour \\(n\\) variant de 1 à 10000. (Indication: penser à utiliser la fonction cumsum()). 10.3 Que constate-on? Pouvait-on s’y attendre? Théorème central limite On désire maintenant approfondir comment \\(\\overline{X}_{500}\\) varie autour de sa valeur moyenne. 11. Proposer une transformation affine de \\(\\overline{X}_{500}\\), de la forme \\(Y=a \\times (\\overline{X}_{500} + b)\\), qui suive approximativement la loi \\(\\mathcal{N}(0,1)\\). 11.1 Simuler avec \\(10000\\) réalisations indépendantes de la variable \\(Y\\). Nous les noterons \\(Y_1, \\ldots, Y_{10000}\\). 11.2 Confirmer l’approximation gaussienne en réalisant un histogramme des valeurs prises par les \\(Y_j\\) pour \\(j \\in \\{1,\\ldots,10000\\}\\), sans oublier de tracer la densité gaussienne correctement renormalisée. Commenter l’écart entre l’histogramme et la densité gaussienne. Bonus Illustration du théorème de Moivre Laplace Pour \\((n=10, p=0.5),\\) puis \\((n=50, p=0.9),\\) puis \\((n=100, p=0.1)\\) Simuler un échantillon \\(X\\) de la loi binomiale de paramètres \\(n\\) et \\(p .\\) Calculer l’échantillon centré-réduit \\(Xcr=\\frac{x-n p}{\\sqrt{n p(1-p)}}\\). Représenter un histogramme des valeurs de \\(X c r .\\) Superposer sur le même graphique la densité de la loi normale \\(\\mathcal{N}(0,1) .\\) Représenter la fonction de répartition empirique de \\(X c r .\\) Superposer sur le même graphique la fonction de répartition de la loi normale \\(N(0,1)\\). "],
["estimation-ponctuelle.html", "Chapitre 3 Estimation ponctuelle 3.1 Introduction 3.2 Méthodes d’estimation 3.3 La méthode des moments 3.4 La méthode du maximum de vraisemblance 3.5 Qualité d’un estimateur 3.6 Propriétés des estimateurs des moments (EMM) 3.7 Propriétés des estimateurs de maximum de vraisemblance (EMV)", " Chapitre 3 Estimation ponctuelle 3.1 Introduction Dans ce chapitre, on suppose que les données \\(x_1,\\ldots,x_n\\) sont \\(n\\) réalisations indépendantes d’une même variable aléatoire sous-jacente \\(X\\) (variable parente). Il est équivalent de supposer que \\(x_1,\\ldots,x_n\\) sont les réalisations de variables aléatoires \\(X_1,\\ldots,X_n\\) indépendantes et de même loi (i.i.d). Nous adopterons ici la seconde formulation, qui est plus pratique à manipuler. Les techniques de statistique descriptive, comme l’histogramme ou le graphe de probabilités, permettent de faire des hypothèses sur la nature de la loi de probabilité des \\(X_i\\). Des techniques statistiques plus sophistiquées, les tests d’adéquation, permettent de valider ou pas ces hypothèses. On supposera ici que ces techniques ont permis d’adopter une famille de lois de probabilité bien précise (par exemple, loi normale, loi de Poisson, etc.) pour la loi des \\(X_i\\), mais que la valeur du ou des paramètres de cette loi est inconnue. On notera \\(\\theta\\) le paramètre inconnu. Le problème traité dans ce chapitre est celui de l’estimation du paramètre \\(\\theta\\). Comme on l’a déjà dit, il s’agit de donner, au vu des observations \\(x_1,\\ldots,x_n\\), une approximation ou une évaluation de \\(\\theta\\) que l’on espère la plus proche possible de la vraie valeur inconnue. On pourra proposer une unique valeur vraisemblable pour \\(\\theta\\) (estimation ponctuelle, dans ce chapitre) ou un ensemble de valeurs vraisemblables (estimation ensembliste ou région (intervalle) de confiance, dans le chapitre suivant). On notera \\(F(x;\\theta)\\) la fonction de répartition des \\(X_i\\). Pour les variables aléatoires discrètes on notera \\(P(X = x;\\theta)\\) les probabilités élémentaires, et pour les variables aléatoires continues on notera \\(f(x;\\theta)\\) la densité. Par exemple, quand \\(X\\) est de loi exponentielle \\(\\mathcal{E}(\\lambda)\\), on aura \\(F(x;\\lambda) = 1 − e^{−\\lambda x}\\) et \\(f(x;\\lambda) = \\lambda e^{−\\lambda x}\\). L’estimation du paramètre \\(\\theta\\) s’agit de donner, au vu des observations \\(x_1,\\ldots,x_n\\), une approximation ou une évaluation de \\(\\theta\\) que l’on espère la plus proche possible de la vraie valeur inconnue. 3.2 Méthodes d’estimation Il existe de nombreuses méthodes pour estimer un paramètre \\(\\theta\\). Dans cette section, nous ne nous intéressons qu’aux deux méthodes d’estimation les plus usuelles, la méthode des moments et la méthode du maximum de vraisemblance. Mais il faut d’abord définir précisément ce que sont une estimation et surtout un estimateur. Pour estimer \\(\\theta\\) on ne dispose que des données \\(x_1,\\ldots,x_n\\), donc une estimation de \\(\\theta\\) sera une fonction de ces observations. Définition 3.1 (Définition d’une statistique) Une statistique \\(t\\) est une fonction des observations \\(x_1,\\ldots,x_n\\) : \\[\\begin{align} t: \\, &amp; \\mathbb{R}^n \\rightarrow \\mathbb{R}^m \\\\ &amp; (x_1,\\ldots,x_n) \\rightarrow t(x_1,\\ldots,x_n) \\end{align}\\] Par exemple, \\(\\overline{x}_n = \\frac{1}{n} \\sum_{i=1}^n x_i, \\,\\, x_1^2 \\,\\, \\text{ou} \\,\\, (x_1,x_3+x_4,2 \\ln x_6)\\) sont des statistiques. Puisque les observations \\(x_1,\\ldots,x_n\\) sont des réalisations des variables aléatoires \\(X_1,\\ldots,X_n\\), la quantité calculable à partir des observations \\(t(x_1,\\ldots,x_n)\\) est une réalisation de la variable aléatoire \\(t(X_1,\\ldots,X_n)\\). Et on retrouve par exemple le fait que \\(\\overline{x}_n = \\frac{1}{n} \\sum_{i=1}^n x_i\\) est une réalisation de \\(\\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i\\). Pour simplifier les écritures, on note souvent \\(t_n = t(x_1,\\ldots,x_n)\\) et \\(T_n = t(X_1,\\ldots,X_n)\\). Par abus, on donne le même nom de statistique aux deux quantités, mais dans une perspective d’estimation, on va nommer différemment \\(t_n\\) et \\(T_n\\). Définition 3.2 (Définition d’un estimateur) Un estimateur d’une grandeur \\(\\theta\\) est une statistique \\(T_n\\) à valeurs dans l’ensemble des valeurs possibles de \\(\\theta\\). Une estimation de \\(\\theta\\) est une réalisation \\(t_n\\) de l’estimateur \\(T_n\\). Un estimateur est donc une variable aléatoire, alors qu’une estimation est une valeur déterministe. Dans l’exemple des ampoules dans l’introduction (ici), l’estimateur de \\(\\lambda\\) est \\(1/\\overline{X}_n\\) et l’estimation de \\(\\lambda\\) est \\(0.012\\).3 Un estimateur est une variable aléatoire, alors qu’une estimation est une valeur déterministe. 3.3 La méthode des moments 3.3.1 L’estimateur des moments (EMM) C’est la méthode la plus naturelle. L’idée de base est d’estimer une espérance mathématique par une moyenne empirique, une variance par une variance empirique, etc… Si le paramètre à estimer est l’espérance de la loi des \\(X_i\\), alors on peut l’estimer par la moyenne empirique de l’échantillon. Autrement dit, si \\(\\theta = E(X)\\), alors l’estimateur de \\(\\theta\\) par la méthode des moments (EMM) est \\(\\hat{\\theta}_n=\\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i\\). Plus généralement, pour \\(\\theta \\in \\mathbb{R}\\), si \\(E(X) = \\phi(\\theta)\\), où \\(\\phi\\) est une fonction inversible, alors l’estimateur de \\(\\theta\\) par la méthode des moments est \\(\\hat{\\theta}_n = \\phi^{-1} (\\overline{X}_n)\\). De la même manière, on estime la variance de la loi des \\(X_i\\) par la variance empirique de l’échantillon \\(S_n^2= \\frac{1}{n} \\sum_{i=1}^n (X_i - \\overline{X}_n)^2 = \\frac{1}{n} \\sum_{i=1}^n X_i^2 - \\overline{X}_n^2\\). 3.3.2 Exemples 3.3.2.1 Exemple 1: loi de Bernoulli Si \\(X_1,\\ldots,X_n\\) sont indépendantes et de même loi de Bernoulli \\(\\mathcal{B}(p)\\), \\(E(X) = p\\). Donc l’estimateur de \\(p\\) par la méthode des moments est \\(\\hat{p}_n = \\overline{X}_n\\). Cet estimateur n’est autre que la proportion de 1 dans l’échantillon. On retrouve donc le principe d’estimation d’une probabilité par une proportion (voir 2.4 et 2.6). 3.3.2.2 Exemple 2: loi exponentielle Si \\(X_1,\\ldots,X_n\\) sont indépendantes et de même loi exponentielle \\(\\mathcal{E}(\\lambda)\\), \\(E(X) = 1/\\lambda\\). Donc l’estimateur de \\(\\lambda\\) par la méthode des moments est \\(\\hat{\\lambda}_n = 1/\\overline{X}_n\\). 3.3.2.3 Exemple 3: loi normale Si \\(X_1,\\ldots,X_n\\) sont indépendantes et de même loi normale \\(\\mathcal{N}(m,\\sigma^2 )\\), \\(E(X) = m\\) et \\(V(X) = \\sigma^2\\), donc les estimateurs de \\(m\\) et \\(\\sigma^2\\) par la méthode des moments sont \\(\\hat{m} = \\overline{X}_n\\) et \\(\\hat{\\sigma}^2=S_n^2\\).4 3.3.2.4 Exemple 4: loi gamma Si \\(X_1,\\ldots,X_n\\) sont indépendantes et de même loi gamma \\(\\Gamma(a,\\lambda)\\), \\(E(X) = a/\\lambda\\) et \\(V(X) = a/\\lambda^2\\). On en déduit facilement que : \\[ \\lambda = \\frac{E(X)}{V(X)} \\quad \\text{et} \\quad a = \\frac{[E(X)]^2}{V(X)}\\] Donc les EMM de \\(a\\) et \\(\\lambda\\) sont: \\[ \\hat{\\lambda} = \\frac{\\overline{X}_n}{S_n^2} \\quad \\text{et} \\quad a = \\frac{\\overline{X}_n^2}{S_n^2}\\] :::rmdinsight L’idée de base de l’estimateur par la méthode des moments est d’estimer une espérance mathématique par une moyenne empirique, une variance par une variance empirique, etc… ::: 3.4 La méthode du maximum de vraisemblance 3.4.1 La fonction de vraisemblance Définition 3.3 Quand les observations sont toutes discrètes ou toutes continues, on appelle fonction de vraisemblance (ou plus simplement vraisemblance) pour l’échantillon \\(x_1,\\ldots,x_n\\), la fonction du paramètre \\(\\theta\\) : \\[\\begin{equation*} \\mathcal{L}(\\theta; x_1,\\ldots,x_n) = \\left\\lbrace \\begin{array}{ll} P(X_1=x_1,\\ldots,X_n=x_n; \\theta) &amp; \\text{si les} \\, X_i \\, \\text{sont discrètes}\\\\ f_{X_1,\\ldots,X_n}(x_1,\\ldots,x_n;\\theta) &amp; \\text{si les} \\, X_i \\, \\text{sont continues} \\end{array} \\right. \\end{equation*}\\] Dans tous les exemples que nous traiterons ici, les \\(X_i\\) sont indépendantes et de même loi. Dans ce cas, la fonction de vraisemblance s’écrit: \\[\\begin{equation*} \\mathcal{L}(\\theta; x_1,\\ldots,x_n) = \\left\\lbrace \\begin{array}{ll} \\displaystyle \\prod_{i=1}^n P(X_i=x_i; \\theta) = \\prod_{i=1}^n P(X=x_i; \\theta) &amp; \\text{si les} \\, X_i \\, \\text{sont discrètes}\\\\ \\displaystyle \\prod_{i=1}^n f_{X_i}(x_i;\\theta) = \\prod_{i=1}^n f(x_i;\\theta) &amp; \\text{si les} \\, X_i \\, \\text{sont continues} \\end{array} \\right. \\end{equation*}\\] Remarque: La probabilité et la densité utilisées dans cette définition sont des fonctions des observations \\(x_1,\\ldots,x_n\\), dépendant du paramètre \\(\\theta\\). A l’inverse, la fonction de vraisemblance est considérée comme une fonction de \\(\\theta\\) dépendant des observations \\(x_1,\\ldots,x_n\\), ce qui permet, par exemple, de dériver cette fonction par rapport à \\(\\theta\\). 3.4.1.1 Exemple introductif Dans cet exemple, \\(n = 1\\). On considère que l’on sait que \\(X_1\\) est de loi binomiale \\(\\mathcal{B}(15,p)\\), avec \\(p\\) inconnu. On observe \\(x_1 = 5\\) et on cherche à estimer \\(p\\). La fonction de vraisemblance est : \\[\\mathcal{L}(p;5) = P(X_1 = 5;p) = C_{15}^5 p^5 (1-p)^{15-5}\\] C’est la probabilité d’avoir observé un 5 quand la valeur du paramètre est \\(p\\). Calculons-là pour quelques valeurs de \\(p\\). \\(p\\) \\(0.1\\) \\(0.2\\) \\(0.3\\) \\(0.4\\) \\(0.5\\) \\(0.6\\) \\(0.7\\) \\(0.8\\) \\(0.9\\) \\(\\mathcal{L}(p;5)\\) \\(0.01\\) \\(0.10\\) \\(0.21\\) \\(0.19\\) \\(0.09\\) \\(0.02\\) \\(0.003\\) \\(10^{-4}\\) \\(210^{-7}\\) On tire de cette table que quand \\(p = 0.8\\), c’est-à-dire quand \\(X_1\\) est de loi \\(\\mathcal{B}(15,0.8)\\), il n’y a qu’une chance sur \\(10000\\) d’observer \\(x_1 = 5\\). En revanche, il y a \\(21\\%\\) de chances d’observer un \\(5\\) quand \\(p = 0.3\\). Il est donc beaucoup plus vraisemblable que \\(p\\) soit égal à \\(0.3\\) plutôt qu’à \\(0.8\\). En suivant ce raisonnement, on aboutit à dire que la valeur la plus vraisemblable de \\(p\\) est celle pour laquelle la probabilité d’observer un \\(5\\) est maximale. C’est donc la valeur de \\(p\\) qui maximise la fonction de vraisemblance. Pour la calculer, on peut annuler la dérivée de la vraisemblance (en fonction de \\(p\\)). Mais on remarque que la vraisemblance est un produit. Comme il est plus commode de maximiser (ou de dériver) une somme qu’un produit, on utilise le fait que la valeur qui rend maximale une fonction rend aussi maximal son logarithme. On va donc plutôt maximiser le logarithme de la fonction de vraisemblance, qu’on appelle la log-vraisemblance. Pour notre exemple, la log-vraisemblance vaut: \\[\\ln \\mathcal{L}(p;x_1)=\\ln C_{15}^{x_1} + x_1 \\ln p + (15-x_1) \\ln (1-p)\\] Sa dérivée est: \\[ \\frac{\\partial }{\\partial p } \\ln \\mathcal{L}(p;x_1)= \\frac{x_1}{p} - \\frac{15-x_1}{1-p} = \\frac{x_1 - 15 p}{p(1-p)} \\] qui s’annule pour \\(p = \\frac{x_1}{15} = \\frac{5}{15} = \\frac{1}{3}\\). Donc la valeur la plus vraisemblable de \\(p\\) est \\(\\frac{1}{3}\\). La vraisemblance maximale est \\(\\mathcal{L}(\\frac{1}{3};5) = 21.4\\%\\). La valeur qui rend maximale une fonction rend aussi maximal son logarithme. 3.4.2 L’estimateur de maximum de vraisemblance (EMV) En suivant le raisonnement précédent, pour \\(n\\) quelconque, il est logique de dire que la valeur la plus vraisemblable de \\(\\theta\\) est la valeur pour laquelle la probabilité d’observer \\(x_1 ,\\ldots,x_n\\) est la plus forte possible. Cela revient à faire comme si c’était l’éventualité la plus probable qui s’était produite au cours de l’expérience. Définition 3.4 L’estimation de maximum de vraisemblance de \\(\\theta\\) est la valeur \\(\\hat{\\theta}_n\\) de \\(\\theta\\) qui rend maximale la fonction de vraisemblance \\(\\mathcal{L}(\\theta;x_1 ,\\ldots,x_n)\\). L’estimateur de maximum de vraisemblance (EMV) de \\(\\theta\\) est la variable aléatoire correspondante. Comme dans l’exemple, dans la plupart des cas, la fonction de vraisemblance s’exprime comme un produit. Donc \\(\\hat{\\theta}_n\\) sera en général calculé en maximisant la log-vraisemblance: \\[ \\hat{\\theta}_{n}=\\arg \\max _{\\theta} \\,\\, \\ln \\mathcal{L}\\left(\\theta ; x_{1}, \\ldots, x_{n}\\right) \\] Quand \\(\\theta = (\\theta_1 ,\\ldots,\\theta_d ) \\in \\mathbb{R}^d\\) et que toutes les dérivées partielles ci-dessous existent, \\(\\hat{\\theta}_{n}\\) est solution du système d’équations appelées équations de vraisemblance: \\[ \\forall j \\in\\{1, \\ldots, d\\}, \\quad \\frac{\\partial}{\\partial \\theta_{j}} \\ln \\mathcal{L}\\left(\\theta ; x_{1}, \\ldots, x_{n}\\right)=0 \\] A priori, une solution de ce système d’équations pourrait être un minimum de la vraisemblance. Mais on peut montrer que la nature d’une fonction de vraisemblance fait que c’est bien un maximum que l’on obtient. Il est fréquent que le système des équations de vraisemblance n’ait pas de solution explicite. Dans ce cas, on le résoud par des méthodes numériques, comme la méthode de Newton-Raphson (lien 1 , lien 2 ). En , la maximisation numérique peut se faire à l’aide de la commande optim(). 3.4.2.1 Exemples 3.4.2.1.1 Exemple 1: loi de Bernoulli Soit les \\(X_i\\), sont de loi \\(\\mathcal{B}(p)\\), on a: \\[P\\left(X_{i}=x_{i} ; p\\right)=\\left\\{\\begin{array}{cc}{p} &amp; {\\text { si } x_{i}=1} \\\\ {1-p} &amp; {\\text { si } x_{i}=0}\\end{array}\\quad \\right\\} = p^{x_{i}}(1-p)^{1-x_{i}}\\] Donc la fonction de vraisemblance est: \\[\\mathcal{L}\\left(p ; x_{1}, \\ldots, x_{n}\\right)=\\prod_{i=1}^{n} P\\left(X_{i}=x_{i} ; p\\right)=\\prod_{i=1}^{n} p^{x_{i}}(1-p)^{1-x_{i}}=p^{\\sum_{i=1}^{n} x_{i}}(1-p)^{\\sum_{i=1}^{n}\\left(1-x_{i}\\right)}\\] D’où \\(\\ln \\mathcal{L}\\left(p ; x_{1}, \\ldots, x_{n}\\right)=\\left(\\sum_{i=1}^{n} x_{i}\\right) \\ln p+\\left(n-\\sum_{i=1}^{n} x_{i}\\right) \\ln (1-p)\\). Alors \\[\\frac{\\partial}{\\partial p} \\ln \\mathcal{L}\\left(p ; x_{1}, \\ldots, x_{n}\\right)=\\frac{\\sum_{i=1}^{n} x_{i}}{p}-\\frac{n-\\sum_{i=1}^{n} x_{i}}{1-p}=\\frac{\\sum_{i=1}^{n} x_{i}-n p}{p(1-p)}\\] qui s’annule pour \\(p=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}=\\overline{x}_{n}\\). Par conséquent, l’EMV de \\(p\\) est \\(\\hat{p}_n= \\overline{X}_n\\). L’EMV de \\(p\\) est \\(\\hat{p}_n= \\overline{X}_n\\). Le même que l’EMM de \\(p\\). 3.4.2.1.2 Exemple 2: loi exponentielle Si les \\(X_i\\) sont de loi \\(\\mathcal{E}(\\lambda)\\), la fonction de vraisemblance est: \\[\\mathcal{L}\\left(\\lambda ; x_{1}, \\ldots, x_{n}\\right)=\\prod_{i=1}^{n} f_{X_{i}}\\left(x_{i} ; \\lambda\\right)=\\prod_{i=1}^{n} \\lambda e^{-\\lambda x_{i}}=\\lambda^{n} e^{-\\lambda \\sum_{i=1}^{n} x_{i}}\\] D’où \\(\\ln \\mathcal{L}\\left(\\lambda ; x_{1}, \\ldots, x_{n}\\right)=n \\ln \\lambda-\\lambda \\sum_{i=1}^{n} x_{i}\\). Alors \\(\\frac{\\partial}{\\partial \\lambda} \\ln \\mathcal{L}\\left(\\lambda ; x_{1}, \\ldots, x_{n}\\right)=\\frac{n}{\\lambda}-\\sum_{i=1}^{n} x_{i}\\), qui s’annule pour \\(\\lambda=\\frac{n}{\\sum_{i=1}^{n} x_{i}}=\\frac{1}{\\overline{x}_{n}}\\). Par conséquent, l’EMV de \\(\\lambda\\) est \\(\\hat{\\lambda}_n = \\frac{1}{\\overline{X}_n}\\). 3.4.2.1.3 Exemple 3: loi normale Si les \\(X_i\\) sont de loi \\(\\mathcal{N}(m,\\sigma^2)\\), la fonction de vraisemblance est: \\[\\begin{aligned} \\mathcal{L}\\left(m, \\sigma^{2} ; x_{1}, \\ldots, x_{n}\\right) &amp;=\\prod_{i=1}^{n} f_{X_{i}}\\left(x_{i} ; m, \\sigma^{2}\\right)=\\prod_{i=1}^{n} \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{\\left(x_{i}-m\\right)^{2}}{2 \\sigma^{2}}} \\\\ &amp;=\\frac{1}{(\\sigma \\sqrt{2 \\pi})^{n}} e^{-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n}\\left(x_{i}-m\\right)^{2}} \\end{aligned}\\] D’où \\(\\ln \\mathcal{L}\\left(m, \\sigma^{2} ; x_{1}, \\ldots, x_{n}\\right)=-\\frac{n}{2} \\ln \\sigma^{2}-\\frac{n}{2} \\ln 2 \\pi-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n}\\left(x_{i}-m\\right)^{2}\\). On doit annuler les dérivées partielles de ce logarithme par rapport à \\(m\\) et \\(\\sigma^2\\). On a: \\(\\frac{\\partial}{\\partial m} \\ln \\mathcal{L}\\left(m, \\sigma^{2} ; x_{1}, \\ldots, x_{n}\\right)=-\\frac{1}{2 \\sigma^{2}} \\sum_{i=1}^{n}-2\\left(x_{i}-m\\right)=\\frac{1}{\\sigma^{2}}\\left(\\sum_{i=1}^{n} x_{i}-n m\\right)\\), qui s’annule pour \\(m=\\frac{1}{n} \\sum_{i=1}^{n} x_{i}=\\overline{x}_{n}\\). \\(\\frac{\\partial}{\\partial \\sigma^{2}} \\ln \\mathcal{L}\\left(m, \\sigma^{2} ; x_{1}, \\ldots, x_{n}\\right)=-\\frac{n}{2 \\sigma^{2}}+\\frac{1}{2 \\sigma^{4}} \\sum_{i=1}^{n}\\left(x_{i}-m\\right)^{2}\\), qui s’annule pour \\(\\sigma^2=\\frac{1}{n} \\sum_{i=1}^{n}\\left(x_{i}-m\\right)^{2}\\). \\(\\hat{m}_n\\) et \\(\\hat{\\sigma}_n^2\\) sont les valeurs de \\(m\\) et \\(\\sigma^2\\) qui vérifient les deux conditions en même temps. On a donc \\(\\hat{m}_{n}=\\overline{X}_{n}\\) et \\(\\hat{\\sigma}_{n}^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}_{n}\\right)^{2}=S_{n}^{2}\\). Remarque: Dans ces les trois exemples, la méthode des moments et la méthode du maximum de vraisemblance donnent les mêmes résultats. Ce n’est le cas que pour quelques lois de probabilité parmi les plus élémentaires. En fait, dans la plupart des cas, les deux méthodes fournissent des estimateurs différents. C’est le cas de la loi gamma. Cela amène à se poser la question de la qualité et de l’optimalité d’un estimateur, ce qui fait l’objet de la section suivante. 3.5 Qualité d’un estimateur En toute généralité, \\(\\theta\\) peut-être un paramètre à plusieurs dimensions, mais on supposera dans toute cette section et dans la suivante que \\(\\theta\\) est un réel. Cela signifie par exemple que, quand \\(X\\) est de loi normale \\(\\mathcal{N}(m,\\sigma^2)\\), on s’intéressera séparément à la qualité des estimateurs de \\(m\\) et de \\(\\sigma^2\\). Les estimateurs \\(T_n\\) considérés ici seront donc des variables aléatoires réelles. Pour \\(\\theta \\in \\mathbb{R}^d, d \\geq 2\\), toutes les notions de ces sections sont généralisables, mais la complexité des résultats augmente notablement. Par exemple, la notion de variance est remplacée par celle de matrice de covariance. 3.5.1 Estimateur sans biais et de variance minimale (ESBVM) Un estimateur \\(T_n\\) de \\(\\theta\\) sera un bon estimateur s’il est suffisamment proche, en un certain sens, de \\(\\theta\\). Il faut donc définir une mesure de l’écart entre \\(\\theta\\) et \\(T_n\\). On appelle cette mesure le risque de l’estimateur. On a intérêt à ce que le risque d’un estimateur soit le plus petit possible. Par exemple, les risques \\(T_n - \\theta,\\,\\, |T_n - \\theta|\\,\\, \\text{et} \\,\\, (T_n - \\theta)^2\\) expriment bien un écart entre \\(T_n\\) et \\(\\theta\\). Mais comme il est plus facile d’utiliser des quantités déterministes que des quantités aléatoires, on s’intéresse en priorité aux espérances des quantités précédentes. En particulier: Définition 3.5 (biais) On appelle le biais de \\(T_n\\) la quantité \\(E(T_n)-\\theta\\). Définition 3.6 (risque quadratique) On appelle le risque quadratique ou erreur quadratique moyenne: \\[ EQM(T_n)=E[(T_n-\\theta)^2]\\] Dans le cas du biais, le rique peut être nul: Définition 3.7 (estimateur sans biais) Un estimateur \\(T_n\\) de \\(\\theta\\) est sans biais si et seulement si \\(E(T_n) = \\theta\\). Il est biaisé si et seulement si \\(E(T_n) \\neq \\theta\\). Le biais mesure une erreur systématique d’estimation de \\(\\theta\\) par \\(T_n\\). Par exemple, si \\(E(T_n)-\\theta &lt; 0\\), cela signifie que \\(T_n\\) aura tendance à sous-estimer \\(\\theta\\). D’autre part, l’erreur quadratique moyenne (nommée aussi risque quadratique) s’écrit: \\[\\begin{aligned} E Q M\\left(T_{n}\\right) &amp; = E\\left[\\left(T_{n}-\\theta\\right)^{2}\\right]=E\\left[\\left(T_{n}-E\\left(T_{n}\\right)+E\\left(T_{n}\\right)-\\theta\\right)^{2}\\right] \\\\ &amp; = E\\left[\\left(T_{n}-E\\left(T_{n}\\right)\\right)^{2}\\right]+2 E\\left[T_{n}-E\\left(T_{n}\\right)\\right] E\\left[E\\left(T_{n}\\right)-\\theta\\right]+E\\left[\\left(E\\left(T_{n}\\right)-\\theta\\right)^{2}\\right] \\\\ &amp; = \\operatorname{Var}\\left(T_{n}\\right)+\\left[E\\left(T_{n}\\right)-\\theta\\right]^{2} \\\\ &amp; = \\text { Variance de l&#39;estimateur }+\\text { carré de son biais } \\end{aligned}\\] Si \\(T_n\\) est un estimateur sans biais, \\(EQM(T_n ) = Var(T_n )\\). On a donc intérêt à ce qu’un estimateur soit sans biais et de faible variance. Par ailleurs, on en déduit immédiatement que de deux estimateurs sans biais, le meilleur est celui qui a la plus petite variance. On a intérêt à ce qu’un estimateur soit sans biais et de faible variance. La variance d’un estimateur mesure sa variabilité. Si l’estimateur est sans biais, cette variabilité est autour de \\(\\theta\\). Si on veut estimer correctement \\(\\theta\\), il ne faut pas que cette variabilité soit trop forte. En pratique, si on observe plusieurs jeux de données similaires, on obtient une estimation de \\(\\theta\\) pour chacun d’entre eux. Alors si l’estimateur est de faible variance, ces estimations seront toutes proches les unes des autres, et s’il est sans biais leur moyenne sera très proche de \\(\\theta\\). Il est logique de s’attendre à ce que, plus la taille des données augmente, plus on a d’information sur le phénomène aléatoire observé, donc meilleure sera l’estimation. En théorie, avec une observation infinie, on devrait pouvoir estimer \\(\\theta\\) sans aucune erreur. On peut traduire cette affirmation par le fait que le risque de l’estimateur \\(T_n\\) doit tendre vers \\(0\\) quand la taille \\(n\\) de l’échantillon tend vers l’infini. Cela revient à dire que l’estimateur \\(T_n\\) doit converger, en un certain sens, vers \\(\\theta\\). Il s’agit en fait d’étudier la convergence de la suite de variables aléatoires \\(\\{T_n\\}_{n \\geq 1}\\) vers la constante \\(\\theta\\). On sait qu’il existe plusieurs types de convergence de suites de variables aléatoires. On peut étudier la convergence presque sûre ou la convergence en probabilité, mais on s’intéresse en général à la convergence en moyenne quadratique (ou convergence dans \\(L^2\\)). Définition 3.8 L’estimateur \\(T_n\\) converge en moyenne quadratique vers \\(\\theta\\) si et seulement si son erreur quadratique moyenne tend vers \\(0\\) quand \\(n\\) tend vers l’infini: \\[T_{n} \\stackrel{M Q}{\\longrightarrow} \\theta \\Leftrightarrow \\lim _{n \\rightarrow \\infty} E\\left[\\left(T_{n}-\\theta\\right)^{2}\\right]=0\\] Si \\(T_n\\) est sans biais, il sera convergent en moyenne quadratique si et seulement si sa variance tend vers \\(0\\) quand \\(n\\) tend vers l’infini. Finalement, on considèrera que le meilleur estimateur possible de \\(\\theta\\) est un estimateur sans biais et de variance minimale (ESBVM). Un tel estimateur n’existe pas forcément. 3.6 Propriétés des estimateurs des moments (EMM) Propriétés de \\(\\overline{X}_n\\) Si \\(\\theta = E(X)\\), alors l’EMM de \\(\\theta\\) est \\(\\hat{\\theta}_n = \\overline{X}_n\\). La justification de cette méthode est la loi des grands nombres, qui dit que \\(\\overline{X}_n\\) converge presque sûrement vers \\(E(X)\\). Donc, si \\(\\theta = E(X)\\), \\(\\overline{X}_n\\) est un estimateur de \\(\\theta\\) convergent presque sûrement. Autrement dit, si on a beaucoup d’observations, on peut estimer une espérance par une moyenne empirique. On peut en fait montrer facilement que \\(\\overline{X}_n\\) est un bon estimateur de \\(\\theta = E(X)\\), sans utiliser la loi des grands nombres: \\[ E\\left(\\overline{X}_{n}\\right)=E\\big[\\frac{1}{n} \\sum_{i=1}^{n} X_{i}\\big]=\\frac{1}{n} \\sum_{i=1}^{n} E\\left(X_{i}\\right)=\\frac{1}{n} n \\theta=\\theta \\] Donc \\(\\overline{X}_{n}\\) est un estimateur sans biais de \\(\\theta = E(X)\\). La variance de \\(\\overline{X}_{n}\\) est: \\[ \\operatorname{Var}\\left(\\overline{X}_{n}\\right)=\\operatorname{Var}\\left[\\frac{1}{n} \\sum_{i=1}^{n} X_{i}\\right]=\\frac{1}{n^{2}} \\sum_{i=1}^{n} \\operatorname{Var}\\left(X_{i}\\right)=\\frac{\\operatorname{Var}(X)}{n} \\] car les \\(X_i\\) sont indépendantes, donc la variance de leur somme est égale à la somme de leurs variances, qui sont toutes égales à \\(Var(X)\\). \\(Var(\\overline{X}_{n})\\) tend vers \\(0\\) quand \\(n\\) tend vers l’infini. Par conséquent: Propriété: La moyenne empirique \\(\\overline{X}_{n}\\) est un estimateur sans biais et convergent en moyenne quadratique de \\(E(X)\\). Propriétés de la variance empirique \\(S_{n}^{2}\\) On considère maintenant l’estimation de la variance de la loi des \\(X_i\\) par la variance empirique de l’échantillon \\(S_{n}^{2}=\\frac{1}{n} \\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}_{n}\\right)^{2}=\\frac{1}{n} \\sum_{i=1}^{n} X_{i}^{2}-\\overline{X}_{n}^{2}\\). Déterminons le biais de cet estimateur. \\[ \\begin{aligned} E\\left(S_{n}^{2}\\right) &amp;=E\\left[\\frac{1}{n} \\sum_{i=1}^{n} X_{i}^{2}-\\overline{X}_{n}^{2}\\right]=\\frac{1}{n} \\sum_{i=1}^{n} E\\left(X_{i}^{2}\\right)-E\\left(\\overline{X}_{n}^{2}\\right)=E\\left(X^{2}\\right)-E\\left(\\overline{X}_{n}^{2}\\right) \\\\ &amp;=\\operatorname{Var}(X)+E(X)^{2}-\\operatorname{Var}\\left(\\overline{X}_{n}\\right)-E\\left(\\overline{X}_{n}\\right)^{2} \\\\ &amp;=\\operatorname{Var}(X)+E(X)^{2}-\\frac{\\operatorname{Var}(X)}{n}-E(X)^{2}=\\left(1-\\frac{1}{n}\\right) \\operatorname{Var}(X) \\\\ &amp;=\\frac{n-1}{n} \\operatorname{Var}(X) \\neq \\operatorname{Var}(X) \\end{aligned} \\] Donc contrairement à ce qu’on pourrait croire, la variance empirique \\(S_n^2\\) n’est pas un estimateur sans biais de \\(Var(X)\\). Cet estimateur n’est qu’asymptotiquement sans biais. En revanche, on voit que \\(E\\left(\\frac{n}{n-1} S_{n}^{2}\\right)=\\frac{n}{n-1} E\\left(S_{n}^{2}\\right)=\\operatorname{Var}(X)\\). On pose donc \\({S_n^{*}}^2=\\frac{n}{n-1} S_{n}^{2}=\\frac{1}{n-1} \\sum_{i=1}^{n}\\big(X_{i}-\\overline{X}_{n}\\big)^{2}\\). \\({S_n^{*}}^2\\) est appelée variance estimée de l’échantillon. Le résultat précédent montre que c’est un estimateur sans biais de \\(\\operatorname{Var}(X)\\). Par ailleurs, on montre que \\[ \\operatorname{Var}\\left({S_n^{*}}^2\\right)=\\frac{1}{n(n-1)}\\left[(n-1) E\\left[(X-E(X))^{4}\\right]-(n-3) \\operatorname{Var}(X)^{2}\\right] \\] qui tend vers \\(0\\) quand \\(n\\) tend vers l’infini. Par conséquent: Propriété: La variance estimée \\({S_n^{*}}^2=\\frac{1}{n-1} \\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}_{n}\\right)^{2}\\) est un estimateur sans biais et convergent en moyenne quadratique de \\(Var(X)\\). La commande var(x) en donne la variance estimée, et non pas la variance empirique de l’échantillon x. On peut montrer également que \\({S_n^{*}}^2\\) et \\(S_{n}^{2}\\) convergent toutes les deux presque sûrement vers \\(Var(X)\\). Remarque 1: On n’a pas de résultat général sur la qualité de \\(S_{n}\\) comme estimateur de l’écart-type de la loi, \\(\\sigma(X)=\\sqrt{\\operatorname{Var}(X)}\\). A priori, ni \\(S_{n}\\) ni \\(S_{n}^{*}\\) ne sont des estimateurs sans biais de \\(\\sigma(X)\\). Remarque 2: Le simple exemple de la variance montre qu’un estimateur des moments n’est pas forcément sans biais. On peut montrer qu’un EMM est asymptotiquement sans biais et convergent presque sûrement. 3.7 Propriétés des estimateurs de maximum de vraisemblance (EMV) Un estimateur de maximum de vraisemblance n’est pas forcément unique (la vraisemblance peut avoir plusieurs maxima), ni sans biais, ni de variance minimale, ni efficace. Mais il possède d’excellentes propriétés asymptotiques (non évoqués dans ce cours). Le fait que l’EMV soit asymptotiquement sans biais et efficace fait que, si on a beaucoup de données, on est pratiquement certains que la méthode du maximum de vraisemblance est la meilleure méthode d’estimation possible. C’est pourquoi cette méthode est considérée comme globalement la meilleure et est utilisée de préference à toute autre méthode, y compris celle des moments. car \\(E(X)=1/\\lambda\\) si \\(X \\thicksim \\mathcal{E}(\\lambda)\\)↩ \\(S_n^2\\) est la variance empirique de l’échantillon \\(S_n^2= \\frac{1}{n} \\sum_{i=1}^n (X_i - \\overline{X}_n)^2 = \\frac{1}{n} \\sum_{i=1}^n X_i^2 - \\overline{X}_n^2\\)↩ "],
["exercices-2.html", "Exercices", " Exercices Exercice 3.1 (La variance corrigée) Soit \\(X\\) une variable aléatoire ayant une espérance \\(m\\) et une variance \\(\\sigma^2\\), sa variance empirique est \\(s_{n}^2=\\frac{1}{n} \\sum X_{i}^{2}-\\overline{X}_{n}^{2}\\) avec \\(\\overline{X}_{n}\\) la moyenne empirique de \\(X\\) et \\(\\frac{1}{n} \\sum X_{i}^{2}\\) la moyenne empirique de \\(X^{2}\\). Calculer \\(E\\left(\\overline{X}_{n}\\right)\\) et \\(V\\left(\\overline{X}_{n}\\right)\\) et en déduire \\(E(\\overline{X}_{n}^{2})\\). Montrer enfin que \\(E\\left(s_{n}^2\\right)=\\frac{n-1}{n} V(X)\\) et en déduire un estimateur sans biais de la variance (on nomme cet estimateur \\(s_{n}^{*^2}\\)). Exercice 3.2 (EMM) On considère l’échantillon statistique \\[1,0,2,1,1,0,1,0,0\\] Cacluler sa moyenne et sa variance empirique. En supposant que les données de cet échantillon sont des réalisations d’une variable de loi inconnue, donner une estimation non biaisée de l’espérance et de la variance de cette loi. On choisit de modéliser les valeurs de cet échantillon par une loi binomiale \\(\\mathcal{B}(2, p)\\). Utiliser la moyenne empirique pour proposer une estimation ponctuelle pour \\(p\\). Avec le même modèle, utiliser la variance empirique pour proposer une autre estimation de \\(p\\). On choisit de modéliser les valeurs de cet échantillon par une loi de Poisson \\(\\mathcal{P}(\\lambda)\\), qui a pour espérance \\(\\lambda\\). Quelle estimation ponctuelle proposez-vous pour \\(\\lambda\\)? Exercice 3.3 (EMV loi normale) Considérons un échantillon aléatoire \\((X_1,\\ldots,X_n)\\) (les \\(X_i\\) sont iid) et issu d’une variable alétoire parente \\(X \\thicksim \\mathcal{N}(\\mu,\\sigma^2)\\). Calculer les estimateurs de maximum de vraisemblance (EMV) de \\(\\mu\\) et \\(\\sigma^2\\). Ces estimateurs sont-ils sans biais? Exercice 3.4 (EMV loi géométrique) Les oiseaux d’un certain type prennent leur envol après avoir effectué quelques sauts sur le sol. On suppose que ce nombre \\(X\\) de sauts peut être modélisé par une distribution géométrique sur \\(\\mathbb{N}^*\\): \\[P(X=x)= p(1-p)^{x-1} \\quad x \\geq 1\\] Pour \\(n=130\\) oiseaux de ce type, on a relevé les données suivantes: Nombre de sauts \\(x\\) 1 2 3 4 5 6 7 8 9 10 11 12 Effectifs 48 31 20 9 6 5 4 2 1 1 2 1 Quel est l’estimateur du maximum de vraisemblance de \\(p\\)? Calculer la valeur de cet estimateur avec les données de l’échantillon. Exercice 3.5 (Comparaison d’estimateurs) Soit \\(X\\) une VAR de loi uniforme sur un intervalle \\([0, a]\\) où \\(a\\) est un paramètre inconnu, et on dispose de \\(\\left(X_{1}, \\ldots, X_{n}\\right)\\) un \\(n\\) -echantillon de \\(X\\). On note \\(\\overline{X}_{n}\\) la moyenne empirique de \\(X\\). Soit \\(T_{n}=2 \\overline{X}_{n}\\), l’estimateur par la méthode de moments de \\(a\\). Montrer que \\(T_{n}\\) est un estimateur sans biais de \\(a\\) et calculer son risque quadratique. Soit \\(T_{n}^{\\prime}=\\max \\left(X_{1}, \\ldots, X_{n}\\right)\\). Montrer que \\(T_n^{\\prime}\\) est l’estimateur par maximum de vraisemblance de \\(a\\). Donner la fonction de répartition de \\(T_{n}^{\\prime}\\). En déduire une densité de \\(T_{n}^{\\prime}\\), puis son biais et son risque quadratique. Soit \\(T_{n}^{\\prime \\prime}=\\frac{n+1}{n} T_{n}^{\\prime}\\). Déterminer son biais et son risque quadratique. Pour de grandes valeurs de \\(n\\), quel est le meilleur estimateur de \\(a\\)? Extra Exercice 3.6 On considère une variable aléatoire \\(X\\) de densité \\(f_{\\theta}\\) avec \\(-\\frac{1}{2} \\leq \\theta \\leq \\frac{1}{2}\\) et \\[ f_{\\theta}(x)=\\left\\{\\begin{array}{cl}{\\frac{1}{2}-\\theta} &amp; {\\text { si } x \\in[-1,0]} \\\\ {\\frac{1}{2}+\\theta} &amp; {\\text { si } x \\in[0,1]} \\\\ {0} &amp; {\\text { sinon }}\\end{array}\\right. \\] Représenter \\(f_{\\theta}\\) et justifier que \\(f_{\\theta}\\) est bien une densité de probabilité pour \\(-\\frac{1}{2} \\leq \\theta \\leq \\frac{1}{2}\\). Calculer l’espérance et la variance de \\(X\\). On considère maintenant \\(X_{1}, \\ldots X_{n}\\) des variables aléatoires indépendantes et de même loi. On suppose que la loi commune est de densité \\(f_{\\theta}\\) avec \\(-\\frac{1}{2} \\leq \\theta \\leq \\frac{1}{2}\\) inconnu. On va chercher à estimer \\(\\theta\\). Proposer un esitmateur \\(\\hat{\\theta}\\) de \\(\\theta\\) basé sur la méthode des moments. On prend \\(\\hat{\\theta}_{n}=\\frac{1}{n} \\sum X_{i}\\). Calculer son biais et son risque quadratique. On va maintenant s’intéresser à l’estimateur du maximum de vraisemblance de \\(\\theta\\). On note \\(N_{1}=\\sum_{i=1}^{n} \\mathbf{1}_{\\left\\{X_{i} \\geq 0\\right\\}}\\) et \\(N_{2}=\\sum_{i=1}^{n} \\mathbf{1}_{\\left\\{X_{i}&lt;0\\right\\}}\\). Soient \\(x_{1}, \\ldots, x_{n} \\in [-1,1]\\) et \\(-\\frac{1}{2} \\leq \\theta \\leq \\frac{1}{2}\\) écrire la vraisemblance du modèle au point \\(\\left(x_{1}, \\ldots, x_{n} ; \\theta\\right)\\) en fonction de \\(N_{1}, N_{2}\\) et \\(\\theta\\). Montrer que l’estimateur du maximum devraisemblance existe et vaut: \\[ \\hat{\\theta}_{M V}=\\frac{N_{1}-N_{2}}{2\\left(N_{1}+N_{2}\\right)}=\\frac{N_{1}}{n}-\\frac{1}{2} \\] On pose \\(1_{\\left\\{X_{i} \\geq 0\\right\\}}\\), pour \\(1 \\leq i \\leq n\\). Calculer l’espérance et la variance des variables aléatoires \\(Y_{i}\\). En déduire l’espérance et le risque quadratique de \\(\\hat{\\theta}_{M V}\\). Quel estimateur vaut-il mieux utiliser entre \\(\\hat{\\theta}\\) et \\(\\hat{\\theta}_{M V}\\)? Justifier. "],
["tp-illustration-numerique-des-methodes-destimation-avec-r.html", "Chapitre 4 TP illustration numérique des méthodes d’estimation avec R 4.1 Comparaison d’estimateurs 4.2 Le maximum de vraisemblance 4.3 Loi de Weibull", " Chapitre 4 TP illustration numérique des méthodes d’estimation avec R Il faut finir les TPs de la 1ère et 2ème séances avant de commencer ce TP. 4.1 Comparaison d’estimateurs Soit \\(\\left(X_{1}, \\ldots, X_{n}\\right)\\) un échantillon de la loi uniforme sur \\([0, \\theta]\\) où \\(\\theta\\) est un paramètre inconnu. On considère les estimateurs convergents (on dit aussi consistants) suivants du paramètre \\(\\theta\\). \\[ \\begin{aligned} T_{1}=&amp; \\frac{2}{n} \\times\\left(X_{1}+\\ldots+X_{n}\\right) \\\\ T_{2}=&amp; \\sqrt{\\frac{3}{n} \\times\\left(X_{1}^{2}+\\ldots+X_{n}^{2}\\right)} \\\\ T_{3}=&amp;\\left(\\frac{4}{n} \\times\\left(X_{1}^{3}+\\ldots+X_{n}^{3}\\right)\\right)^{\\frac{1}{3}} \\\\ T_{4}=&amp;\\left(\\frac{3}{2 n} \\times(\\sqrt{X_{1}}+\\ldots+\\sqrt{X_{n}})\\right)^{-2} \\\\ T_{5}=&amp;\\left(\\frac{1}{2 n} \\times\\left(\\frac{1}{\\sqrt{X_{1}}}+\\ldots+\\frac{1}{\\sqrt{X_{n}}}\\right)\\right)^{-2} \\\\ T_{6}=&amp; \\exp (1) \\times\\left(X_{1} \\times \\ldots \\times X_{n}\\right)^{\\frac{1}{n}} \\\\ T_{7}=&amp; \\max \\left\\{X_{1}, \\ldots, X_{n}\\right\\} \\\\ T_{8}=&amp; \\frac{n+1}{n} \\max \\left\\{X_{1}, \\ldots, X_{n}\\right\\} \\end{aligned} \\] \\(T1\\) est l’emm de \\(\\theta\\). \\(T7\\) est l’emv de \\(\\theta\\) (biaisé). \\(T8\\) est l’emv corrigé de \\(\\theta\\). 1. Choisir une valeur de \\(\\theta\\) et simuler 1000 échantillons de taille 100 de la loi uniforme sur \\([0, \\theta]\\). Calculer pour chacun de ces échantillons la valeur prise par les 8 estimateurs. On pourra ensuite créer une matrice ayant 1000 lignes et 8 colonnes dont la jème colonne contient les 1000 réalisations de l’estimateur \\(T_{j}\\): T &lt;- cbind(T1,T2,T3,T4,T5,T6,T7,T8) 2. Calculer la moyenne empirique et la variance empirique des 8 échantillons de taille 1000 ainsi obtenus. En déduire une estimation du biais et de l’erreur quadratique de chacun des 8 estimateurs. On rappelle que pour un estimateur \\(T\\), le biais est \\(E[T]-\\theta\\) et l’erreur quadratique est \\(E\\left[(T-\\theta)^{2}\\right]\\). 3. Quels estimateus sont les moins biaisés? Et les estimateurs de risque quadratique minimale? 4. Représenter sur un même graphique les boites à moustaches (boxplots) des 8 estimateurs. Superposer sur le même graphique la vraie valeur du paramètre, en rouge. Commenter la pertinence de chacun des estimateurs: lequel préfereriez-vous utiliser? On pourra utiliser boxplot(data.frame(T)) abline(h=theta,col=&quot;red&quot;) 4.2 Le maximum de vraisemblance Pour cette partie, imaginons qu’on a une série de valeurs, ça peut par exemple être l’âge de 1000 étudiants pris au hasard dans une ville. Nous avons tracé l’histogramme de l’échantillon et obtenu le suivant: On peut voir ici que la distribution des valeurs suit approximativement une loi normale avec une moyenne aux alentours de 22 et un écart-type difficile à évaluer au premier coup d’oeil. En effet, pour obtenir les données de cet échantillon, j’ai généré un échantillon suivant la loi normale de moyenne 22 et d’écart-type mystère que vous devez découvrir en utilisant la méthode du maximum de vraisemblance. Les données ont été générée avec la commande suivante: data = rnorm(1000, mean = 22, sd = mystere) # où j&#39;ai caché ici la valeur mystère de l&#39;écart-type utilisé. Les données de l’échantillon obtenu se trouvent dans le fichier mystere.txt. Pour lire les données de l’échantillon du fichier mystere.txt, vous pouvez les copier et les saisir dans un vecteur en utilisant la fonction c() ou bien utiliser la fonction scan(). Par exemple: donnees &lt;- scan(\"mystere.txt\", sep=\",\") Sur l’intervalle \\([1,4]\\), chercher la valeur de \\(\\sigma\\) qui maximise la vraisemblance. On la notera \\(\\hat{\\sigma}\\). On procédera de façon empirique en représentant le graphe de la Log-vraisemblance sur l’intervalle \\([1,4]\\). On se contentera d’une valeur approchée de \\(\\hat{\\sigma}\\) à \\(10^{−1}\\) près. Quelle estimation de \\(\\sigma\\) par maximum de vraisemblance proposez-vous? Re-tracer ensuite l’histogramme montré ci dessus en superposant la densité de la loi normale de moyenne 22 et d’écart-type estimé. 4.3 Loi de Weibull En fiabilité, la durée de vie \\(X\\) d’un composant électronique est souvent modélisée par une loi de Weibull de paramètre \\(\\theta&gt;0\\). Une variable aleatoire \\(X\\) distribuée selon une loi de Weibull de paramètre \\(\\theta\\) a pour densité: \\[\\begin{equation} f(x)=\\theta x^{\\theta-1} \\exp (-x^{\\theta}) \\, \\times \\, 1_{\\mathbb{R}^+} \\tag{4.1} \\end{equation}\\] A noter que quand \\(\\theta=1\\) la loi de Weibull coincide avec la loi Exponentielle de paramètre égal à \\(1\\). L’interprétation du paramètre \\(\\theta\\) est la suivante. Quand \\(\\theta&gt;1\\) cela signifie que la propension à tomber en panne à l’instant \\(t\\) augmente avec \\(t\\), quand \\(\\theta&lt;1\\), c’est l’inverse. Enfin, quand \\(\\theta=1\\) la propension à tomber en panne à l’instant \\(t\\) ne dépent pas de \\(t\\) (la loi exponentielle est sans mémoire). On entend ici par panne toute défaillance du composant électronique rendant celui-ci hors d’usage. 1. Représenter le graphe de la densité d’une loi de Weibull quand \\(\\theta = 1/2, 1, 2,\\text{et } 3\\). On se limitera à l’intervalle \\([0,5]\\) pour \\(x\\). Pour cette question, vous devez créer la fonction dweibull qui calcule la densité comme définie dans l’équation (4.1). Pour estimer \\(\\theta\\) on dispose de la durée de vie de \\(n=1000\\) composants. Les données (en milliers d’heures) se trouvent dans le fichier weibull.txt. 2. Chercher la valeur de \\(\\theta\\) qui maximise la vraisemblance. (\\(\\theta \\in [0,5]\\)). On la notera \\(\\hat{\\theta}\\). 3. On se propose maintenant d’estimer \\(\\theta\\) en utilisant le fait que \\(E(X)=\\Gamma(1+1/\\theta)\\). (Méthode de moments) Indication: Chercher dans un premier temps une estimation de la durée de vie moyenne du composant électronique, autrement dit de \\(E(X)\\), puis en déduire une estimation de \\(\\theta\\). Remarque: Il existe sour une commande qui permet de résoudre des équations. Par exemple, pour résoudre \\(f(x)=3\\), sur l’intervalle \\([0,3]\\), on utilise la commande optimize(function(x) abs(3-f(x)), c(0,3)). 4. Comparer les deux estimations, puis interpréter les résultats obtenus. Pour l’interprétation pouvez afficher l’histogramme de l’échantillon et superposer les densités de Weibull avec les deux estimations de \\(\\theta\\). "],
["intervalle-de-confiance.html", "Chapitre 5 Intervalle de confiance", " Chapitre 5 Intervalle de confiance "],
["tests-dhpotheses.html", "Chapitre 6 Tests d’hpothèses", " Chapitre 6 Tests d’hpothèses "],
["variables-aleatoires-discretes.html", "Variables Aléatoires Discrètes Notions de Probabilités Notion de variable aléatoire réelle (v.a.r.) Variables aléatoires discrètes Moments d’une variable aléatoire discrète Couple de variables aléatoires discrètes Lois usuelles discrètes", " Variables Aléatoires Discrètes Notions de Probabilités Espace Probabilisable Exemple fondamental: Considérons le jeu du lancé d’un dé. Expérience aléatoire \\(\\varepsilon\\) : “lancer un dé équilibré” \\(\\longleftarrow\\) Action. Univers: l’ensemble de tous les résultats possibles de cette expérience aléatoire \\[\\Omega= \\{1,2,3,4,5,6\\}\\] Evénements: Dans cette expérience aléatoire, on peut s’intéresser à des événements plus complexes qu’un simple résultat élémentaire. L’ensemble de parties de \\(\\Omega\\), appelé \\(\\mathcal{P}({\\Omega})\\), est l’ensemble des sous-ensembles de \\(\\Omega\\). Une famille \\(\\mathcal{A}\\) de parties (i.e. de sous ensembles) de \\(\\Omega\\). Ces parties sont appelées des événements. On dit que l’événement \\(A\\) s’est réalisé si et seulement si le résultat \\(\\Omega\\) de \\(\\Omega\\) qui s’est produit appartient à \\(A\\). Tribu: On appelle tribu sur \\(\\Omega\\), toute famille \\(\\mathcal{A}\\) de parties de \\(\\Omega\\) vérifiant: \\(\\Omega \\in \\mathcal{A}\\). si \\(A \\in \\mathcal{A}\\), alors \\(\\bar{A} \\in \\mathcal{A}\\). si \\((A_n)_{n\\in\\mathbb{N}}\\) est une suite d’éléments de \\(\\mathcal{A}\\), alors \\(\\bigcup\\limits_{n\\in\\mathbb{N}} A_n \\in \\mathcal{A}\\). \\(({\\Omega},\\mathcal{A})\\) est un espace probibilisable. Notions sur les Evénements Soit \\(({\\Omega},\\mathcal{A})\\) un espace probibilisable: L’ensemble \\(\\mathcal{A}\\) est appelé tribu des événements. Les éléments de \\(\\mathcal{A}\\) s’appellent les événements. L’événement \\(\\Omega\\) est appelé événement certain. L’événement \\(\\emptyset\\) est appelé événement impossible. Opérations sur les événements. Soient \\(A\\) et \\(B\\) deux événements: \\(\\bar{A}\\) est l’événement contraire de \\(A\\) (on note aussi \\(A^c\\)). \\(\\bar{A}={\\Omega}\\setminus A\\). \\(\\bar{A}\\) se réalise si et seulement si \\(A\\) ne se réalise pas. \\(A\\, {\\cap} \\,B\\) est l’événement &lt;&lt;\\(A\\) et \\(B\\)&gt;&gt;. \\(A\\, {\\cap} \\,B\\) se réalise lorsque les deux événements se réalisent. \\(A {\\cup} B\\) est l’événement &lt;&lt;\\(A\\) ou \\(B\\)&gt;&gt;. \\(A {\\cup} B\\) se réalise lorsque au moins un des deux événements se réalise. Incompatibilité: \\(A\\) et \\(B\\) sont incompatibles si leur réalisation simultanée est impossible: \\(A \\cap B = \\emptyset\\). Implication: \\(A\\) implique \\(B\\) signifie que si \\(A\\) se réalise, alors \\(B\\) se réalise aussi: \\(A \\subset B\\). Espace Probabilisé Soit \\(({\\Omega},\\mathcal{A})\\) un espace probabilisable. On appelle probabilité sur \\(({\\Omega},\\mathcal{A})\\), toute application \\[P : \\mathcal{A} \\rightarrow \\mathbb{R}\\] vérifiant: \\(\\forall A \\in \\mathcal{A}, P(A) \\geq 0\\). \\(P({\\Omega})=1\\). \\(\\forall (A_n)_{n\\in\\mathbb{N}^*} \\in \\mathcal{A}^{\\mathbb{N}^*}\\), une suite d’éléments de \\(\\mathcal{A}\\) deux à deux incompatibles, on a: \\[P(\\bigcup\\limits_{n\\in\\mathbb{N}^*} A_n) = \\sum_{n=1}^{+\\infty} P(A_n)\\] Le triplet \\(({\\Omega},\\mathcal{A},P)\\) est appelé espace probabilisé. Probabilité: Propriétés \\(P(\\emptyset) = 0\\). \\(P(A_1 \\cup A_2 ) = P(A_1 ) + P(A_2 )-P(A_1 \\cap A_2 )\\). Si \\(A_1\\) et \\(A_2\\) sont incompatibles, \\(A_1 \\cap A_2 = \\emptyset\\), \\(P(A_1 \\cup A_2 ) = P(A_1 ) + P(A_2 )\\). \\(P(A_1 \\cup A_2 \\cup A_3 ) = P(A_1 ) + P(A_2 ) + P(A_3 ) - P(A_1 \\cap A_2 ) - P(A_1 \\cap A_3 ) - P(A_2 \\cap A_3 )+P(A_1 \\cap A_2 \\cap A_3 )\\). \\(P(\\bar{A}) = 1-P(A)\\). \\(P(B\\setminus A)=P(B)-P(B\\cap A)\\). \\(A \\subset B \\Rightarrow P(A) \\leq P(B)\\). Probabilité uniforme sur \\(\\Omega\\) fini Soit \\(\\Omega\\) un univers fini. On dit que \\(P\\) est la probabilité uniforme sur l’espace probabilisable \\(({\\Omega},P({\\Omega}))\\) si: \\[\\forall {\\omega},{\\omega}&#39; \\in {\\Omega}, \\quad \\quad P(\\{{\\omega}\\})=P(\\{{\\omega}&#39;\\})\\] On dit aussi qu’il y a équiprobabilité des événements élémentaires. Soit \\(({\\Omega}, \\mathcal{P}({\\Omega}), P)\\) un espace probabilisé fini. Si \\(P\\) est la probabilité uniforme, alors \\[\\forall A \\in \\mathcal{A}, \\quad \\quad P(A)=\\frac{Card(A)}{Card({\\Omega})}\\] Probabilité conditionnelle Soit \\(({\\Omega},\\mathcal{A},P)\\) une espace probabilisé et \\(B \\in \\mathcal{A}\\) tel que \\(P(B) &gt; 0\\). L’application \\(P_B\\) définie sur \\(\\mathcal{A}\\) par: \\[P_B(A) = P(A|B) =\\frac{P(A\\cap B)}{P(B)}, \\quad \\quad \\forall A \\in \\mathcal{A}\\] est une probabilité sur \\(({\\Omega}, \\mathcal{A})\\); elle est appelée la probabilité conditionnelle sachant \\(B\\). C’est la probabilité pour que l’événement \\(A\\) se produise sachant que l’événement \\(B\\) s’est produit. Remarque: \\((A|B)\\) n’est pas un événement! On utilise la notation \\(P(A|B)\\) par simplicité, mais c’est \\(P_B (A)\\) qui est correcte. Formule des probabilités composées: \\[P(A\\cap B) = P(A|B)P(B) = P(B|A)P(A)\\] Formule des probabilités totales: \\(\\forall A \\in \\mathcal{A}, \\quad P(A) = P(A \\cap B) + P(A \\cap \\bar{B} )\\) On appelle système complet d’événements (SCE), toute partition dénombrable de \\(\\Omega\\) formée d’éléments de \\(A\\); c-à-d tout ensemble dénombrable d’événements, deux à deux incompatibles et dont l’union dénombrable est l’événement certain. Soit \\((B_n)_{n\\geq 0}\\) un SCE de \\(\\Omega\\). On a: \\[\\forall A \\in \\mathcal{A},\\quad \\quad P(A)=\\sum_{n\\geq 0} P(A \\cap B_n)\\] Indépendance: Les événement \\(A\\) et \\(B\\) sont indépendants ssi \\(P(A\\cap B)=P(A)P(B)\\). Formule de Bayes Première formule de Bayes Soit \\(({\\Omega},\\mathcal{A},P)\\) une espace probabilisé. Pour tous événements \\(A\\) et \\(B\\) tels que \\(P(A) \\neq 0\\) et \\(P(B) \\neq 0\\), on a: \\[P(B|A) = \\frac{P(A|B)P(B)}{P(A)}\\] Deuxième formule de Bayes Soit \\(({\\Omega},\\mathcal{A},P)\\) une espace probabilisé et \\((B_n)_{n\\geq 0}\\) un SCE de \\(\\Omega\\) t.q. pour tout \\(n\\geq 0 \\,\\, P(B_n)\\neq 0\\). On a pour tout \\(A \\in \\mathcal{A}\\) t.q. \\(P(A)\\neq 0\\) \\[P(B_i|A) = \\frac{P(A|B_i) P(B_i)}{\\sum_{n\\geq 0} P(A|B_n) P(B_n)} \\quad \\quad \\forall i \\geq 0\\] Notion de variable aléatoire réelle (v.a.r.) Après avoir réalisé une expérience aléatoire, il arrive bien souvent qu’on s’intéresse plus à une fonction du résultat qu’au résultat lui-même. Expliquons ceci au moyen des exemples suivants: lorsqu’on joue au dés, certains jeux accordent de l’importance à la somme obtenue sur deux dés, 7 par exemple, plutôt qu’à la question de savoir si c’est la paire (1,6) qui est apparue, ou (2,5), (3,4), (4,3), (5,2) ou plutôt (6,1). Dans le cas du jet d’une pièce, il peut être plus intéressant de connaître le nombre de fois où le côté pile est apparue plutôt que la séquence détaillée des jets pile et face. Ces grandeurs auxquelles on s’intéresse sont en fait des fonctions réelles définies sur l’ensemble fondamental et sont appelées variables aléatoires. Du fait que la valeur d’une variable aléatoire est déterminée par le résultat de l’expérience, il est possible d’attribuer une probabilité aux différentes valeurs que la variable aléatoire peut prendre. Soient \\(\\varepsilon\\) une expérience aléatoire et \\((\\Omega,\\mathcal{A},P)\\) un espace probabilisé lié à cette expérience. Dans de nombreuses situations, on associe à chaque résultat \\(\\omega \\in \\Omega\\) un nombre réel noté \\(X(\\omega)\\); on construit ainsi une application \\(X : \\Omega \\rightarrow \\mathbb{R}\\). Historiquement, \\(\\varepsilon\\) était un jeu et \\(X\\) représentait le gain du joueur. Exemple: Un joueur lance un dé équilibré à 6 faces numérotées de 1 à 6, et on observe le numéro obtenu. Si le joueur obtient 1, 3 ou 5, il gagne 1 euro. S’il obtient 2 ou 4, il gagne 5 euros. S’il obtient 6, il perd 10 euros. Selon l’expérience aléatoire (lancer d’un dé équilibré) l’ensemble fondamental est \\(\\Omega = \\{1,2,3,4,5,6\\}\\), \\(\\mathcal{A} = \\mathcal{P}(\\Omega)\\) et \\(P\\) l’équiprobabilité sur \\((\\Omega,\\mathcal{A})\\). Soit \\(X\\) l’application de \\(\\Omega\\) dans \\(\\mathbb{R}\\) qui à tout \\(\\omega \\in \\Omega\\) associe le gain correspondant. On a donc \\(X(1) = X(3) = X(5) = 1\\) \\(X(2) = X(4) = 5\\) \\(X(6) = -10\\) On dit que \\(X\\) est une variable aléatoire sur \\(\\Omega\\). On peut s’intéresser à la probabilité de gagner 1 euro, c’est-à-dire d’avoir \\(X(\\omega) = 1\\), ce qui se réalise si et seulement si \\(\\omega \\in \\{1,3,5\\}\\). La probabilité cherchée est donc égale à \\(P(\\{1,3,5\\}) = 1/2\\). On écrira aussi \\(P(X=1) = 1/2\\). On pourra donc considérer l’événement : \\[\\{X=1\\} = \\{\\omega \\in \\Omega / X(\\omega) = 1\\} = \\{\\omega \\in \\Omega / X(\\omega) \\in \\{1\\}\\} = X^{-1} (\\{1\\}) = \\{1,3,5\\}.\\] On aura du même \\(P(X=5) = 1/3\\) et \\(P(X=-10) = 1/6\\). Ce que l’on peut présenter dans un tableau \\(x_i\\) \\(-10\\) \\(1\\) \\(5\\) \\(p_i=P(X = x_i)\\) \\(1/6\\) \\(1/2\\) \\(1/3\\) Cela revient à considérer un nouvel ensemble d’événements élémentaires: \\[\\Omega_X = X(\\Omega)= \\{-10,1,5\\}\\] et à munir cet ensemble de la probabilité \\(P_X\\) définie par le tableau des \\(P(X=x_i)\\) ci dessus. Cette nouvelle probabilité s’appelle loi de la variable aléatoire X. Remarquer que \\[P(\\bigcup_{x_i \\in \\Omega_X} \\{X=x_i\\}) = \\sum_{x_i \\in \\Omega_X} P(X=x_i) = 1\\] Dans ce chapitre, nous traitons le cas où \\(X(\\Omega)\\) est dénombrable. La variable aléatoire est alors dite discrète. Sa loi de probabilité, qui peut être toujours définie par sa fonction de répartition, le sera plutôt par les probabilités individuelles. Nous définirons les deux caractéristiques numériques principales d’une variable aléatoire discrète, l’espérance caractéristique de valeur centrale, et la variance, caractéristique de dispersion. Nous définirons aussi les couples de variables aléatoires. Variables aléatoires discrètes Définition, loi de probabilité Définition 6.1 On dit qu’une variable aléatoire réelle (v.a.r.) \\(X\\) est discrète (v.a.r.d.) si l’ensemble des valeurs que prend \\(X\\) est fini ou infini dénombrable. Si on suppose \\(X(\\Omega)\\) l’ensemble des valeurs de \\(X\\) qui admet un plus petit élément \\(x_1\\). Alors la v.a.r.d. \\(X\\) est entièrement définie par: L’ensemble \\(X(\\Omega)\\) des valeurs prises par \\(X\\), rangées par ordre croissant: \\(X(\\Omega) = \\{x_1, x_2,\\ldots,x_i,\\ldots\\}\\) avec \\(x_1 \\leq x_2 \\leq \\ldots \\leq x_i \\leq \\ldots\\). La loi de probabilité définie sur \\(X(\\Omega)\\) par \\[p_i = P(X=x_i) \\,\\,\\,\\,\\, \\forall \\,\\, i=1,2,\\ldots\\] Remarques: Soit \\(B\\) un ensemble de \\(\\mathbb{R}\\), \\[P(X \\in B) = \\sum_{i / x_i \\in B} p(x_i)\\] En particulier \\[P( a &lt; X \\leq b) = \\sum_{i / a &lt; x_i \\leq b} p(x_i)\\] Bien sûr tous les \\(p(x_i)\\) sont positives et \\(\\sum_{i=1}^{\\infty} p(x_i) =1\\). Si \\(X\\) ne prend qu’un petit nombre de valeurs, cette loi est généralement présentée dans un tableau. Fonction de répartition d’une variable aléatoire discrète Définition 6.2 On appelle fonction de répartition de la v.a. \\(X\\), qu’on note \\(F(a)\\) de la v.a.r.d. \\(X\\), ou \\(F_X(a)\\), la fonction définie pour tout réel \\(a\\), \\(-\\infty &lt; a &lt; \\infty\\), par \\[F(a)=P(X \\leq a)=\\sum_{i / x_{i}\\leq a} P(X=x_{i})\\] Cette valeur représente la probabilité de toutes les réalisations inférieures ou égales au réel \\(a\\). Propriétés: Voici quelques propriétés de cette fonction: C’est une fonction en escalier (constante par morceaux). \\(F(a) \\leq 1\\) car c’est une probabilité. \\(F(a)\\) est continue à droite. \\(\\lim\\limits_{a\\to - \\infty} F(a) = 0\\) et \\(\\lim\\limits_{a\\to\\infty} F(a) = 1\\) La fonction de répartition caractérise la loi de \\(X\\), autrement dit: \\(F_{X} = F_{Y}\\) si et seulement si les variables aléatoires \\(X\\) et \\(Y\\) ont la même loi de probabilité. Fonction de répartition et probabilités sur \\(X\\) Tous les calculs de probabilité concernant \\(X\\) peuvent être traités en termes de fonction de répartition. Par exemple, \\[P(a &lt; X \\leq b) = F(b) - F(a) \\quad \\quad \\text{pour tout } a &lt; b\\] On peut mieux s’en rendre compte en écrivant \\(\\{X \\leq b\\}\\) comme union des deux événements incompatibles \\(\\{X \\leq a\\}\\) et \\(\\{ a &lt; X \\leq b\\}\\), soit \\[\\{X \\leq b\\} = \\{X \\leq a\\} \\cup \\{ a &lt; X \\leq b\\}\\] et ainsi \\[P(X \\leq b) = P(X \\leq a) + P(a &lt; X \\leq b)\\] ce qui établit l’égalité ci dessus. On peut déduire de \\(F\\) les probabilités individuelles par: \\[p_{i}=F(x_{i})-F(x_{i-1})\\quad \\quad \\text{pour } 1 \\leq i \\leq n\\] Exemple: On joue trois fois à pile ou face. Soit \\(X\\) la variable aléatoire “nombre de pile obtenus”. Ici \\(\\Omega=\\{P, F\\}^3\\), et donc \\[X(\\Omega)=\\{0, 1, 2, 3\\}.\\] On a \\(card(\\Omega)=2^3=8\\). Calculons par exemple \\(P(X=1)\\), c’est à dire la probabilité d’avoir exactement une pile. \\[X^{-1}(1)=\\{(P, F, F), (F, P, F), (F, F, P) \\}\\] D’où \\(P(X=1)=\\frac{3}{8}\\). En procédant de la même façon, on obtient la loi de probabilité de \\(X\\): \\(k\\) \\(0\\) \\(1\\) \\(2\\) \\(k\\) \\(P(X = k)\\) \\(\\frac{1}{8}\\) \\(\\frac{3}{8}\\) \\(\\frac{3}{8}\\) \\(\\frac{1}{8}\\) La fonction de répartition de \\(X\\) est donc donnée par: \\[F(x) = \\left\\{ \\begin{array}{l l} 0 &amp; \\quad \\text{si $x&lt;0$}\\\\ 1/8 &amp; \\quad \\text{si $0 \\leq x &lt; 1$}\\\\ 1/2 &amp; \\quad \\text{si $1 \\leq x &lt; 2$}\\\\ 7/8 &amp; \\quad \\text{si $2 \\leq x &lt; 3$}\\\\ 1 &amp; \\quad \\text{si $x \\geq 3$}\\\\ \\end{array} \\right.\\] Le graphe de cette dernière est représentée dans la figure suivante: Exemple: Soit \\(A\\) un événement quelconque. On appelle variable aléatoire indicatrice de cet événement \\(A\\), la variable aléatoire définie par: \\[X(\\omega) = \\left\\{ \\begin{array}{l l} 1 &amp; \\quad \\text{si $\\omega \\in A$}\\\\ 0 &amp; \\quad \\text{si $\\omega \\in \\bar{A}$}\\\\ \\end{array} \\right.\\] et notée \\(X=1_A\\). Ainsi: \\[P(X=1)=P(A)=p\\] \\[P(X=0)=P(\\bar{A})=1-p\\] La fonction de répartition de \\(X\\) est donc donnée par: \\[F(x) = \\left\\{ \\begin{array}{l l} 0 &amp; \\quad \\text{si $x&lt;0$}\\\\ 1-p &amp; \\quad \\text{si $0 \\leq x &lt; 1$}\\\\ 1 &amp; \\quad \\text{si $x \\geq 1$}\\\\ \\end{array} \\right.\\] On peut prendre par exemple le cas d’un tirage d’une boule dans une urne contenant 2 boules blanches et 3 boules noires. Soit \\(A:\\text{&quot;obtenir une boule blanche&quot;}\\) et \\(X\\) la variable indicatrice de \\(A\\). La loi de probabilité de \\(X\\) est alors \\(k\\) \\(0\\) \\(1\\) \\(P(X = k)\\) \\(\\frac{3}{5}\\) \\(\\frac{2}{5}\\) et sa fonction de répartition est: \\[F(x) = \\left\\{ \\begin{array}{l l} 0 &amp; \\quad \\text{si $x&lt;0$}\\\\ 3/5 &amp; \\quad \\text{si $0 \\leq x &lt; 1$}\\\\ 1 &amp; \\quad \\text{si $x \\geq 1$}\\\\ \\end{array} \\right.\\] Moments d’une variable aléatoire discrète Espérance mathématique Définition 6.3 Pour une variable aléatoire discrète \\(X\\) de loi de probabilité \\(p(.)\\), on définit l’espérance de \\(X\\), notée \\(E(X)\\), par l’expression \\[E(X)=\\sum_{i \\in \\mathbb{N}} x_{i} p(x_i)\\] En termes concrets, l’espérance de \\(X\\) est la moyenne pondérée des valeurs que \\(X\\) peut prendre, les poids étant les probabilités que ces valeurs soient prises. Reprenons l’exemple où on joue 3 fois à pile ou face. L’espérance de \\(X=\\)“nombre de pile obtenus” est égal à: \\[E(X)=0 \\times \\frac{1}{8}+1 \\times \\frac{3}{8}+2 \\times \\frac{3}{8}+3 \\times \\frac{1}{8}=1.5\\] Dans le cas de la loi uniforme sur \\(X(\\Omega)=\\{x_{1},\\ldots, x_{k}\\}\\), c’est à dire avec équiprobabilité de toutes les valeurs \\(p_{i}=1/k\\), on obtient: \\[E(X)=\\frac{1}{k} \\sum_{i=1}^k x_{i}\\] et dans ce cas \\(E(X)\\) se confond avec la moyenne arithmétique simple \\(\\bar{x}\\) des valeurs possibles de \\(X\\). Pour le jet d’un dé équilibré par exemple: \\[E(X)=\\frac{1}{6} \\sum_{i=1}^6 i=\\frac{7}{2}=3.5\\] Espérance d’une fonction d’une variable aléatoire Théorème 6.1 (Théorème du transfert) Si X est une variable aléatoire discrète pouvant prendre ses valeurs parmi les valeurs \\(x_i\\), \\(i \\geq 1\\), avec des probabilités respectives \\(p(x_i)\\), alors pour toute fonction réelle \\(g\\) on a \\[E(g(X)) = \\sum_i g(x_i)p(x_i)\\] Exemple6.1 Soit \\(X\\) une variable aléatoire qui prend une des trois valeurs \\(\\{-1,0,1\\}\\) avec les probabilités respectives \\[P(X=-1) = 0.2 \\quad \\quad P(X=0)=0.5 \\quad \\quad P(X=1) = 0.3\\] Calculer \\(E(X^2)\\). Solution: Première approche: Soit \\(Y=X^2\\). La distribution de \\(Y\\) est donnée par \\[\\begin{aligned} P(Y=1) &amp;= P(X=-1) + P(X=1) = 0.5 \\\\ P(Y=0) &amp;= P(X=0) = 0.5 \\end{aligned}\\] Donc \\[E(X^2)=E(Y) = 1(0.5) + 0(0.5) = 0.5\\] Deuxième approche: En utilisant le théorème \\[\\begin{aligned} E(X^2) &amp;= (-1)^2(0.2) + 0^2(0.5) + 1^2 (0.3) \\\\ &amp;= 1(0.2+0.3)+0(0.5)=0.5 \\end{aligned}\\] Remarquer que \\[0.5=E(X^2) \\neq (E(X))^2 = 0.01\\] Linéarité de l’espérance Propriétés de l’espérance \\(E(X+a)=E(X)+a, \\quad a \\in \\mathbb{R}\\) résultat qui se déduit de: \\[\\sum_{i}p_{i}(x_{i}+a)= \\sum_{i}p_{i}x_{i}+\\sum_{i}ap_{i}=\\sum_{i}p_{i}x_{i}+a \\sum_{i}p_{i}=\\sum_{i}p_{i}x_{i}+a\\] \\(E(aX)=aE(X), \\quad a\\in \\mathbb{R}\\) il suffit d’écrire: \\[\\sum_{i}p_{i}a x_{i}=a\\sum_{i}p_{i}x_{i}\\] \\(E(X+Y)=E(X)+E(Y)\\), \\(X\\) et \\(Y\\) étant deux variables aléatoire. On peut résumer ces trois propriétés en disant que l’espérance mathématique est linéaire: \\[E(\\lambda X + \\mu Y)= \\lambda E(X)+\\mu E(Y), \\quad \\forall \\lambda \\in \\mathbb{R}, \\, \\forall \\mu \\in \\mathbb{R}.\\] Variance Définition 6.4 La variance est un indicateur mesurant la dispersion des valeurs \\(x_{i}\\) que peut prendre la v.a. \\(X\\) et son espérance \\(E(X)\\). On appelle variance de X, que l’on note \\(V(X)\\), la quantité \\[V(X)=E\\big[ (X-E(X))^2 \\big]\\] lorsque cette quantité existe. C’est l’espérance mathématique du carré de la v.a. centrée \\(X-E(X)\\). On peut établir une autre formule pour le calcul de \\(V(X)\\): \\[V(X)=E(X^2)-E^2(X)\\] Or: \\[\\begin{aligned} V(X)&amp;= E\\left[X^2-2XE(X)+E^2(X)\\right] \\\\ &amp;=E(X^2)-E[2XE(X)]+ E[E^2(X)]\\\\ &amp;=E(X^2)-2E^2(X)+E^2(X) \\\\ &amp;=E(X^2)-E^2(X) \\end{aligned}\\] On cherche \\(V(X)\\) où \\(X\\) est le nombre obtenu lors du jet d’un dé équilibré. On a vu dans l’exemple que \\(E(X) = \\frac{7}{2}\\). De plus, \\[\\begin{aligned} E(X^2) &amp;= 1^2 \\bigg(\\frac{1}{6}\\bigg) + 2^2 \\bigg(\\frac{1}{6}\\bigg) + 3^2 \\bigg(\\frac{1}{6}\\bigg) + 4^2 \\bigg(\\frac{1}{6}\\bigg) + 5^2 \\bigg(\\frac{1}{6}\\bigg) + 6^2 \\bigg(\\frac{1}{6}\\bigg) \\\\ &amp;=\\bigg(\\frac{1}{6}\\bigg) (91) = \\frac{91}{6}.\\end{aligned}\\] Et donc \\[V(X) = \\frac{91}{6} - \\bigg(\\frac{7}{2}\\bigg)^2 = \\frac{35}{12}\\] Propriétés de la variance \\(V(X) \\geq 0\\) \\(V(X+a)=V(X)\\) en effet: \\[\\begin{aligned} V(X+a) &amp;= E\\big[\\left[X+a-E(X+a)\\right]^2\\big] \\\\ &amp;=E\\big[\\left[X+a-E(X)-a\\right]^2\\big] \\\\ &amp;=E\\big[\\left[X-E(X)\\right]^2\\big] \\\\ &amp;=V(X). \\end{aligned}\\] \\(V(aX)=a^2V(X)\\) en effet: \\[\\begin{aligned} V(aX) &amp;= E\\big[\\left[aX-E(aX)\\right]^2\\big] \\\\ &amp;=E\\big[\\left[aX-aE(X)\\right]^2\\big] \\\\ &amp;=E\\big[a^2\\left[X-E(X)\\right]^2\\big] \\\\ &amp;=a^2\\big[E\\left[X-E(X)\\right]^2\\big] \\\\ &amp;= a^2V(X). \\end{aligned}\\] Ecart-type Définition 6.5 La racine carrée de \\(V(X)\\) est appelée l’écart-type de \\(X\\), qui se note \\(\\sigma_{X}\\). On a \\[\\sigma_{X} = \\sqrt{V(X)}\\] \\(\\sigma_{X}\\) s’exprime dans les mêmes unités de mesure que la variable aléatoire \\(X\\). A noter: L’écart type sert à mesurer la dispersion d’un ensemble de données. Plus il est faible, plus les valeurs sont regroupées autour de la moyenne. Exemple: La répartition des notes d’une classe. Plus l’écart type est faible, plus la classe est homogène. L’espérance et l’écart-type sont reliés par l’inégalité de Bienaymé-Tchebychev. Inégalité de Bienaymé-Tchebychev Théorème 6.2 Soit \\(X\\) une variable aléatoire d’espérance \\(\\mu\\) et de variance \\(\\sigma^2\\). Pour tout \\(\\varepsilon &gt; 0\\), on a l’inégalité suivante: \\[P\\left(|X-E(X)| \\geq \\varepsilon \\right) \\leq \\frac{\\sigma^2}{\\varepsilon^2}\\] On peut l’écrire autrement. Soit \\(k=\\varepsilon/\\sigma\\). \\[P\\left(|X-E(X)| \\geq k\\sigma \\right) \\leq \\frac{1}{k^2}\\] Importance: Cette inégalité relie la probabilité pour \\(X\\) de s’écarter de sa moyenne \\(E(X)\\), à sa variance qui est justement un indicateur de dispersion autour de la moyenne de la loi. Elle montre quantitativement que “plus l’écart type est faible, plus la probabilité de s’écarter de la moyenne est faible”. Théorème 6.3 (Inégalité de Markov) Soit \\(X\\) une variable aléatoire à valeur non négatives. Pour tout réel \\(a &gt; 0\\) \\[P(X&gt;a) \\leq \\frac{E(X)}{a}\\] Moments non centrés et centrés On appelle moment non centré d’ordre \\(r \\in \\mathbb{N^*}\\) de \\(X\\) la quantité, lorsqu’elle existe: \\[m_{r}(X)=\\sum_{i \\in \\mathbb{N} } x_{i}^r p(x_{i})=E(X^r).\\] Le moment centré d’ordre \\(r \\in \\mathbb{N^*}\\) est la quantité, lorsqu’elle existe: \\[\\mu_{r}(X)=\\sum_{i \\in \\mathbb{N} } p_{i}\\left[x_{i}-E(X)\\right]^r=E\\left[X-E(X)\\right]^r.\\] Les premiers moments sont: \\[m_{1}(X)=E(X), \\quad \\mu_{1}(X)=0\\] \\[\\mu_{2}(X)=V(X)=m_{2}(X)-m_{1}^2(X)\\] Couple de variables aléatoires discrètes Considérons deux variables aléatoires discrètes \\(X\\) et \\(Y\\). Il nous faut pour modéliser le problème une fonction qui nous donne la probabilité que \\((X = x_i )\\) en même temps que \\((Y = y_j )\\). C’est la loi de probabilité conjointe. Soit \\(X\\) et \\(Y\\) deux variables aléatoires réelles discrètes, définies sur un espace probabilisé \\((\\Omega,\\mathcal{A},P)\\) et que \\[\\begin{aligned} X(\\Omega) &amp;= \\{x_1,x_2,\\ldots,x_l\\} \\\\ Y(\\Omega) &amp;= \\{y_1,y_2,\\ldots,y_k\\} \\\\ &amp; \\quad (l \\text{ et } k \\in \\mathbb{N})\\end{aligned}\\] La loi du couple \\((X,Y)\\), dite loi de probabilité conjointe ou simultanée, est entièrement définie par les probabilités: \\[p_{ij} = P(X=x_i;Y=y_j) = P(\\{X=x_i\\}\\cap\\{Y=y_j\\})\\] On a \\[p_{ij} \\geq 0 \\quad \\text{et} \\quad \\sum_{i=1}^{l} \\sum_{j=1}^{k} p_{ij} = 1\\] Le couple \\((X,Y)\\) s’appelle variable aléatoire à deux dimensions et peut prendre \\(l\\times k\\) valeurs. Table de probabilité conjointe Les probabilités \\(p_{ij}\\) peuvent être présentées dans un tableau à deux dimensions qu’on appelle table de probabilité conjointe: \\(X\\backslash Y\\) \\(y_1\\) \\(y_2\\) \\(\\ldots\\) \\(y_j\\) \\(\\ldots\\) \\(y_k\\) \\(x_1\\) \\(p_{11}\\) \\(p_{12}\\) \\(p_{1j}\\) \\(p_{1k}\\) \\(x_2\\) \\(p_{21}\\) \\(p_{22}\\) \\(p_{2j}\\) \\(p_{2k}\\) \\(\\vdots\\) \\(x_i\\) \\(p_{i1}\\) \\(p_{i2}\\) \\(p_{ij}\\) \\(p_{ik}\\) \\(\\vdots\\) \\(x_l\\) \\(p_{l1}\\) \\(p_{l2}\\) \\(p_{lj}\\) \\(p_{lk}\\) A la première ligne figure l’ensemble des valeurs de \\(Y\\) et à la première colonne figure l’ensemble des valeurs de \\(X\\). La probabilité \\(p_{ij} = P(X=x_i;Y=y_j)\\) est à l’intersection de la \\(i^{e}\\) et de la \\(j^{e}\\) colonne. Lois marginales Lorsqu’on connaît la loi conjointe des variables aléatoires \\(X\\) et \\(Y\\), on peut aussi s’intéresser à la loi de probabilité de \\(X\\) seule et de \\(Y\\) seule. Ce sont les lois de probabilité marginales. Loi marginale de \\(X\\): \\[p_{i.} = P(X=x_i) = P[\\{X=x_i\\}\\cap \\Omega] = \\sum_{j=1}^k p_{ij} \\quad \\quad \\forall \\, i=1,2,\\ldots,l\\] Loi marginale de \\(Y\\): \\[p_{.j} = P(Y=y_j) = P[ \\Omega \\cap \\{Y=y_j\\}] = \\sum_{i=1}^l p_{ij} \\quad \\quad \\forall \\, j=1,2,\\ldots,k\\] On peut calculer les lois marginales directement depuis la table de la loi conjointe. La loi marginale de \\(X\\) est calculée en faisant les totaux par ligne, tandis que celle de \\(Y\\) l’est en faisant les totaux par colonne. C’est le fait que les lois de \\(X\\) et \\(Y\\) individuellement puissent être lues dans les marges du tableau qui leur vaut leur nom de lois marginales. \\(X\\backslash Y\\) \\(y_1\\) \\(y_2\\) \\(\\ldots\\) \\(y_j\\) \\(\\ldots\\) \\(y_k\\) Marginale de \\(X\\) \\(x_1\\) \\(p_{11}\\) \\(p_{12}\\) \\(p_{1j}\\) \\(p_{1k}\\) \\(p_{1.}\\) \\(x_2\\) \\(p_{21}\\) \\(p_{22}\\) \\(p_{2j}\\) \\(p_{2k}\\) \\(p_{2.}\\) \\(\\vdots\\) \\(x_i\\) \\(p_{i1}\\) \\(p_{i2}\\) \\(p_{ij}\\) \\(p_{ik}\\) \\(p_{i.}\\) \\(\\vdots\\) \\(x_l\\) \\(p_{l1}\\) \\(p_{l2}\\) \\(p_{lj}\\) \\(p_{lk}\\) \\(p_{l.}\\) Marginale de \\(Y\\) \\(p_{.1}\\) \\(p_{.2}\\) \\(p_{.j}\\) \\(p_{.k}\\) \\(1\\) On tire au hasard 3 boules d’une urne contenant 3 boules rouges, 4 blanches et 5 noires. \\(X\\) et \\(Y\\) désignent respectivement le nombre de boules rouges et celui de boules blanches tirées. Déterminer la loi de probabilité conjointe du couple \\((X,Y)\\) ainsi que les lois marginales de \\(X\\) et de \\(Y\\). Lois conditionnelles Pour chaque valeur \\(y_j\\) de \\(Y\\) telle que \\(p_{.j} = P(Y=y_j) \\neq 0\\) on peut définir la loi conditionnelle de \\(X\\) sachant \\(Y=y_j\\) par \\[p_{i/j} = P(X=x_i / Y=y_j) = \\frac{P(X=x_i;Y=y_j)}{P(Y=y_j)} = \\frac{p_{ij}}{p_{.j}} \\quad \\quad \\forall i = 1,2,\\ldots,l\\] De même on définit la loi de \\(Y\\) sachant \\(X=x_i\\) par \\[p_{j/i} = P(Y=y_j / X=x_i) = \\frac{P(X=x_i;Y=y_j)}{P(X=x_i)} = \\frac{p_{ij}}{p_{i.}} \\quad \\quad \\forall j = 1,2,\\ldots,k\\] Indépendance de variables aléatoires Théorème 6.4 On dit que deux v.a.r.d sont indépendantes si et seulement si \\[P(X=x_i;Y=y_j) = P(X=x_i) P(Y=y_j) \\quad \\quad \\forall \\, i = 1,2,\\ldots,l \\text{ et } j = 1,2,\\ldots,k\\] On montre que \\[P(\\{X\\in A\\} \\cap \\{Y \\in B\\}) = P(\\{X\\in A\\}) P(\\{Y \\in B\\}) \\quad \\quad \\forall \\,\\, A \\text{ et } B \\in \\mathcal{A}\\] Propriétés Soit deux v.a.r.d. \\(X\\) et \\(Y\\), \\(E(X+Y)=E(X)+E(Y)\\) Si \\(X\\) et \\(Y\\) sont indépendantes alors \\(E(XY)=E(X)E(Y)\\). Mais la réciproque n’est pas toujours vraie. Covariance Soit \\(X\\) et \\(Y\\) deux v.a.r.d. On appelle covariance de \\(X\\) et de \\(Y\\) la valeur si elle existe de \\[Cov(X,Y) = E[(X-E(X))(Y-E(Y))] = \\sum_i \\sum_j (x_i-E(X))(y_j-E(Y)) p_{ij}\\] qu’on peut calculer en utilisant la formule suivante \\[Cov(X,Y) = E(XY) - E(X)E(Y)\\] Propriétés \\(Cov(X,Y)=Cov(Y,X)\\) \\(Cov(aX_1+bX_2,Y) = a Cov(X_1,Y) + b Cov(X_2,Y)\\) \\(V(X+Y)= V(X) + V(Y) + 2 Cov(X,Y)\\) Si \\(X\\) et \\(Y\\) sont indépendantes alors \\(Cov(X,Y) = 0\\) (la réciproque n’est pas vraie) \\(V(X+Y) = V(X) + V(Y)\\) (la réciproque n’est pas vraie) Coefficient de corrélation linéaire On appelle coefficient de corrélation linéaire de \\(X\\) et de \\(Y\\) la valeur définie par \\[\\rho = \\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{V(X)V(Y)}} = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}\\] On peut montrer que \\[-1 \\leq \\rho(X,Y) \\leq 1\\] Pour le montrer on peut partir du fait que la variance est toujours positive ou nulle. Donc \\(V(\\frac{X}{\\sigma_X} + \\frac{Y}{\\sigma_Y}) \\geq 0\\) et \\(V(\\frac{X}{\\sigma_X} - \\frac{Y}{\\sigma_Y}) \\geq 0\\). Interprétation de \\(\\rho\\) Le coefficient de corrélation est une mesure du degré de linéarité entre \\(X\\) et \\(Y\\). Les valeurs de \\(\\rho\\) proches de \\(1\\) ou \\(-1\\) indiquent une linéarité quasiment rigoureuse entre \\(X\\) et \\(Y\\). Les valeurs de \\(\\rho\\) proche de 0 indiquent une absence de toute relation linéaire. Lorsque \\(\\rho(X,Y)\\) est positif, \\(Y\\) a tendance à augmenter si \\(X\\) en fait autant. Lorsque \\(\\rho(X,Y) &lt; 0\\), \\(Y\\) a tendance à diminuer si \\(X\\) augmente. Si \\(\\rho(X,Y) =0\\), on dit que ces deux statistiques sont non corrélées. Lois usuelles discrètes Loi uniforme discrète \\(\\mathcal{U}(n)\\) Définition 6.6 Une distribution de probabilité suit une loi uniforme lorsque toutes les valeurs prises par la variable aléatoire sont équiprobables. Si \\(n\\) est le nombre de valeurs différentes prises par la variable aléatoire alors on a: \\[\\label{eq:unif} P(X=x_i)=\\frac{1}{n} \\qquad \\forall \\, i \\in \\{1,\\ldots, n\\}\\] Exemple: La distribution des chiffres obtenus au lancer de dé (si ce dernier est non pipé) suit une loi uniforme dont la loi de probabilité est la suivante : \\(x_i\\) \\(1\\) \\(2\\) \\(3\\) \\(4\\) \\(5\\) \\(6\\) \\(P(X = x_i)\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) Moments de loi uniforme discrète Dans le cas particulier d’une loi uniforme discrète où chaque valeur de la variable aléatoire \\(X\\) correspond à son rang, i.e. \\(x_i=i \\, \\, \\forall i \\in \\{1,\\ldots, n\\}\\), on a: \\[E(X)=\\frac{n+1}{2} \\quad \\text{et} \\quad V(X)=\\frac{n^2-1}{12}\\] La démonstration de ces résultats est établie en utilisant les égalités (cf. Annexe) \\[\\sum_{i=1}^n i=\\frac{n(n+1)}{2} \\quad \\text{et} \\quad \\sum_{i=1}^n i^2=\\frac{n(n+1)(2n+1)}{6}.\\] En revenant à l’exemple du lancer du dé de cette section, on peut calculer directement les moments de \\(X\\): \\[E(X)=\\frac{6+1}{2}=3.5\\] et \\[V(X)=\\frac{6^2-1}{12}=\\frac{35}{12}\\simeq 2.92.\\] Loi de Bernoulli \\(\\mathcal{B}(p)\\) Définition 6.7 On réalise une expérience dont le résultat sera interprété soit comme un succès soit comme un échec. On définit alors la variable aléatoire \\(X\\) en lui donnant la valeur 1 lors d’un succès et 0 lors d’un échec (variable indicatrice). La loi de probabilité de \\(X\\) est alors \\[\\begin{align} &amp;p(1)=P(X=1)=p \\tag{6.1} \\\\ &amp;p(0)=P(X=0)= 1-p=q \\notag \\end{align}\\] où \\(p\\) est la probabilité d’un succès, \\(0 \\leq p \\leq 1\\). Une variable aléatoire \\(X\\) est dite de Bernoulli \\(X \\sim \\mathcal{B} \\left({p}\\right)\\) s’il existe un nombre \\(p \\, \\in \\, ]0,1[\\) tel que la loi de probabilité de \\(X\\) soit donnée par (6.1). La fonction de répartition est définie par: \\[F(x) = \\left\\{ \\begin{array}{ll} 0 &amp; \\quad \\text{si $x &lt; 0$} \\\\ 1 - p &amp; \\quad \\text{si $0 \\leq x &lt; 1$} \\\\ 1 &amp; \\quad \\text{si $x \\geq 1$}. \\end{array} \\right.\\] L’espérance la loi de Bernoulli est \\(p\\), en effet \\[E(X) =1 \\times P(X=1)+0 \\times P(X=0)=P(X=1)=p\\] La variance la loi de Bernoulli est \\(np\\), en effet \\[V(X) =E(X^2)-E^2(X)=p-p^2=p(1-p)=pq\\] car \\[E(X^2) =1^2\\times P(X=1)+0^2 \\times P(X=0)=P(X=1)=p\\] Loi Binomiale \\(\\mathcal{B}(n,p)\\) Décrite pour la première fois par Isaac Newton en 1676 et démontrée pour la première fois par le mathématicien suisse Jacob Bernoulli en 1713, la loi binomiale est l’une des distributions de probabilité les plus fréquemment rencontrées en statistique appliquée. Supposons qu’on exécute maintenant \\(n\\) épreuves indépendantes, chacune ayant \\(p\\) pour probabilité de succès et \\(1-p\\) pour probabilité d’échec. La variable aléatoire \\(X\\) qui compte le nombre de succès sur l’ensemble des \\(n\\) épreuves est dite variable aléatoire binomiale de paramètres \\(n\\) et \\(p\\). Une variable de Bernoulli n’est donc qu’une variable binomiale de paramètres \\((1,p)\\). Définition 6.8 Si on effectue \\(n\\) épreuves successives indépendantes où on note à chaque fois la réalisation ou non d’un certain événement \\(A\\), on obtient une suite de la forme \\(AA\\bar{A}A\\bar{A}\\ldots \\bar{A}AA\\). Soit \\(X\\) le nombre de réalisations de \\(A\\). On définit ainsi une v.a. \\(X\\) qui suit une loi binomiale de paramètres \\(n\\) et \\(p=P(A)\\), caractérisée par \\(X(\\Omega)=\\{0, 1,\\ldots, n\\}\\) : \\[\\begin{equation} P(X=k)=\\binom{n}{k}p^k (1-p)^{n-k} \\qquad 0\\leq k \\leq n \\tag{6.2} \\end{equation}\\] On écrit \\(X \\sim \\mathcal{B} \\left({n, p}\\right)\\). Donc la loi binomiale modélise le nombre de réalisations de \\(A\\) (succès) obtenues lors de la répétition indépendante et identique de \\(n\\) épreuves de Bernoulli. Pour établir (6.2) il faut remarquer que \\(\\binom{n}{k}\\) est le nombre d’échantillons de taille \\(n\\) comportant exactement \\(k\\) événements \\(A\\), de probabilité \\(p^k\\), indépendamment de l’ordre, et donc \\(n-k\\) événements \\(\\bar{A}\\), de probabilité \\((1-p)^{n-k}\\). Remarque: Il est possible d’obtenir aisément les valeurs des combinaisons de la loi binomiale en utilisant le triangle de Pascal. En utilisant la formule du binôme de Newton, on vérifie bien que c’est une loi de probabilité: \\[{\\sum_{k=0}^nP(X=k)=\\sum_{k=0}^n\\binom{n}{k} p^{k}(1-p)^{n-k}=[p+(1-p)]^n=1}\\] Exemple: On jette cinq pièces équilibrées. Les résultats sont supposés indépendants. Donner la loi de probabilité de la variable \\(X\\) qui compte le nombre de piles obtenus. Moments de la loi Binomiale Pour calculer facilement les moments de cette loi, nous allons associer à chaque épreuve \\(i\\), \\(1\\leq i \\leq n\\), une v.a. de Bernoulli (variable indicatrice sur \\(A\\)): \\[{1}_A=X_i = \\left\\{ \\begin{array}{l l} 1 &amp; \\quad \\text{si $A$ est réalisé}\\\\ 0 &amp; \\quad \\text{si $\\bar{A}$ est réalisé}\\\\ \\end{array} \\right.\\] On peut écrire alors: \\(X=\\sum_{i=1}^nX_i=X_1+X_2+\\ldots+X_n\\), ce qui nous permet de déduire aisément: \\[\\begin{aligned} E(X)&amp;=E\\left(\\sum_{i=1}^nX_i\\right)=\\sum_{i=1}^nE(X_i)=np \\\\ \\text{et} \\nonumber \\\\ V(X)&amp;=V\\left(\\sum_{i=1}^nX_i\\right)=\\sum_{i=1}^nV(X_i)=np(1-p) \\quad \\text{car les v.a. $X_i$ sont indépendantes.} \\end{aligned}\\] Le calcul direct des moments de \\(X\\) peut s’effectuer à partir de la définition générale, mais de façon beaucoup plus laborieuse: \\[\\begin{aligned} E(X)&amp;= \\sum_{k=0}^nk \\binom{n}{k} p^{k}(1-p)^{n-k}=\\sum_{k=1}^nk \\frac{n!}{k!(n-k)!} p^{k}(1-p)^{n-k} \\\\ &amp;= \\sum_{k=1}^n\\frac{n!}{(k-1)!(n-k)!} p^{k}(1-p)^{n-k}= np \\sum_{k=1}^n\\frac{(n-1)!}{(k-1)!(n-k)!} p^{k-1}(1-p)^{n-k} \\\\ &amp;= np \\sum_{j=0}^{n-1}\\frac{(n-1)!}{j!(n-1-j)!}p^j (1-p)^{n-1-j} =np \\sum_{j=0}^{n-1}\\binom{n-1}{j} p^{j}(1-p)^{n-1-j} \\\\ &amp;= np [p+(1-p)]^{n-1}=np \\end{aligned}\\] Pour obtenir \\(E(X^2)\\) par un procédé de calcul identique, on passe par l’intermédiaire du moment factoriel \\(E[X(X-1)]=E(X^2)-E(X)\\): \\[\\begin{aligned} E[X(X-1)]&amp;= \\sum_{k=0}^nk(k-1) \\frac{n!}{k!(n-k)!} p^{k}(1-p)^{n-k} \\\\ &amp;= n(n-1)p^2 \\sum_{k=2}^{n}\\frac{(n-2)!}{(k-2)!(n-k)!} p^{k-2}(1-p)^{n-k} \\\\ &amp;= n(n-1)p^2 \\sum_{j=0}^{n-2}\\binom{n-2}{j} p^{j}(1-p)^{n-2-j} \\\\ &amp;= n(n-1)p^2[p+(1-p)]^{n-2}= n(n-1)p^2 \\end{aligned}\\] On en déduit alors: \\[E(X^2)=E[X(X-1)]+E(X)= n(n-1)p^2+np,\\] puis: \\[\\begin{aligned} V(X)&amp;=n(n-1)p^2+np-(np)^2 \\\\ &amp;=n^2p^2+np(1-p)-n^2p^2 \\\\ &amp;=np(1-p). \\end{aligned}\\] Le nombre de résultats pile apparus au cours de \\(n\\) jets d’une pièce de monnaie suit une loi binomiale \\(\\mathcal{B} \\left({n, 1/2}\\right)\\): \\[P(X=k)=\\binom{n}{k}\\left(\\frac{1}{2}\\right)^k \\left(\\frac{1}{2}\\right)^{n-k}=\\frac{\\binom{n}{k}}{2^n}, \\quad 0\\leq k \\leq n\\] avec \\(E(X)=n/2\\) et \\(V(X)=n/4\\). Le nombre \\(N\\) de boules rouges apparues au cours de \\(n\\) tirages avec remise dans une urne contenant deux rouges, trois vertes et une noire suit une loi binomiale \\(\\mathcal{B} \\left({n, 1/3}\\right)\\): \\[P(N=k)=\\binom{n}{k}\\left(\\frac{1}{3}\\right)^k \\left(\\frac{2}{3}\\right)^{n-k}=\\binom{n}{k} \\frac{2^{n-k}}{3^n}, \\quad 0\\leq k \\leq n\\] avec \\(E(X)=n/3\\) et \\(V(X)=2n/9\\). Théorème 6.5 Si \\(X_1 \\sim \\mathcal{B} \\left({n_1, p}\\right)\\) et \\(X_2 \\sim \\mathcal{B} \\left({n_2, p}\\right)\\), les v.a. \\(X_1\\) et \\(X_2\\) étant indépendantes, alors \\(X_1+X_2 \\sim \\mathcal{B} \\left({n_1+n_2, p}\\right)\\). Ceci résulte de la définition d’une loi binomiale puisqu’on totalise ici le résultat de \\(n_1+n_2\\) épreuves indépendantes. Loi de Poisson \\(\\mathcal{P}(\\lambda)\\) La loi de Poisson est découverte au début du XIX\\(^e\\) siècle par le magistrat français Siméon-Denis Poisson. Les variables aléatoires de Poisson ont un champ d’application fort vaste, en particulier du fait qu’on peut les utiliser pour approximer des variables aléatoires binomiales de paramètres \\((n,p)\\) pour autant que \\(n\\) soit grand et \\(p\\) assez petit pour que \\(np\\) soit d’ordre de grandeur moyen. Définition 6.9 Une v.a. \\(X\\) suit une loi de Poisson de paramètre \\(\\lambda&gt;0\\) si c’est une variable à valeurs entières, \\(X(\\Omega)=\\mathbb{N}\\), donc avec une infinité de valeurs possibles, de probabilité: \\[\\label{eq:poisson} P(X=k)=e^{-\\lambda} \\frac{\\lambda^k}{k!}, \\quad k \\in \\mathbb{N}\\] Cette loi ne dépend qu’un seul paramètre réel positif \\(\\lambda\\), avec l’écriture symbolique \\(X \\sim \\mathcal{P}(\\lambda)\\). Le développement en série entière de l’exponentielle \\(e^\\lambda=\\sum_{k=0}^{+\\infty} \\frac{\\lambda^k}{k!}\\) permet de vérifier qu’il s’agit bien d’une loi de probabilité: \\[\\sum_{k=0}^{\\infty} P(X=k)=\\sum_{k=0}^{\\infty} e^{-\\lambda} \\frac{\\lambda^k}{k!}=e^{-\\lambda}\\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!}=e^{-\\lambda}e^{\\lambda}=1\\] Moments de loi de Poisson Le calcul de l’espérance mathématique se déduit du développement en série entière de l’exponentielle: \\[\\begin{aligned} E(X)&amp;=\\sum_{k=0}^{\\infty} k P(X=k)=\\sum_{k=1}^{\\infty} k e^{-\\lambda} \\frac{\\lambda^k}{k!} \\\\ &amp;=e^{-\\lambda} \\sum_{k=1}^{\\infty} \\frac{\\lambda^k}{(k-1)!}=\\lambda e^{-\\lambda} \\sum_{k=1}^{\\infty} \\frac{\\lambda^{k-1}}{(k-1)!} \\\\ &amp;= \\lambda e^{-\\lambda} \\sum_{j=0}^{\\infty} \\frac{\\lambda^{j}}{j!}= \\lambda e^{-\\lambda} e^{\\lambda} \\\\ &amp;= \\lambda.\\end{aligned}\\] Pour calculer la variance nous n’allons pas calculer \\(E(X^2)\\) mais le moment factoriel \\(E[X(X-1)]\\) qui s’obtient plus facilement, selon la méthode précédente: \\[\\begin{aligned} E[X(X-1)] &amp;=\\sum_{k=0}^{\\infty} k(k-1)P(X=k)=\\sum_{k=2}^{\\infty} k(k-1) \\,e^{-\\lambda} \\frac{\\lambda^k}{k!} \\\\ &amp;=e^{-\\lambda} \\sum_{k=2}^{\\infty} \\frac{\\lambda^k}{(k-2)!}=\\lambda^2 e^{-\\lambda} \\sum_{k=2}^{\\infty} \\frac{\\lambda^{k-2}}{(k-2)!} \\\\ &amp;= \\lambda^2 e^{-\\lambda} \\sum_{j=0}^{\\infty} \\frac{\\lambda^{j}}{j!}= \\lambda^2 e^{-\\lambda} e^{\\lambda} = \\lambda^2.\\end{aligned}\\] On en déduit: \\[\\begin{aligned} V(X)&amp;=E(X^2)-E^2(X)=E[X(X-1)]+E(X)-E^2(X) \\\\ &amp;=\\lambda^2+\\lambda-\\lambda^2=\\lambda.\\end{aligned}\\] Théorème 6.6 Si \\(X\\) et \\(Y\\) sont deux variables indépendantes suivant des lois de Poisson \\[X \\sim \\mathcal{P}(\\lambda) \\quad \\text{et} \\quad Y \\sim \\mathcal{P}(\\mu)\\] alors leur somme suit aussi une loi de Poisson: \\[X+Y \\sim \\mathcal{P}(\\lambda+\\mu).\\] Exemple: Soit \\(X\\) la variable aléatoire associée au nombre de micro-ordinateurs vendus chaque jour dans le magasin. On suppose que \\(X\\) suit une loi de Poisson de paramètre \\(\\lambda=5\\). On écrit alors \\(X \\sim \\mathcal{P}(5).\\) La probabilité associée à la vente de 5 micro-ordinateurs se détermine par : \\[P(X=5)=e^{-5} \\frac{5^5}{5!}=e^{-5}\\simeq 0.1755\\] La probabilité de vendre au moins 2 micro-ordinateurs est égal à: \\[\\begin{aligned} P(X \\geq 2)&amp;=1-\\left(e^{-5} \\frac{5^0}{0!}+e^{-5} \\frac{5^1}{1!}\\right)\\simeq 0.9596\\end{aligned}\\] Le nombre moyen de micro-ordinateurs vendus chaque jour dans le magasin est égal à 5 puisque \\(E(X)=\\lambda=5\\). Approximation d’une loi binomiale Le théorème de Poisson nous montre que si \\(n\\) est suffisamment grand et \\(p\\) assez petit, alors on peut approcher la distribution d’une loi binomiale de paramètres \\(n\\) et \\(p\\) par celle d’une loi de Poisson de paramètre \\(\\lambda=np\\), en effet \\[\\text{si} \\; n \\rightarrow \\infty \\; \\text{et}\\; p \\rightarrow 0 \\; \\text{alors} \\; X: \\mathcal{B}(n, p) \\rightarrow \\mathcal{P}(\\lambda).\\] Une bonne approximation est obtenue si \\(n \\geq 50\\) et \\(np \\leq 5\\). Dans ce contexte, la loi de Poisson est souvent utilisée pour modéliser le nombre de succès lorsqu’on répète un très grand nombre de fois une expérience ayant une chance très faible de réussir par une loi de Poisson (nombre de personnes dans la population française atteints d’une maladie rare, par exemple). On cherche la probabilité de trouver au moins un centenaire parmi 200 personnes dans une population où une personne sur cent est un centenaire. La probabilité \\(p=1/100=0.01\\) étant faible et \\(n=200\\) étant suffisamment grand, on peut modéliser le nombre \\(X\\) de centenaires pris parmi 200 personnes par la loi de Poisson de paramètre \\(\\lambda=200 \\times 0.01=2\\). Donc on a: \\[P(X\\geq 1)=1-P(X=0)=1-e^{-2}\\simeq 0.86\\] Soit une v.a. \\(X\\) telle que \\(X \\sim \\mathcal{B}(100, 0.01)\\), les valeurs des probabilités pour \\(k\\) de 0 à 5 ainsi que leur approximation à \\(10^{-3}\\) avec une loi de Poisson de paramètre \\(\\lambda= np =1\\) sont données dans le tableau ci-dessous : \\(k\\) \\(1\\) \\(2\\) \\(3\\) \\(4\\) \\(5\\) \\(k\\) \\(P(X = k)\\) \\(0.366\\) \\(0.370\\) \\(0.185\\) \\(0.061\\) \\(0.015\\) \\(0.000\\) Approximation \\(0.368\\) \\(0.368\\) \\(0.184\\) \\(0.061\\) \\(0.015\\) \\(0.003\\) Dans le cas de cet exemple où \\(n =100\\) et \\(np =1\\), l’approximation de la loi binomiale par une loi de poisson donne des valeurs de probabilités identiques à \\(10^{-3}\\) près. Loi Géométrique ou de Pascal \\(\\mathcal{G}(p)\\) On effectue des épreuves successives indépendantes jusqu’à la réalisation d’un événement particulier \\(A\\) de probabilité \\(p=P(A)\\) et on note \\(X\\) le nombre aléatoire d’épreuves effectuées. On définit ainsi une v.a. à valeurs entières de loi géométrique, ou de Pascal. A chaque épreuve est associé l’ensemble fondamental \\(\\Omega=\\{A, \\bar{A}\\}\\) et l’événement \\(\\{X=k\\}\\) pour \\(k\\in \\mathbb{N^*}\\) est représenté par une suite de \\(k-1\\) événements \\(\\bar{A}\\), terminée par l’événement \\(A\\): \\[\\underbrace{\\bar{A}\\bar{A}\\ldots \\bar{A}}_{k-1}A\\] D’où: \\[\\begin{equation} P(X=k)=(1-p)^{k-1}p \\quad \\forall \\, k \\in \\mathbb{N^*} \\tag{6.3} \\end{equation}\\] Cette loi peut servir à modéliser des temps de vie, ou des temps d’attente, lorsque le temps est mesuré de manière discrète (nombre de jours par exemple). En utilisant la série entière \\[\\label{eq:serie_entiere} \\sum_{k=0}^\\infty x^k = 1/(1-x) \\quad \\text{pour} \\quad |x|&lt;1\\] on vérifie bien que c’est une loi de probabilité: \\[\\begin{aligned} \\sum_{k=1}^\\infty P(X=k)&amp;= \\sum_{k=1}^\\infty (1-p)^{k-1}p = p \\sum_{j=0}^\\infty (1-p)^{j} \\\\ &amp;= p \\frac{1}{1-(1-p)}=1\\end{aligned}\\] Moments de loi Géométrique En dérivant la série entière (6.3) ci-dessus, on obtient \\(\\sum_{k=1}^\\infty k x^{k-1}=1/(1-x)^2\\). Ceci permet d’obtenir l’espérance: \\[E(X)=\\sum_{k=1}^\\infty kp(1-p)^{k-1}=\\frac{p}{[1-(1-p)]^2}=\\frac{1}{p}\\] En d’autres termes, si des épreuves indépendantes ayant une probabilité \\(p\\) d’obtenir un succès sont réalisés jusqu’à ce que le premier succès se produise, le nombre espéré d’essais nécessaires est égal à \\(1/p\\). Par exemple, le nombre espéré de jets d’un dé équilibré qu’il faut pour obtenir la valeur 1 est 6. Le calcul de la variance se fait à partir du moment factoriel et en utilisant la dérivée seconde de la série entière (6.3): \\(\\sum_{k=2}^\\infty k(k-1) x^{k-2} = 2/(1-x)^3\\), Donc \\[\\begin{aligned} E[X(X-1)]&amp;=\\sum_{k=2}^\\infty k(k-1)p(1-p)^{k-1} \\\\ &amp;= p(1-p)\\sum_{k=2}^\\infty k(k-1)(1-p)^{k-2} \\\\ &amp;= \\frac{2p(1-p)}{[1-(1-p)]^3}=\\frac{2(1-p)}{p^2}\\end{aligned}\\] d’où on déduit: \\[V(X)=E[X(X-1)]+E(X)-E^2(X)=\\frac{1-p}{p^2}.\\] Si l’on considère la variable aléatoire \\(X\\) “nombre de naissances observées jusqu’à l’obtention d’une fille” avec p = 1/2 (même probabilité de naissance d’une fille ou d’un garçon), alors X suit une loi géométrique et on a pour tout \\(k\\in \\mathbb{N^*}\\): \\[P(X=k)=(1-1/2)^{k-1}(1/2)=1/2^k\\] avec \\(E(X)=2\\) et \\(V(X)=2.\\) Loi Binomiale Négative \\(\\mathcal{BN}(r,p)\\) \\(\\varepsilon\\): “On répéte l’épreuve de Bernoulli jusqu’à obtenir un total de \\(r\\) succès”. Exemple avec : \\[\\bar{A} \\quad {A} \\quad \\bar{A} \\quad \\bar{A} \\quad \\bar{A} \\quad {A} \\quad \\bar{A} \\quad \\bar{A} \\quad {A}\\] \\[{E} \\quad {S} \\quad {E} \\quad {E} \\quad {E} \\quad {S} \\quad {E} \\quad {E} \\quad {S}\\] Mais on peut obtenir d’autres façons: \\[{S} \\quad {E} \\quad {E} \\quad {E} \\quad {E} \\quad {E} \\quad {S} \\quad {E} \\quad {S}\\] \\[{E} \\quad {E} \\quad {E} \\quad {E} \\quad {S} \\quad {E} \\quad {S} \\quad {E} \\quad {S}\\] Chaque épreuve a \\({p}\\) pour probabilité de succès et \\({1-p}\\) pour probabilité d’échec. Désignons \\(X=\\)“le nombre d’épreuves nécessaires pour atteindre ce résultat”. \\[\\underbrace{\\overbrace{{E} \\quad {S} \\quad {E} \\quad {E} \\quad {E} \\quad {S} \\quad {E} \\quad {E}}^{ {r-1 \\, succès}\\, et \\, {k-r \\, échecs}} \\quad {S}}_{X=k}\\] \\(X(\\Omega)=\\{r,r+1,r+2,\\ldots\\}\\). On dit \\(X \\sim \\mathcal{BN}(r,p)\\). \\(\\forall \\, k \\in X(\\Omega),\\) \\[P(X=k) = \\binom{{k-1}}{{r-1}} {p^r} {(1-p)^{k-r}}\\] \\(\\mathcal{G}(p)=\\mathcal{BN}(1,p)\\) \\(\\varepsilon\\): “On répéte l’épreuve de Bernoulli jusqu’à obtenir un total de \\(r\\) succès”. Soit, \\[{E} \\quad \\ldots \\quad {E} \\quad {S} \\quad {E} \\quad \\ldots \\quad {E} \\quad {S} \\ldots \\quad {E} \\ldots \\quad {E} \\quad {S}\\] Soit, \\(Y_1\\) le nombre d’épreuves nécessaires jusqu’au premier succès, \\(Y_2\\) le nombre d’épreuves supplémentaires nécessaires pour obtenir un deuxième succès, \\(Y_3\\) celui menant au 3ème et ainsi de suite. Càd, \\[\\underbrace{{E} \\quad \\ldots \\quad {E} \\quad {S}}_{Y_1} \\quad \\underbrace{{E} \\quad \\ldots \\quad {E} \\quad {S}}_{Y_2} \\quad \\underbrace{\\ldots}_{\\ldots} \\quad \\underbrace{{E} \\quad \\ldots \\quad {E} \\quad {S}}_{Y_r}\\] Les tirages étants indépendantes et ayant toujours la même probabilité de succès, chacune des variables \\(Y_1,Y_2,\\ldots,Y_r\\) est géométrique \\(\\mathcal{G}(p)\\). \\(X=\\)“le nombre d’épreuves nécessaires à l’obtention de \\(r\\) succès”\\(=Y_1 + Y_2 + \\ldots + Y_r\\). Donc, \\[E(X)= E(Y_1) + E(Y_2) + \\ldots + E(Y_r) = \\sum_{i=1}^r \\frac{1}{p} = \\frac{r}{p}\\] et \\[V(X)= \\sum_{i=1}^r V(Y_i) = \\frac{r(1-p)}{p^2}\\] car les \\(Y_i\\) sont indépendantes. "],
["variables-aleatoires-continues.html", "Variables Aléatoires Continues Densité d’une variable aléatoire continue Fonction de répartition d’une v.a.c Fonction d’une variable aléatoire continue Espérance et variance de variables aléatoires continues Lois usuelles de v.a.c Couple de variables aléatoires continues", " Variables Aléatoires Continues Densité d’une variable aléatoire continue Dans les chapitres précédents nous avons traité des variables aléatoires discrètes, c’est-à-dire de variables dont l’univers est fini ou infini dénombrable. Il existe cependant des variables dont l’univers est infini non dénombrable. On peut citer par exemple, l’heure d’arrivée d’un train à une gare donnée ou encore la durée de vie d’un transistor. Désignons par \\(X\\) une telle variable. Définition 6.10 \\(X\\) est une variable aléatoire continue s’il existe une fonction \\(f\\) non négative définie pour tout \\(x \\in \\mathbb{R}\\) et vérifiant pour tout ensemble \\(B\\) de nombres réels la propriété \\[\\begin{equation} P(X \\in B) = \\int_B f(x)dx \\tag{6.4} \\end{equation}\\] La fonction \\(f\\) est appelée densité de probabilité de la variable aléatoire \\(X\\). Tous les problèmes de probabilité relatifs à \\(X\\) peuvent être traités grâce à \\(f\\). Par exemple pour \\(B=[a,b]\\), on obtient grâce à l’équation (6.4) \\[\\begin{equation} P(a\\le X \\le b) = \\int_a^bf(x)dx \\tag{6.5} \\end{equation}\\] Graphiquement, \\(P(a\\le X \\le b)\\) est l’aire de la surface entre l’axe de \\(x\\), la courbe correspondante à \\(f(x)\\) et les droites \\(x=a\\) et \\(x=b\\). Voire Figure 6.1 et Figure 6.2. Figure 6.1: \\(P(a \\leq X \\leq B)=\\) surface grisée Figure 6.2: L’aire hachurée correspond à des probabilités. \\(f(x)\\) étant une fonction densité de probabilité Définition 6.11 Pour toute variable aléatoire continue \\(X\\) de densité \\(f\\): \\(f(x) \\ge 0 \\quad \\forall \\, x \\in \\mathbb{R}\\) \\(\\int_{-\\infty}^{+\\infty}f(x)dx = 1\\) Si l’on pose \\(a=b\\) dans (6.5), il résulte \\[P(X=a)=\\int_a^a f(x)dx = 0\\] Ceci siginifie que la probabilité qu’une variable aléatoire continue prenne une valeur isolée fixe est toujours nulle. Aussi on peut écrire \\[P(X &lt; a) = P( X \\le a) = \\int_{-\\infty}^a f(x)dx\\] Soit \\(X\\) la variable aléatoire réelle de densité de probabilité \\[f(x)= \\left\\lbrace \\begin{array}{ll} kx &amp; \\mbox{si} \\quad 0\\le x \\le 5\\\\ 0 &amp; \\mbox{sinon} \\end{array} \\right.\\] Calculer \\(k\\). Calculer: \\(P(1 \\le X \\le 3), P(2 \\le X \\le 4)\\) et \\(P(X &lt; 3)\\). Soit \\(X\\) une variable aléatoire réelle continue ayant pour densité de probabilité \\[f(x)= \\left\\lbrace \\begin{array}{ll} \\frac{1}{6} x + k &amp; \\mbox{si} \\quad 0\\le x \\le 3\\\\ 0 &amp; \\mbox{sinon} \\end{array} \\right.\\] Calculer \\(k\\). Calculer \\(P(1 \\le X \\le 2)\\) Fonction de répartition d’une v.a.c Définition 6.12 Si comme pour les variables aléatoires discrètes, on définit la fonction de répartition de \\(X\\) par: \\[\\begin{aligned} F_X \\colon \\mathbb{R} &amp;\\longrightarrow \\mathbb{R} \\\\ x &amp;\\longmapsto F_X(a) = P(X \\le a)\\end{aligned}\\] alors la relation entre la fonction de répartition \\(F_X\\) et la fonction densité de probabilité \\(f(x)\\) est la suivante: \\[\\forall \\quad a \\in \\mathbb{R} \\quad F_X(a)= P(X \\le a) = \\int_{-\\infty}^a f(x)dx\\] La fonction de répartition \\(F_X(a)\\) est la primitive de la fonction densité de probabilité \\(f(x)\\) (donc la densité d’une v.a.c est la dérivée de la fonction de répartition), et permet d’obtenir les probabilités associées à la variable aléatoire \\(X\\), en effet: Propriétés: Pour une variable aléatoire continue X: \\(F&#39;_X(x) = \\frac{\\text{d}}{\\text{d} x} F_X(x) = f(x)\\). Pour tous réels \\(a \\le b\\), \\[\\begin{aligned} P(a &lt; X &lt; b) &amp; = P(a &lt; X \\le b) \\\\ &amp; = P(a \\le X &lt; b) \\\\ &amp; = P( a \\le X \\le b) \\\\ &amp; = F_X(b) - F_X(a) = \\int_a^bf(x)dx \\end{aligned}\\] La fonction de répartition correspond aux probabilités cumulées associées à la variable aléatoire continue sur l’intervalle d’étude (Figure 6.3). Figure 6.3: L’aire hachurée en vert sous la courbe de la fonction densité de probabilité correspond à la probabilité \\(P ( X &lt; a ) = F_X ( a )\\) et vaut 0.5 car ceci correspond exactement à la moitié de l’aire totale sous la courbe Propriétés: Les propriétés associées à la fonction de répartition sont les suivantes: \\(F_X\\) est continue sur \\(\\mathbb{R}\\), dérivable en tout point où \\(f\\) est continue. \\(F_X\\) est croissante sur \\(\\mathbb{R}\\). \\(F_X\\) est à valeurs dans \\([0,1]\\). \\(\\lim\\limits_{x\\to - \\infty} F_X(x) = 0\\) et \\(\\lim\\limits_{x\\to +\\infty} F_X(x) = 1\\). Fonction d’une variable aléatoire continue Soit \\(X\\) une variable aléatoire continue de densité \\(f_X\\) et de fonction de répartition \\(F_X\\). Soit \\(h\\) une fonction continue définie sur \\(X(\\Omega)\\), alors \\(Y=h(X)\\) est une variable aléatoire. Pour déterminer la densité de \\(Y\\), notée \\(f_Y\\), on commence par calculer la fonction de répartition de \\(Y\\), notée \\(F_Y\\), ensuite nous dérivons pour déterminer \\(f_Y\\). Calcul de densités pour \\(h(X)=aX+b\\) \\(\\forall \\quad y \\in \\mathbb{R}\\), \\[F_Y(y) = P(Y\\leq y)=P(h(X) \\le y) = P(aX+b \\le y)\\] si \\(a&gt;0\\), \\[F_Y(y) = P(aX+b \\le y) = P(X\\leq \\frac{y-b}{a})=F_X(\\frac{y-b}{a})\\] si \\(a&lt;0\\), \\[F_Y(y) = P(aX+b \\le y) =P(X\\geq \\frac{y-b}{a})=1-F_X(\\frac{y-b}{a})\\] En dérivant on obtient la densité de \\(Y\\) \\[f_Y(y)=\\frac{1}{|a|}f_X(\\frac{y-b}{a}).\\] Calcul de densités pour \\(h(X)=X^2\\) si \\(y&lt;0\\), \\(F_Y(y) =P(Y\\leq y)=0\\). si \\(y&gt;0\\), \\[F_Y(y) =P(Y\\leq y)=P(X^2 \\le y)=P(-\\sqrt{y}\\leq X \\leq \\sqrt{y})=F_X(\\sqrt{y})-F_X(-\\sqrt{y})\\] En dérivant on obtient la densité de \\(Y\\), \\[f_Y(y)= \\left\\lbrace \\begin{array}{ll} \\frac{1}{2\\sqrt{y}}\\big[f_X(\\sqrt{y})+f_X(-\\sqrt{y})\\big] &amp; \\mbox{si} \\quad y \\ge 0\\\\ 0 &amp; \\mbox{sinon} \\end{array} \\right.\\] Calcul de densités pour \\(h(X)=e^X\\) si \\(y&lt;0\\), \\(F_Y(y) = P(Y\\leq y)=0\\). si \\(y&gt;0\\), \\(F_Y(y) = P(Y\\leq y)=P(e^X \\le y)=P( X \\leq \\ln (y))=F_X(\\ln(y))\\). En dérivant on obtient la densité de \\(Y\\) \\[f_Y(y)= \\left\\lbrace \\begin{array}{ll} \\frac{1}{y} f\\big(\\ln (y)\\big) &amp; \\mbox{si} \\quad y \\ge 0\\\\ 0 &amp; \\mbox{sinon} \\end{array} \\right.\\] Soit la v.a.c \\(X\\) ayant la fonction de densité \\[f_X(x)= \\left\\lbrace \\begin{array}{ll} 2 x &amp; \\mbox{si} \\quad 0 \\le x \\le 1\\\\ 0 &amp; \\mbox{sinon} \\end{array} \\right.\\] Déterminer la densité de: \\(Y=3X+1\\), \\(Z=X^2\\) et \\(T=e^X\\). Espérance et variance de variables aléatoires continues Espérance d’une v.a.c Définition 6.13 Si \\(X\\) est une variable aléatoire absolument continue de densité \\(f\\), on appelle espérance de X, le réel \\(E(X)\\), défini par: \\[E(X)= \\int_{-\\infty}^{+\\infty}x f(x) dx\\] si cette intégrale est convergente. Les propriétés de l’espérance d’une variable aléatoire continue sont les mêmes que pour une variable aléatoire discrète. Propriétés: Soit \\(X\\) une variable aléatoire continue, \\(E(aX+b)=aE(X)+b \\quad \\quad a \\ge 0 \\,\\, \\text{et} \\,\\, b \\in \\mathbb{R}\\). Si \\(X \\ge 0\\) alors \\(E(X) \\ge 0\\). Si \\(X\\) et \\(Y\\) sont deux variables aléatoires définies sur un même univers \\(\\Omega\\) alors \\[E(X+Y)=E(X)+E(Y)\\] Théorème 6.7 (Théorème de transfert) Si \\(X\\) est une variable aléatoire de densité \\(f(x)\\), alors pour toute fonction réelle \\(g\\) on aura \\[E[g(X)] = \\int_{-\\infty}^{+\\infty}g(x) f(x) dx\\] Soit la v.a.c \\(X\\) ayant la fonction de densité \\[f_X(x)= \\left\\lbrace \\begin{array}{ll} 2 x &amp; \\mbox{si} \\quad 0 \\le x \\le 1\\\\ 0 &amp; \\mbox{sinon} \\end{array} \\right.\\] Calculer l’espérance des variables aléatoires \\(Y=3X+1\\), \\(Z=X^2\\) et \\(T=e^X\\). Variance d’une v.a.c La variance d’une variable aléatoire \\(V(X)\\) est l’espérance mathématique du carré de l’écart à l’espérance mathématique. C’est un paramètre de dispersion qui correspond au moment centré d’ordre 2 de la variable aléatoire \\(X\\). Définition 6.14 Si \\(X\\) est une variable aléatoire ayant une espérance \\(E(X)\\), on appelle variance de \\(X\\) le réel \\[V(X)=E\\big([X-E(X)]^2\\big) = E(X^2) - [E(X)]^2\\] Si \\(X\\) est une variable aléatoire continue, on calcule \\(E(X^2)\\) en utilisant le théorème 6.7, \\[E(X^2) = \\int_{-\\infty}^{+\\infty}x^2 f(x)dx\\] Propriétés: Si \\(X\\) est une variable aléatoire admettant une variance alors: \\(V(X) \\ge 0\\), si elle existe. \\(\\forall \\quad a \\in \\mathbb{R}, V(aX) = a^2 V(X)\\) \\(\\forall \\quad (a,b) \\in \\mathbb{R}, V(aX+b) = a^2 V(X)\\) Si \\(X\\) et \\(Y\\) sont deux variables aléatoires indépendantes, \\(V(X+Y)=V(X)+V(Y)\\) Définition 6.15 (Ecart-type) Si \\(X\\) est une variable aléatoire ayant une variance \\(V(X)\\), on appelle écart-type de \\(X\\), le réel: \\[\\sigma_X = \\sqrt{V(X)}\\] Lois usuelles de v.a.c Loi uniforme \\(U(a,b)\\) La loi uniforme est la loi exacte de phénomènes continus uniformément répartis sur un intervalle. Définition 6.16 La variable aléatoire \\(X\\) suit une loi uniforme sur le segment \\([a,b]\\) avec \\(a &lt; b\\) si sa densité de probabilité est donnée par \\[f(x)= \\left\\lbrace \\begin{array}{ll} \\frac{1}{b-a} &amp; \\mbox{si} \\quad x \\in [a,b]\\\\ 0 &amp; \\mbox{si} \\quad x \\notin [a,b] \\end{array} \\right. = \\frac{1}{b-a} {1}_{[a,b]}(x)\\] Figure 6.4: Fonction de densité de \\(U([a,b]\\)) Quelques commentaires: La loi uniforme continue étant une loi de probabilité, l’aire hachurée en bleu sur la Figure 6.4 vaut \\(1\\). La fonction de répartition associée à la loi uniforme continue est \\[F_X(x)= \\left\\lbrace \\begin{array}{ll} 0 &amp; \\mbox{si} \\quad x &lt; a \\\\ \\frac{x-a}{b-a} &amp; \\mbox{si} \\quad a \\le x \\le b \\\\ 1 &amp; \\mbox{si} \\quad x &gt; b \\end{array} \\right.\\] Propriétés: Si \\(X\\) est une v.a.c qui suit la loi uniforme sur \\([a,b]\\): \\(E(X) = \\frac{b+a}{2}\\) \\(V(X) =\\frac{(b-a)^2}{12}\\) Soit \\(X \\thicksim U(0,10)\\). Calculer: \\(P(X &lt;3)\\) \\(P(X\\ge 6)\\) \\(P(3 &lt; X &lt; 8)\\) Loi exponentielle \\(\\mathcal{E}(\\lambda)\\) Définition 6.17 On dit qu’une variable aléatoire \\(X\\) est exponentielle (ou suit la loi exponentielle) de paramètre \\(\\lambda\\) si sa densité est donnée par \\[f(x)= \\left\\lbrace \\begin{array}{ll} \\lambda e^{- \\lambda x} &amp; \\mbox{si} \\quad x \\ge 0\\\\ 0 &amp; \\mbox{si} \\quad x &lt; 0 \\end{array} \\right. = \\lambda e^{- \\lambda x} {1}_{\\mathbb{R}^{+}}(x)\\] On dit \\(X \\thicksim \\mathcal{E}(\\lambda)\\) La fonction de répartition \\(F\\) d’une variable aléatoire exponentielle est donnée par \\[\\mbox{Si}\\,\\, x \\ge 0 \\quad F(x) = P(X \\le x) = \\int_0^x f(t)dt = \\int_0^x \\lambda e^{- \\lambda t} dt = \\big[ -e^{- \\lambda t} \\big]_0^x = 1-e^{- \\lambda x} \\quad\\] Propriétés: Si \\(X \\thicksim \\mathcal{E}(\\lambda)\\) \\(E(X) = \\frac{1}{\\lambda}\\) \\(V(X)= \\frac{1}{\\lambda^2}\\) Cas d’utilisations de la loi exponentielle : Dans la pratique, on rencontre souvent la distribution exponentielle lorsqu’il s’agit de représenter le temps d’attente avant l’arrivée d’un événement spécifié. Une loi exponentielle modélise la durée de vie d’un phénomène sans mémoire, ou sans vieillissement, ou sans usure. En d’autres termes, le fait que le phénomène ait duré pendant un temps \\(t\\) ne change rien à son espérance de vie à partir du temps \\(t\\). On dit qu’une variable aléatoire non négative \\(X\\) est sans mémoire lorsque \\[P(X &gt; t+h | X &gt; t) = P(X &gt; h) \\quad \\quad \\forall \\quad t,h \\ge 0\\] Par exemple, la durée de vie de la radioactivité ou d’un composant électronique, le temps qui nous sépare d’un prochain tremblement de terre ou du prochain appel téléphonique mal aiguillé sont toutes des variables aléatoires dont les distributions tendent en pratique à se rapprocher de distributions exponentielles. Loi Normale ou de Laplace-Gauss \\(\\mathcal{N}(\\mu,\\sigma^2)\\) Définition 6.18 Une variable aléatoire \\(X\\) est dite normale avec paramètres \\(\\mu\\) et \\(\\sigma^2\\) si la densité de \\(X\\) est donnée par \\[f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-(x - \\mu)^2/2\\sigma^2} \\quad \\quad \\forall \\,\\, x \\in \\mathbb{R}\\] Avec \\(\\mu \\in \\mathbb{R}\\) et \\(\\sigma \\in \\mathbb{R}^{+}\\). On dit que \\(X \\thicksim \\mathcal{N}(\\mu,\\sigma^2)\\). Remarque: On admet que \\(\\int_{-\\infty}^{+\\infty}f(x)dx = 1\\) dans la mesure où l’intégration analytique est impossible. Étude de la densité de la loi Normale La fonction \\(f\\) est paire autour d’un axe de symétrie \\(x = \\mu\\) car \\(f(x + \\mu ) = f(\\mu - x)\\). \\(f&#39;(x)=0\\) pour \\(x=\\mu\\), \\(f&#39;(x) &lt; 0\\) pour \\(x &lt; \\mu\\) et \\(f&#39;(x) &gt; 0\\) pour \\(x &gt; \\mu\\) Figure 6.5: Représentation graphique de la densité d’une loi normale. Remarque: Le paramètre \\(\\mu\\) représente l’axe de symétrie et s le degré d’aplatissement de la courbe de la loi normale dont la forme est celle d’une courbe en cloche Propriétés: Soit \\(X \\thicksim \\mathcal{N}(\\mu,\\sigma^2)\\), on a: \\(E(X)=\\mu\\) \\(V(X)=\\sigma^2\\) Théorème 6.8 (Stabilité de la loi normale) Soit \\(X_1\\) et \\(X_2\\) deux variables aléatoires normales et indépendantes de paramètres respectifs \\((\\mu_1,\\sigma_1^2)\\) et \\((\\mu_2,\\sigma_2^2)\\), alors leur somme \\(X_1+X_2\\) est une variable aléatoire normale de paramètres \\((\\mu_1 + \\mu_2,\\sigma_1^2+\\sigma_2^2)\\). Loi Normale centrée réduite \\(\\mathcal{N}(0,1)\\) Définition 6.19 Une variable aléatoire continue \\(X\\) suit une loi normale centrée réduite si sa densité de probabilité est donnée par \\[\\begin{equation} f(x) = \\frac{1}{{\\sqrt {2\\pi } }}e^{- \\frac{1}{2} x^2} \\quad \\quad \\forall \\,\\, x \\in \\mathbb{R} \\end{equation}\\] On dit \\(X \\thicksim \\mathcal{N}(0,1)\\). Remarque: \\(E(X)=0\\) et \\(V(X)=1\\). Figure 6.6: (gauche): Densité d’une loi normale centrée réduite \\(\\mathcal{N}(0,1)\\). (droite): Fonction de répartition de \\(\\mathcal{N}(0,1)\\). Relation entre loi normale et loi normale centrée réduite Théorème 6.9 (Relation avec la loi normale) Si \\(X\\) suit une loi normale \\(\\mathcal{N}(\\mu,\\sigma^2)\\), alors \\(Z= \\frac{X-\\mu}{\\sigma}\\) est une variable centrée réduite qui suit la loi normale centrée réduite \\(\\mathcal{N}(0,1)\\). Calcul des probabilités d’une loi normale La fonction de répartition de la loi normale réduite permet d’obtenir les probabilités associées à toutes variables aléatoires normales \\(\\mathcal{N}(\\mu,\\sigma^2)\\) après transformation en variable centrée réduite. Définition 6.20 On appelle fonction \\(\\Phi\\), la fonction de répartition de la loi normale centrée réduite \\(\\mathcal{N}(0,1)\\), telle que \\[\\forall \\,\\, x \\in \\mathbb{R} \\quad \\Phi(x) = P(X \\le x) = \\frac{1}{{\\sqrt {2\\pi}}} \\int_{-\\infty}^x f(t)dt\\] Propriétés: Les propriétés associées à la fonction de répartition \\(\\Phi\\) sont: \\(\\Phi\\) est croissante, continue et dérivable sur \\(\\mathbb{R}\\) et vérifie: \\(\\lim\\limits_{x\\to - \\infty} \\Phi(x) = 0\\) et \\(\\lim\\limits_{x\\to\\infty} \\Phi(x) = 1\\) \\(\\forall \\,\\, x \\in \\mathbb{R} \\quad \\Phi(x) + \\Phi(-x) = 1\\) \\(\\forall \\,\\, x \\in \\mathbb{R} \\quad \\Phi(x) - \\Phi(-x) = 2\\Phi(x) -1\\) Une application directe de la fonction \\(\\Phi\\) est la lecture des probabilités de la loi normale sur la table de la loi normale centrée réduite. Soit \\(X\\) une variable aléatoire normale de paramètres \\(\\mu =3\\) et \\(\\sigma^2=4\\). Calculer: \\(P(X &gt; 0)\\) \\(P(2 &lt; X &lt; 5)\\) \\(P(|X-3| &gt; 4)\\) Approximation normale d’une répartition binomiale Un résultat important de la théorie de probabilité est connu sous le nom de théorème limite de Moivre-Laplace. Il dit que pour \\(n\\) grand, une variable binomiale \\(\\mathcal{B}(n,p)\\) suivra approximativement la même loi qu’une variable aléatoire normale avec même moyenne et même variance. Ce théorème énonce que si “on standardise” une variable aléatoire binomiale \\(\\mathcal{B}(n,p)\\) en soustrayant d’abord sa moyenne \\(np\\) puis en divisant le résultat par son écart-type \\(\\sqrt{np(1-p)}\\), alors la variable aléatoire standardisée (de moyenne 0 et variance 1) suivra approximativement, lorsque \\(n\\) est grand, une distribution normale standard. Ce résultat fut ensuite progressivement généralisé par Laplace, Gauss et d’autres pour devenir le théorème actuellement connu comme théorème centrale limite qui est un des deux résultats les plus importants de la théorie de probabilités. Ce théorème sert de base théorique pour expliquer un fait empirique souvent relevé, à savoir qu’en pratique de très nombreux phénomènes aléatoires suivent approximativement une distribution normale. On remarquera qu’à ce stade deux approximations de la répartition binomiale ont été proposées: l’approximation de Poisson, satisfaisante lorsque \\(n\\) est grand et lorsque \\(np\\) n’est pas extrême; l’approximation normale pour laquelle on peut montrer qu’elle est de bonne qualité lorsque \\(np(1-p)\\) est grand (dès que \\(np(1-p)\\) dépasse 10). Figure 6.7: La loi de probabilité d’une variable aléatoire \\(B( n,p )\\) devient de plus en plus normale à mesure que \\(n\\) augmente. Loi de \\(\\chi^{2}\\) de Pearson Définition 6.21 Soit \\(X_1,X_2,\\ldots,X_n\\), \\(n\\) variables normales centrées réduites, et \\(Y\\) la variable aléatoire définie par \\[Y = X_1^2 + X_2^2 + \\ldots + X_i^2 + \\ldots + X_n^2 = \\sum_{i=1}^n X_i^2\\] On dit que \\(Y\\) suit la loi de \\(\\chi^2\\) (ou loi de Pearson) à \\(n\\) degrés de liberté, \\(Y \\thicksim \\chi^2 (n)\\) La loi de \\(\\chi^2\\) trouve de nombreuses applications dans le cadre de la comparaison de proportions, des tests de conformité d’une distribution observée à une distribution théorique et le test d’indépendance de deux caractères qualitatifs. Ce sont les tests du khi-deux. Remarque: Si \\(n=1\\), la variable du \\(\\chi^2\\) correspond au carré d’une variable normale centrée réduite \\(\\mathcal{N}(0,1)\\). Propriétés: Si \\(Y \\thicksim \\chi^2 (n)\\), alors: \\(E(Y)= n\\) \\(V(Y) = 2n\\) Loi de Student \\(St(n)\\) Définition 6.22 Soit \\(U\\) une variable aléatoire suivant une loi normale centrée réduite \\(\\mathcal{N}(0,1)\\) et \\(V\\) une variable aléatoire suivant une loi de \\(\\chi^2(n)\\), \\(U\\) et \\(V\\) étant indépendantes, on dit alors que \\(T_n = \\frac{U}{\\sqrt{\\frac{V}{n}}}\\) suit une loi de Student à \\(n\\) degrés de liberté. \\(T_n \\thicksim St(n)\\) La loi de Student est utilisée lors des tests de comparaison de paramètres comme la moyenne et dans l’estimation de paramètres de la population à partir de données sur un échantillon (Test de Student). Loi de Fisher-Snedecor \\(\\mathcal{F}(n,m)\\) Définition 6.23 Soit \\(U\\) et \\(V\\) deux variables aléatoires indépendantes suivant une loi de \\(\\chi^2\\) respectivement à \\(n\\) et \\(m\\) degrés de liberté. On dit que \\(F= \\frac{U/n}{V/m}\\) suit une loi de Fisher-Snedecor à \\((n,m)\\) degrés de liberté. \\(F \\thicksim \\mathcal{F}(n,m)\\) La loi de Fisher-Snedecor est utilisée pour comparer deux variances observées et sert surtout dans les très nombreux tests d’analyse de variance et de covariance. Couple de variables aléatoires continues Densité conjointe Définition 6.24 On dit que \\((X,Y)\\) est un couple aléatoire continu s’il existe une fonction \\(f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}\\) telle que pour tout \\(D \\subseteq \\mathbb{R}\\) on a \\[P\\{(X,Y) \\in D\\} = \\iint\\limits_{(x,y) \\in D} f(x,y) dx dy\\] Remarque: On a la condition de normalité \\(\\iint\\limits_{\\mathbb{R}^2} f(x,y)dxdy=1\\) La fonction \\(f\\) s’appelle densité conjointe de \\(X\\) et \\(Y\\). Notons par \\(A\\) et \\(B\\) deux ensembles de nombres réels. En définissant \\(D=\\{(x,y) : x \\in A, y \\in B\\}\\), on obtient \\[P(X\\in A, Y \\in B) = \\int_A \\int_B f(x,y) dxdy\\] La fonction de répartition du \\((X,Y)\\) est définie par \\[F(a,b)=P(X \\le a, Y \\le b) = \\int_{- \\infty}^b \\int_{- \\infty}^a f(x,y) dx dy\\] \\(f\\) est le dérivé de \\(F\\): \\(f(a,b)= \\frac{\\partial^2}{\\partial a \\partial b} F(a,b)\\) Soit \\((X,Y)\\) un couple aléatoire continu de densité \\[f(x,y)= \\left\\lbrace \\begin{array}{ll} a x y^2 &amp; \\mbox{si} \\quad 0 \\le x \\le y \\le 1 \\\\ 0 &amp; \\mbox{sinon} \\end{array} \\right.\\] Trouver la constante \\(a\\). Soit \\((X,Y)\\) un couple aléatoire continu de densité \\[f(x,y)= \\left\\lbrace \\begin{array}{ll} 2 e^{-x} e^{-2y} &amp; \\mbox{si} \\quad x &gt; 0, \\,\\, y &gt; 0\\\\ 0 &amp; \\mbox{sinon} \\end{array} \\right.\\] Montrer que: \\(P(X &gt; 1, Y &lt; 1)=e^{-1}(1-e^{-2})\\) \\(P(X &lt; a) = 1-e^{-a}\\) \\(P(X &lt; Y ) = 1/3\\) Densités marginales Si on dispose de la densité du couple, on peut retrouver les densités de \\(X\\) et de \\(Y\\), appelées les densités marginales: Densité marginale de X: \\[f(x,.)=f_X(x)=\\int_{\\mathbb{R}} f(x,y)dy\\] Densité marginale de Y: \\[f(.,y)=f_Y(y)=\\int_{\\mathbb{R}} f(x,y)dx\\] Espérance d’une fonction du couple Si \\((X,Y)\\) est un couple continu de densité \\(f(x,y)\\) et \\(g: \\mathbb{R}^2 \\rightarrow \\mathbb{R}\\) on a \\[E[ g(X,Y)] = \\iint\\limits_{\\mathbb{R}^2} g(x,y) f(x,y)dxdy\\] Indépendance Les v.a. \\(X\\) et \\(Y\\) sont indépendantes ssi \\(\\forall \\, (x,y) \\in \\mathbb{R}^2\\) on a \\[f(x,y)=f_X(x) f_Y(y)\\] Distribution conditionnelle Si \\((X,Y)\\) est un couple continu de densité \\(f(x,y)\\), on définit densité conditionnelle de \\(X\\), sous la condition \\(Y=y\\) et lorsque \\(f_Y(y) &gt; 0\\) par la relation \\[f_{X|Y} (x|y) = \\frac{f(x,y)}{f_Y(y)}\\] Supposons que \\(X\\) et \\(Y\\) aient pour densité conjointe \\[f(x,y)= \\left\\lbrace \\begin{array}{ll} \\frac{1}{y} e^{- x/y}e^{-y} &amp; \\mbox{si} \\quad x &gt; 0, \\,\\, y &gt; 0\\\\ 0 &amp; \\mbox{sinon} \\end{array} \\right.\\] Déterminer la densité conditionnelle de \\(X\\) lorsque \\(Y=y\\). Calculer \\(P(X&gt;1 | Y = y)\\) "],
["app-introRStudio.html", "A Introduction to RStudio", " A Introduction to RStudio RStudio is the most employed Integrated Development Environment (IDE) for nowadays. When you start RStudio you will see a window similar to Figure A.1. There are a lot of items in the GUI, most of them described in the RStudio IDE Cheat Sheet . The most important things to keep in mind are: The code is written in scripts in the source panel (upper-right panel in Figure A.1); for running a line or code selection from the script in the console (first tab in the lower-right panel in Figure A.1), you do it with the keyboard shortcut 'Ctrl+Enter' (Windows and Linux) or 'Cmd+Enter' (Mac OS X). Figure A.1: Main window of RStudio. The red shows the code panel and the yellow shows the console output. Extracted from here. "],
["tab-normale.html", "B Table de la loi Normale centrée réduite", " B Table de la loi Normale centrée réduite 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0 0.5000 0.5040 0.5080 0.5120 0.5160 0.5199 0.5239 0.5279 0.5319 0.5359 0.1 0.5398 0.5438 0.5478 0.5517 0.5557 0.5596 0.5636 0.5675 0.5714 0.5753 0.2 0.5793 0.5832 0.5871 0.5910 0.5948 0.5987 0.6026 0.6064 0.6103 0.6141 0.3 0.6179 0.6217 0.6255 0.6293 0.6331 0.6368 0.6406 0.6443 0.6480 0.6517 0.4 0.6554 0.6591 0.6628 0.6664 0.6700 0.6736 0.6772 0.6808 0.6844 0.6879 0.5 0.6915 0.6950 0.6985 0.7019 0.7054 0.7088 0.7123 0.7157 0.7190 0.7224 0.6 0.7257 0.7291 0.7324 0.7357 0.7389 0.7422 0.7454 0.7486 0.7517 0.7549 0.7 0.7580 0.7611 0.7642 0.7673 0.7704 0.7734 0.7764 0.7794 0.7823 0.7852 0.8 0.7881 0.7910 0.7939 0.7967 0.7995 0.8023 0.8051 0.8078 0.8106 0.8133 0.9 0.8159 0.8186 0.8212 0.8238 0.8264 0.8289 0.8315 0.8340 0.8365 0.8389 1 0.8413 0.8438 0.8461 0.8485 0.8508 0.8531 0.8554 0.8577 0.8599 0.8621 1.1 0.8643 0.8665 0.8686 0.8708 0.8729 0.8749 0.8770 0.8790 0.8810 0.8830 1.2 0.8849 0.8869 0.8888 0.8907 0.8925 0.8944 0.8962 0.8980 0.8997 0.9015 1.3 0.9032 0.9049 0.9066 0.9082 0.9099 0.9115 0.9131 0.9147 0.9162 0.9177 1.4 0.9192 0.9207 0.9222 0.9236 0.9251 0.9265 0.9279 0.9292 0.9306 0.9319 1.5 0.9332 0.9345 0.9357 0.9370 0.9382 0.9394 0.9406 0.9418 0.9429 0.9441 1.6 0.9452 0.9463 0.9474 0.9484 0.9495 0.9505 0.9515 0.9525 0.9535 0.9545 1.7 0.9554 0.9564 0.9573 0.9582 0.9591 0.9599 0.9608 0.9616 0.9625 0.9633 1.8 0.9641 0.9649 0.9656 0.9664 0.9671 0.9678 0.9686 0.9693 0.9699 0.9706 1.9 0.9713 0.9719 0.9726 0.9732 0.9738 0.9744 0.9750 0.9756 0.9761 0.9767 2 0.9772 0.9778 0.9783 0.9788 0.9793 0.9798 0.9803 0.9808 0.9812 0.9817 2.1 0.9821 0.9826 0.9830 0.9834 0.9838 0.9842 0.9846 0.9850 0.9854 0.9857 2.2 0.9861 0.9864 0.9868 0.9871 0.9875 0.9878 0.9881 0.9884 0.9887 0.9890 2.3 0.9893 0.9896 0.9898 0.9901 0.9904 0.9906 0.9909 0.9911 0.9913 0.9916 2.4 0.9918 0.9920 0.9922 0.9925 0.9927 0.9929 0.9931 0.9932 0.9934 0.9936 2.5 0.9938 0.9940 0.9941 0.9943 0.9945 0.9946 0.9948 0.9949 0.9951 0.9952 2.6 0.9953 0.9955 0.9956 0.9957 0.9959 0.9960 0.9961 0.9962 0.9963 0.9964 2.7 0.9965 0.9966 0.9967 0.9968 0.9969 0.9970 0.9971 0.9972 0.9973 0.9974 2.8 0.9974 0.9975 0.9976 0.9977 0.9977 0.9978 0.9979 0.9979 0.9980 0.9981 2.9 0.9981 0.9982 0.9982 0.9983 0.9984 0.9984 0.9985 0.9985 0.9986 0.9986 3 0.9987 0.9987 0.9987 0.9988 0.9988 0.9989 0.9989 0.9989 0.9990 0.9990 Par exemple, pour \\(x = 1.23\\) (intersection de la ligne 1.2 et de la colonne 0.03), on obtient : \\(\\Phi(1.23) \\approx 0.8907\\). "]
]
